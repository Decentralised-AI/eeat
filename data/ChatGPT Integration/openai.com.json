{
    "summary": "Close\n\nSearch Submit\n\nSkip to main content\n\n## Site Navigation\n\n  * Research\n    * Overview\n    * Index\n    * GPT-4\n    * DALL\u00b7E 3\n  * API\n    * Overview\n    * Pricing\n    * Docs\n  * ChatGPT\n    * Overview\n    * Team\n    * Enterprise\n    * Pricing\n    * Try ChatGPT\n  * Safety\n  * Company\n    * About\n    * Blog\n    * Careers\n    * Residency\n    * Charter\n    * Security\n    * Customer stories\n\nSearch\n\n##  Navigation quick links\n\n  * Log in\n  * Try ChatGPT\n\nMenu\n\n#  Mobile Navigation\n\nClose\n\n## Site Navigation\n\n### Research\n\n  * Overview\n  * Index\n  * GPT-4\n  * DALL\u00b7E 3\n\n### API\n\n  * Overview\n  * Pricing\n  * Docs\n\n### ChatGPT\n\n  * Overview\n  * Team\n  * Enterprise\n  * Pricing\n  * Try ChatGPT\n\nSafety\n\n### Company\n\n  * About\n  * Blog\n  * Careers\n  * Residency\n  * Charter\n  * Security\n  * Customer stories\n\n##  Quick Links\n\n  * Log in\n  * Try ChatGPT\n\nSearch Submit\n\nBlog\n\n# Introducing ChatGPT and Whisper APIs\n\nDevelopers can now integrate ChatGPT and Whisper models into their apps and\nproducts through our API.  \n\nIllustration: Ruby Chen  \n\nMarch 1, 2023\n\n### Authors\n\n  * Greg Brockman\n  * Atty Eleti\n  * Elie Georges\n  * Joanne Jang\n  * Logan Kilpatrick\n  * Rachel Lim\n  * Luke Miller\n  * Michelle Pokrass\n\nProduct, Announcements\n\nChatGPT and Whisper models are now available on our API, giving developers\naccess to cutting-edge language (not just chat!) and speech-to-text\ncapabilities. Through a series of system-wide optimizations, we\u2019ve achieved\n90% cost reduction for ChatGPT since December; we\u2019re now passing through those\nsavings to API users. Developers can now use our open-source Whisper large-v2\nmodel in the API with much faster and cost-effective results. ChatGPT API\nusers can expect continuous model improvements and the option to choose\ndedicated capacity for deeper control over the models. We\u2019ve also listened\nclosely to feedback from our developers and refined our API terms of service\nto better meet their needs.  \n\nGet started\n\n## Early users of ChatGPT and Whisper APIs\n\n **Snap Inc**., the creator of Snapchat, introduced My AI for Snapchat+ this\nweek. The experimental feature is running on ChatGPT API. My AI offers\nSnapchatters a friendly, customizable chatbot at their fingertips that offers\nrecommendations, and can even write a haiku for friends in seconds. Snapchat,\nwhere communication and messaging is a daily behavior, has 750 million monthly\nSnapchatters:  \n\nPlay video\n\nMy AI for Snapchat+  \n\n **Quizlet** is a global learning platform with more than 60 million students\nusing it to study, practice and master whatever they\u2019re learning. Quizlet has\nworked with OpenAI for the last three years, leveraging GPT-3 across multiple\nuse cases, including vocabulary learning and practice tests. With the launch\nof ChatGPT API, Quizlet is introducing Q-Chat, a fully-adaptive AI tutor that\nengages students with adaptive questions based on relevant study materials\ndelivered through a fun chat experience:  \n\nPlay video\n\nQuizlet Q-Chat  \n\n **Instacart** is augmenting the Instacart app to enable customers to ask\nabout food and get inspirational, shoppable answers. This uses ChatGPT\nalongside Instacart\u2019s own AI and product data from their 75,000+ retail\npartner store locations to help customers discover ideas for open-ended\nshopping goals, such as \u201cHow do I make great fish tacos?\u201d or \u201cWhat\u2019s a healthy\nlunch for my kids?\u201d Instacart plans to launch \u201cAsk Instacart\u201d later this year:  \n\nPlay video\n\nInstacart\u2019s Ask Instacart  \n\n **Shop**, Shopify\u2019s consumer app, is used by 100 million shoppers to find and\nengage with the products and brands they love. ChatGPT API is used to power\nShop\u2019s new shopping assistant. When shoppers search for products, the shopping\nassistant makes personalized recommendations based on their requests. Shop\u2019s\nnew AI-powered shopping assistant will streamline in-app shopping by scanning\nmillions of products to quickly find what buyers are looking for\u2014or help them\ndiscover something new:  \n\nPlay video\n\nShopify\u2019s Shop app  \n\n **Speak** is an AI-powered language learning app focused on building the best\npath to spoken fluency. They\u2019re the fastest-growing English app in South\nKorea, and are already using the Whisper API to power a new AI speaking\ncompanion product, and rapidly bring it to the rest of the globe. Whisper\u2019s\nhuman-level accuracy for language learners of every level unlocks true open-\nended conversational practice and highly accurate feedback:  \n\nPlay video\n\nThe Speak app  \n\n## ChatGPT API\n\n **Model** : The ChatGPT model family we are releasing today, `gpt-3.5-turbo`,\nis the same model used in the ChatGPT product. It is priced at $0.002 per 1k\ntokens, which is 10x cheaper than our existing GPT-3.5 models. It\u2019s also our\nbest model for many non-chat use cases\u2014we\u2019ve seen early testers migrate from\n`text-davinci-003` to `gpt-3.5-turbo` with only a small amount of adjustment\nneeded to their prompts.\n\n  \n **API** : Traditionally, GPT models consume unstructured text, which is\nrepresented to the model as a sequence of \u201ctokens.\u201d ChatGPT models instead\nconsume a sequence of messages together with metadata. (For the curious: under\nthe hood, the input is still rendered to the model as a sequence of \u201ctokens\u201d\nfor the model to consume; the raw format used by the model is a new format\ncalled Chat Markup Language (\u201cChatML\u201d).)\n\nWe\u2019ve created a new endpoint to interact with our ChatGPT models:  \n\n  * Request\n  * Response\n  * Python bindings\n\n    \n    \n    curl https://api.openai.com/v1/chat/completions \\\n     -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n     \"model\": \"gpt-3.5-turbo\",\n     \"messages\": [{\"role\": \"user\", \"content\": \"What is the OpenAI mission?\"}] \n     }'\n    \n    \n    {\n      \"id\": \"chatcmpl-6p5FEv1JHictSSnDZsGU4KvbuBsbu\",\n      \"object\": \"messages\",\n      \"created\": 1677693600,\n      \"model\": \"gpt-3.5-turbo\",\n      \"choices\": [\n        {\n          \"index\": 0,\n          \"finish_reason\": \"stop\",\n          \"message\": {\n            \"role\": \"assistant\",\n            \"content\": \"OpenAI's mission is to ensure that artificial general intelligence benefits all of humanity.\"\n          }\n        }\n      ],\n      \"usage\": {\n        \"prompt_tokens\": 20,\n        \"completion_tokens\": 18,\n        \"total_tokens\": 38\n      }\n    }\n    \n    \n    import openai\n    \n    completion = openai.ChatCompletion.create(\n      model=\"gpt-3.5-turbo\", \n      messages=[{\"role\": \"user\", \"content\": \"What is the OpenAI mission?\"}]\n    )\n    \n    print(completion)\n\nTo learn more about the ChatGPT API, visit our Chat guide.  \n\n## ChatGPT upgrades\n\nWe are constantly improving our ChatGPT models, and want to make these\nenhancements available to developers as well. Developers who use the\n`gpt-3.5-turbo` model will always get our recommended stable model, while\nstill having the flexibility to opt for a specific model version. For example,\ntoday we\u2019re releasing `gpt-3.5-turbo-0301`, which will be supported through at\nleast June 1st, and we\u2019ll update `gpt-3.5-turbo` to a new stable release in\nApril. The models page will provide switchover updates.  \n\n## Dedicated instances\n\nWe are also now offering dedicated instances for users who want deeper control\nover the specific model version and system performance. By default, requests\nare run on compute infrastructure shared with other users, who pay per\nrequest. Our API runs on Azure, and with dedicated instances, developers will\npay by time period for an allocation of compute infrastructure that\u2019s reserved\nfor serving their requests.\n\nDevelopers get full control over the instance\u2019s load (higher load improves\nthroughput but makes each request slower), the option to enable features such\nas longer context limits, and the ability to pin the model snapshot.\n\nDedicated instances can make economic sense for developers running beyond\n~450M tokens per day. Additionally, it enables directly optimizing a\ndeveloper\u2019s workload against hardware performance, which can dramatically\nreduce costs relative to shared infrastructure. For dedicated instance\ninquiries, contact us.  \n\n## Whisper API\n\nWhisper, the speech-to-text model we open-sourced in September 2022, has\nreceived immense praise from the developer community but can also be hard to\nrun. We\u2019ve now made the large-v2 model available through our API, which gives\nconvenient on-demand access priced at $0.006 / minute. In addition, our\nhighly-optimized serving stack ensures faster performance compared to other\nservices.\n\nWhisper API is available through our `transcriptions` (transcribes in source\nlanguage) or `translations` (transcribes into English) endpoints, and accepts\na variety of formats (m4a, mp3, mp4, mpeg, mpga, wav, webm):  \n\n  * Request\n  * Response\n  * Python bindings\n\n    \n    \n    curl https://api.openai.com/v1/audio/transcriptions \\\n      -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n      -H \"Content-Type: multipart/form-data\" \\\n      -F model=\"whisper-1\" \\\n      -F file=\"@/path/to/file/openai.mp3\"\n    \n    \n    {\n      \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger...\"\n    }\n    \n    \n    \n    import openai\n    \n    file = open(\"/path/to/file/openai.mp3\", \"rb\")\n    transcription = openai.Audio.transcribe(\"whisper-1\", file)\n    \n    print(transcription)\n\nTo learn more about the Whisper API, visit our Speech to Text guide.  \n\n## Developer focus\n\nOver the past six months, we\u2019ve been collecting feedback from our API\ncustomers to understand how we can better serve them. We\u2019ve made concrete\nchanges, such as:  \n\n  * Data submitted through the API is no longer used for service improvements (including model training) unless the organization opts in\n  * Implementing a default 30-day data retention policy for API users, with options for stricter retention depending on user needs.\n  * Removing our pre-launch review (unlocked by improving our automated monitoring)\n  * Improving developer documentation\n  * Simplifying our Terms of Service and Usage Policies, including terms around data ownership: users own the input and output of the models.\n\nFor the past two months our uptime has not met our own expectations nor that\nof our users. Our engineering team\u2019s top priority is now stability of\nproduction use cases\u2014we know that ensuring AI benefits all of humanity\nrequires being a reliable service provider. Please hold us accountable for\nimproved uptime over the upcoming months!\n\nWe believe that AI can provide incredible opportunities and economic\nempowerment to everyone, and the best way to achieve that is to allow everyone\nto build with it. We hope that the changes we announced today will lead to\nnumerous applications that everyone can benefit from. Start building next-\ngeneration apps powered by ChatGPT & Whisper.  \n\nGet started\n\n### Authors\n\n  * #### Greg Brockman\n\nView all articles\n\n  * #### Atty Eleti\n\nView all articles\n\n  * #### Elie Georges\n\nView all articles\n\n  * #### Joanne Jang\n\nView all articles\n\n  * #### Logan Kilpatrick\n\nView all articles\n\n  * #### Rachel Lim\n\nView all articles\n\n  * #### Luke Miller\n\nView all articles\n\n  * #### Michelle Pokrass\n\nView all articles\n\n### Acknowledgments\n\n#### Contributors\n\nJeff Belgum, Jake Berdine, Trevor Cai, Alexander Carney, Brooke Chan, Che\nChang, Derek Chen, Ruby Chen, Aidan Clark, Thomas Degry, Steve Dowling, Sheila\nDunning, Liam Fedus, Vik Goel, Scott Gray, Aurelia Guy, Jeff Harris, Peter\nHoeschele, Angela Jiang, Denny Jin, Jong Wook Kim, Yongjik Kim, Michael Lampe,\nDaniel Levy, Brad Lightcap, Patricia Lue, Bianca Martin, Christine McLeavey,\nLuke Metz, Andrey Mishchenko, Vinnie Monaco, Evan Morikawa, Mira Murati, Rohan\nNuttall, Alex Paino, Ashley Pantuliano, Mikhail Pavlov, Andrew Peng, Henrique\nPonde de Oliveira Pinto, Alec Radford, Kendra Rimbach, Aliisa Rosenthal, Nick\nRyder, Ted Sanders, Heather Schmidt, John Schulman, Zarina Stanik, Felipe\nSuch, Nick Turley, Carroll Wainwright, Peter Welinder, Clemens Winter, Sherwin\nWu, Tao Xu, Qiming Yuan, Barret Zoph  \n\n#### Research\n\n  * Overview\n  * Index\n  * GPT-4\n  * DALL\u00b7E 3\n\n#### API\n\n  * Overview\n  * Pricing\n  * Docs\n\n#### ChatGPT\n\n  * Overview\n  * Team\n  * Enterprise\n  * Pricing\n  * Try ChatGPT\n\n#### Company\n\n  * About\n  * Blog\n  * Careers\n  * Charter\n  * Security\n  * Customer stories\n  * Safety\n\nOpenAI \u00a9 2015 \u2013 2024Terms & policiesPrivacy policyBrand guidelines\n\n#### Social\n\n  * Twitter\n  * YouTube\n  * GitHub\n  * SoundCloud\n  * LinkedIn\n\nBack to top\n\n",
    "links": "[{\"link\": \"https://openai.com/\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog/introducing-chatgpt-and-whisper-apis#content\", \"text\": \"\"}, {\"link\": \"https://openai.com/\", \"text\": \"\"}, {\"link\": \"https://openai.com/research/overview\", \"text\": \"\"}, {\"link\": \"https://openai.com/research\", \"text\": \"\"}, {\"link\": \"https://openai.com/gpt-4\", \"text\": \"\"}, {\"link\": \"https://openai.com/dall-e-3\", \"text\": \"\"}, {\"link\": \"https://openai.com/product\", \"text\": \"\"}, {\"link\": \"https://openai.com/pricing\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt/team\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt/enterprise\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt/pricing\", \"text\": \"\"}, {\"link\": \"https://openai.com/safety\", \"text\": \"\"}, {\"link\": \"https://openai.com/about\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog\", \"text\": \"\"}, {\"link\": \"https://openai.com/careers\", \"text\": \"\"}, {\"link\": \"https://openai.com/residency\", \"text\": \"\"}, {\"link\": \"https://openai.com/charter\", \"text\": \"\"}, {\"link\": \"https://openai.com/security\", \"text\": \"\"}, {\"link\": \"https://openai.com/customer-stories\", \"text\": \"\"}, {\"link\": \"https://openai.com/\", \"text\": \"\"}, {\"link\": \"https://openai.com/research/overview\", \"text\": \"\"}, {\"link\": \"https://openai.com/research\", \"text\": \"\"}, {\"link\": \"https://openai.com/gpt-4\", \"text\": \"\"}, {\"link\": \"https://openai.com/dall-e-3\", \"text\": \"\"}, {\"link\": \"https://openai.com/product\", \"text\": \"\"}, {\"link\": \"https://openai.com/pricing\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt/team\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt/enterprise\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt/pricing\", \"text\": \"\"}, {\"link\": \"https://openai.com/safety\", \"text\": \"\"}, {\"link\": \"https://openai.com/about\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog\", \"text\": \"\"}, {\"link\": \"https://openai.com/careers\", \"text\": \"\"}, {\"link\": \"https://openai.com/residency\", \"text\": \"\"}, {\"link\": \"https://openai.com/charter\", \"text\": \"\"}, {\"link\": \"https://openai.com/security\", \"text\": \"\"}, {\"link\": \"https://openai.com/customer-stories\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog/introducing-chatgpt-and-whisper-apis#GregBrockman\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog/introducing-chatgpt-and-whisper-apis#AttyEleti\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog/introducing-chatgpt-and-whisper-apis#ElieGeorges\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog/introducing-chatgpt-and-whisper-apis#JoanneJang\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog/introducing-chatgpt-and-whisper-apis#LoganKilpatrick\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog/introducing-chatgpt-and-whisper-apis#RachelLim\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog/introducing-chatgpt-and-whisper-apis#LukeMiller\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog/introducing-chatgpt-and-whisper-apis#MichellePokrass\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?topics=product\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?topics=announcements\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?authors=greg-brockman\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?authors=atty-eleti\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?authors=elie-georges\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?authors=joanne-jang\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?authors=logan-kilpatrick\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?authors=rachel-lim\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?authors=luke-miller\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog?authors=michelle-pokrass\", \"text\": \"\"}, {\"link\": \"https://openai.com/\", \"text\": \"\"}, {\"link\": \"https://openai.com/research/overview\", \"text\": \"\"}, {\"link\": \"https://openai.com/research\", \"text\": \"\"}, {\"link\": \"https://openai.com/gpt-4\", \"text\": \"\"}, {\"link\": \"https://openai.com/dall-e-3\", \"text\": \"\"}, {\"link\": \"https://openai.com/product\", \"text\": \"\"}, {\"link\": \"https://openai.com/pricing\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt/team\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt/enterprise\", \"text\": \"\"}, {\"link\": \"https://openai.com/chatgpt/pricing\", \"text\": \"\"}, {\"link\": \"https://openai.com/about\", \"text\": \"\"}, {\"link\": \"https://openai.com/blog\", \"text\": \"\"}, {\"link\": \"https://openai.com/careers\", \"text\": \"\"}, {\"link\": \"https://openai.com/charter\", \"text\": \"\"}, {\"link\": \"https://openai.com/security\", \"text\": \"\"}, {\"link\": \"https://openai.com/customer-stories\", \"text\": \"\"}, {\"link\": \"https://openai.com/safety\", \"text\": \"\"}, {\"link\": \"https://openai.com/policies\", \"text\": \"\"}, {\"link\": \"https://openai.com/policies/privacy-policy\", \"text\": \"\"}, {\"link\": \"https://openai.com/brand\", \"text\": \"\"}]",
    "priceAndPlans": "Close\n\nSearch Submit\n\nSkip to main content\n\n## Site Navigation\n\n  * Research\n    * Overview\n    * Index\n    * GPT-4\n    * DALL\u00b7E 3\n  * API\n    * Overview\n    * Pricing\n    * Docs\n  * ChatGPT\n    * Overview\n    * Team\n    * Enterprise\n    * Pricing\n    * Try ChatGPT\n  * Safety\n  * Company\n    * About\n    * Blog\n    * Careers\n    * Residency\n    * Charter\n    * Security\n    * Customer stories\n\nSearch\n\n##  Navigation quick links\n\n  * Log in\n  * Try ChatGPT\n\nMenu\n\n#  Mobile Navigation\n\nClose\n\n## Site Navigation\n\n### Research\n\n  * Overview\n  * Index\n  * GPT-4\n  * DALL\u00b7E 3\n\n### API\n\n  * Overview\n  * Pricing\n  * Docs\n\n### ChatGPT\n\n  * Overview\n  * Team\n  * Enterprise\n  * Pricing\n  * Try ChatGPT\n\nSafety\n\n### Company\n\n  * About\n  * Blog\n  * Careers\n  * Residency\n  * Charter\n  * Security\n  * Customer stories\n\n##  Quick Links\n\n  * Log in\n  * Try ChatGPT\n\nSearch Submit\n\n# Pricing\n\nSimple and flexible. Only pay for what you use.\n\n## Quick links\n\n  * Contact sales\n  * Learn more\n\n## Language models\n\nMultiple models, each with different capabilities and price points. Prices are\nper 1,000 tokens. You can think of tokens as pieces of words, where 1,000\ntokens is about 750 words. This paragraph is 35 tokens.  \n\n### GPT-4 Turbo\n\nWith 128k context, fresher knowledge and the broadest set of capabilities,\nGPT-4 Turbo is more powerful than GPT-4 and offered at a lower price.  \n\nLearn about GPT-4 Turbo\n\nModel| Input| Output  \n---|---|---  \ngpt-4-1106-preview| $0.01 / 1K tokens| $0.03 / 1K tokens  \ngpt-4-1106-vision-preview| $0.01 / 1K tokens| $0.03 / 1K tokens  \n  \n### gpt-4-1106-preview\n\nInput\n\n$0.01 / 1K tokens\n\nOutput\n\n$0.03 / 1K tokens\n\n### gpt-4-1106-vision-preview\n\nInput\n\n$0.01 / 1K tokens\n\nOutput\n\n$0.03 / 1K tokens\n\n## Vision pricing calculator\n\npx\n\nby\n\npx\n\n=$0.00255\n\nLow resolution\n\n=$0.00255\n\nPrice per 1K tokens (fixed)| $0.01  \n---|---  \nResized width| 150  \nResized height| 150  \n512 \u00d7 512 tiles| 1 \u00d7 1  \nTotal tiles| 1  \nBase tokens| 85  \nTile tokens| 170 \u00d7 1 = 170  \nTotal tokens| 255  \nTotal price|  $0.00255  \n  \n### GPT-4\n\nWith broad general knowledge and domain expertise, GPT-4 can follow complex\ninstructions in natural language and solve difficult problems with accuracy.\n\nLearn about GPT-4\n\nModel| Input| Output  \n---|---|---  \ngpt-4| $0.03 / 1K tokens| $0.06 / 1K tokens  \ngpt-4-32k| $0.06 / 1K tokens| $0.12 / 1K tokens  \n  \n### gpt-4\n\nInput\n\n$0.03 / 1K tokens\n\nOutput\n\n$0.06 / 1K tokens\n\n### gpt-4-32k\n\nInput\n\n$0.06 / 1K tokens\n\nOutput\n\n$0.12 / 1K tokens\n\n### GPT-3.5 Turbo\n\nGPT-3.5 Turbo models are capable and cost-effective.\n\n`gpt-3.5-turbo-0125` is the flagship model of this family, supports a 16K\ncontext window and is optimized for dialog.\n\n`gpt-3.5-turbo-instruct` is an Instruct model and only supports a 4K context\nwindow.\n\nLearn about GPT-3.5 Turbo\n\nModel| Input| Output  \n---|---|---  \ngpt-3.5-turbo-0125| $0.0010 / 1K tokens| $0.0020 / 1K tokens  \ngpt-3.5-turbo-instruct| $0.0015 / 1K tokens| $0.0020 / 1K tokens  \n  \n### gpt-3.5-turbo-0125\n\nInput\n\n$0.0010 / 1K tokens\n\nOutput\n\n$0.0020 / 1K tokens\n\n### gpt-3.5-turbo-instruct\n\nInput\n\n$0.0015 / 1K tokens\n\nOutput\n\n$0.0020 / 1K tokens\n\n### Assistants API\n\nAssistants API and tools (retrieval, code interpreter) make it easy for\ndevelopers to build AI assistants within their own applications. Each\nassistant incurs its own retrieval file storage fee based on the files passed\nto that assistant. The retrieval tool chunks and indexes your files content in\nour vector database.\n\nLearn more\n\nThe tokens used for the Assistant API are billed at the chosen language\nmodel's per-token input / output rates and the assistant intelligently chooses\nwhich context from the thread to include when calling the model  \n\nLearn about Assistants API\n\nTool| Input  \n---|---  \nCode interpreter| $0.03 / session  \nRetrieval| $0.20 / GB / assistant / day (free until 02/01/2024)  \n  \n### Code interpreter\n\nInput\n\n$0.03 / session\n\n### Retrieval\n\nInput\n\n$0.20 / GB / assistant / day (free until 02/01/2024)\n\n  \n\n### Fine-tuning models\n\nCreate your own custom models by fine-tuning our base models with your\ntraining data. Once you fine-tune a model, you\u2019ll be billed only for the\ntokens you use in requests to that model.\n\nLearn about fine-tuning\n\nModel| Training| Input usage| Output usage  \n---|---|---|---  \ngpt-3.5-turbo| $0.0080 / 1K tokens| $0.0030 / 1K tokens| $0.0060 / 1K tokens  \ndavinci-002| $0.0060 / 1K tokens| $0.0120 / 1K tokens| $0.0120 / 1K tokens  \nbabbage-002| $0.0004 / 1K tokens| $0.0016 / 1K tokens| $0.0016 / 1K tokens  \n  \n### gpt-3.5-turbo\n\nTraining\n\n$0.0080 / 1K tokens\n\nInput usage\n\n$0.0030 / 1K tokens\n\nOutput usage\n\n$0.0060 / 1K tokens\n\n### davinci-002\n\nTraining\n\n$0.0060 / 1K tokens\n\nInput usage\n\n$0.0120 / 1K tokens\n\nOutput usage\n\n$0.0120 / 1K tokens\n\n### babbage-002\n\nTraining\n\n$0.0004 / 1K tokens\n\nInput usage\n\n$0.0016 / 1K tokens\n\nOutput usage\n\n$0.0016 / 1K tokens\n\n### Embedding models\n\nBuild advanced search, clustering, topic modeling, and classification\nfunctionality with our embeddings offering.\n\nLearn about embeddings\n\nModel| Usage  \n---|---  \nada v2| $0.0001 / 1K tokens  \n  \n### ada v2\n\nUsage\n\n$0.0001 / 1K tokens\n\n### Base models\n\nGPT base models are not optimized for instruction-following and are less\ncapable, but they can be effective when fine-tuned for narrow tasks.\n\nLearn about GPT base models\n\nModel| Usage  \n---|---  \ndavinci-002| $0.0020 / 1K tokens  \nbabbage-002| $0.0004 / 1K tokens  \n  \n### davinci-002\n\nUsage\n\n$0.0020 / 1K tokens\n\n### babbage-002\n\nUsage\n\n$0.0004 / 1K tokens\n\n## Other models\n\n### Image models\n\nBuild DALL\u00b7E directly into your apps to generate and edit novel images and\nart. DALL\u00b7E 3 is the highest quality model and DALL\u00b7E 2 is optimized for lower\ncost.\n\nLearn about image generation\n\nModel| Quality| Resolution| Price  \n---|---|---|---  \nDALL\u00b7E 3| Standard| 1024\u00d71024| $0.040 / image  \n| Standard| 1024\u00d71792, 1792\u00d71024| $0.080 / image  \nDALL\u00b7E 3| HD| 1024\u00d71024| $0.080 / image  \n| HD| 1024\u00d71792, 1792\u00d71024| $0.120 / image  \nDALL\u00b7E 2| | 1024\u00d71024| $0.020 / image  \n| | 512\u00d7512| $0.018 / image  \n| | 256\u00d7256| $0.016 / image  \n  \n### DALL\u00b7E 3\n\nQuality\n\nStandard\n\nResolution\n\n1024\u00d71024\n\nPrice\n\n$0.040 / image\n\n###\n\nQuality\n\nStandard\n\nResolution\n\n1024\u00d71792, 1792\u00d71024\n\nPrice\n\n$0.080 / image\n\n### DALL\u00b7E 3\n\nQuality\n\nHD\n\nResolution\n\n1024\u00d71024\n\nPrice\n\n$0.080 / image\n\n###\n\nQuality\n\nHD\n\nResolution\n\n1024\u00d71792, 1792\u00d71024\n\nPrice\n\n$0.120 / image\n\n### DALL\u00b7E 2\n\nQuality\n\nResolution\n\n1024\u00d71024\n\nPrice\n\n$0.020 / image\n\n###\n\nQuality\n\nResolution\n\n512\u00d7512\n\nPrice\n\n$0.018 / image\n\n###\n\nQuality\n\nResolution\n\n256\u00d7256\n\nPrice\n\n$0.016 / image\n\n### Audio models\n\nWhisper can transcribe speech into text and translate many languages into\nEnglish.\n\nText-to-speech (TTS) can convert text into spoken audio.\n\nModel| Usage  \n---|---  \nWhisper| $0.006 / minute (rounded to the nearest second)  \nTTS| $0.015 / 1K characters  \nTTS HD| $0.030 / 1K characters  \n  \n### Whisper\n\nUsage\n\n$0.006 / minute (rounded to the nearest second)\n\n### TTS\n\nUsage\n\n$0.015 / 1K characters\n\n### TTS HD\n\nUsage\n\n$0.030 / 1K characters\n\nPlease note that our Usage Policies require you to provide a clear disclosure\nto end users that the TTS voice they are hearing is AI-generated and not a\nhuman voice.  \n\n## Older models\n\nWe continue to improve our models and periodically retire older, less used\nmodels.  \n\nView pricing and info for older models\n\n## Simple and flexible\n\n **Pay as you go**  \nTo keep things simple and flexible, pay only for the resources you use.\n\n **Choose your model**  \nUse the right model for the job. We offer a spectrum of capabilities and price\npoints.  \n\n## Built with OpenAI\n\nView all customer stories\n\n  * ### Morgan Stanley\n\nMorgan Stanley wealth management deploys GPT-4 to organize its vast knowledge\nbase.\n\n  * ### Stripe\n\nStripe leverages GPT-4 to streamline user experience and combat fraud.\n\n  *   * \n\n## FAQ\n\n  * ### What\u2019s a token?\n\nYou can think of tokens as pieces of words used for natural language\nprocessing. For English text, 1 token is approximately 4 characters or 0.75\nwords. As a point of reference, the collected works of Shakespeare are about\n900,000 words or 1.2M tokens.\n\nTo learn more about how tokens work and estimate your usage\u2026\n\n    * Experiment with our interactive Tokenizer tool.\n    * Log in to your account and enter text into the Playground. The counter in the footer will display how many tokens are in your text.  \n\n  * ### Which model should I use?\n\nWe generally recommend that developers use either `gpt-4` or `gpt-3.5-turbo`,\ndepending on how complex the tasks you are using the models for are. `gpt-4`\ngenerally performs better on a wide range of evaluations, while\n`gpt-3.5-turbo` returns outputs with lower latency and costs much less per\ntoken. We recommend experimenting with these models in Playground to\ninvestigate which models provide the best price performance trade-off for your\nusage. A common design pattern is to use several distinct query types which\nare each dispatched to the model appropriate to handle them.  \n\n  * ### How will I know how many tokens I\u2019ve used each month?\n\nLog in to your account to view your usage tracking dashboard. This page will\nshow you how many tokens you\u2019ve used during the current and past billing\ncycles.  \n\n  * ### How can I manage my spending?\n\nYou can set a  **monthly budget**  in your billing settings, after which we\u2019ll\nstop serving your requests. There may be a delay in enforcing the limit, and\nyou are responsible for any overage incurred. You can also configure an\n**email notification threshold**  to receive an email alert once you cross\nthat threshold each month. We recommend checking your usage tracking dashboard\nregularly to monitor your spend.  \n\n  * ### Is the ChatGPT API included in the ChatGPT Plus subscription?\n\nNo, the ChatGPT API and ChatGPT Plus subscription are billed separately. The\nAPI has its own pricing, which can be found at https://openai.com/pricing. The\nChatGPT Plus subscription covers usage on chat.openai.com only and costs\n$20/month.  \n\n  * ### Does Playground usage count against my quota?\n\nYes, we treat Playground usage the same as regular API usage.  \n\n  * ### How is pricing calculated for Completions?\n\nChat completion requests are billed based on the number of input tokens sent\nplus the number of tokens in the output(s) returned by the API.\n\nYour request may use up to `num_tokens(input) + [max_tokens * max(n,\nbest_of)]` tokens, which will be billed at the per-engine rates outlined at\nthe top of this page.\n\nIn the simplest case, if your prompt contains 200 tokens and you request a\nsingle 900 token completion from the gpt-3.5-turbo-0125 API, your request will\nuse 1100 tokens and will cost `[(200 * 0.001) + (900 * 0.002)] / 1000 =\n$0.002`.\n\nYou can limit costs by reducing prompt length or maximum response length,\nlimiting usage of `best_of/n` , adding appropriate stop sequences, or using\nengines with lower per-token costs.  \n\n  * ### How is pricing calculated for Fine-tuning?\n\nThere are two components to fine-tuning pricing: training and usage.\n\nWhen training a fine-tuned model, the total tokens used will be billed\naccording to our training rates. Note that the number of training tokens\ndepends on the number of tokens in your training dataset  **and**  your chosen\nnumber of training epochs. The default number of epochs is 4.\n\n(Tokens in your training file * Number of training epochs) = Total training\ntokens  \n\nOnce you fine-tune a model, you\u2019ll be billed only for the tokens you use.\nRequests sent to fine-tuned models are billed at our usage rates.  \n\n  * ### Is there an SLA on the various models?\n\nWe will be publishing an SLA soon. In the meantime you can visit our Status\npage to monitor service availability and view historical uptime. If your\ncompany or application has specific requirements, please contact our sales\nteam.  \n\n  * ### Is the API available on Microsoft Azure?\n\nYes. Azure customers can access the OpenAI API on Azure with the compliance,\nregional support, and enterprise-grade security that Azure offers. Learn more\nor contact sales@openai.com.  \n\n#### Research\n\n  * Overview\n  * Index\n  * GPT-4\n  * DALL\u00b7E 3\n\n#### API\n\n  * Overview\n  * Pricing\n  * Docs\n\n#### ChatGPT\n\n  * Overview\n  * Team\n  * Enterprise\n  * Pricing\n  * Try ChatGPT\n\n#### Company\n\n  * About\n  * Blog\n  * Careers\n  * Charter\n  * Security\n  * Customer stories\n  * Safety\n\nOpenAI \u00a9 2015 \u2013 2024Terms & policiesPrivacy policyBrand guidelines\n\n#### Social\n\n  * Twitter\n  * YouTube\n  * GitHub\n  * SoundCloud\n  * LinkedIn\n\nBack to top\n\n"
}