{
    "summary": "Toggle navigation\n\n\u2122\n\n  * Products\n\nCloud servers\n\nCloud servers with per-second billing. Isolated resources will give maximum\nperformance for your project.\n\nGPU servers\n\nCloud servers with modern RTX and Tesla graphics accelerators for games,\nrendering, streaming, working with 3D graphics, artificial intelligence,\nblockchain.\n\nRTX 4090\n\nRTX 3090\n\nRTX 3080\n\nTesla A100\n\nRTX A5000\n\nTesla A10\n\nRTX 2080 Ti\n\nTesla A2\n\nTesla T4\n\nTesla V100\n\nAll GPU servers\n\nCPU servers\n\nCloud servers with high-performance Intel Xeon Gold second and third\ngenerations CPUs, available for 100% CPU time.\n\nSSD serversNVMe servers\n\nAll CPU servers\n\nDedicated servers\n\n\u0410\u0440\u0435\u043d\u0434\u0443\u0439\u0442\u0435 \u0444\u0438\u0437\u0438\u0447\u0435\u0441\u043a\u0438 \u0432\u044b\u0434\u0435\u043b\u0435\u043d\u043d\u044b\u0439 \u0441\u0435\u0440\u0432\u0435\u0440 \u043d\u0430 \u0434\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0441\u0440\u043e\u043a \u0441 \u043f\u043e\u043c\u0435\u0441\u044f\u0447\u043d\u043e\u0439 \u043e\u043f\u043b\u0430\u0442\u043e\u0439.\n\u0421\u043e\u0431\u0440\u0435\u0440\u0438\u0442\u0435 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044e \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0441\u043e\u0432\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043a\u043e\u043c\u043b\u0435\u043a\u0442\u0443\u044e\u0449\u0438\u0445: \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u043e\u0432\nIntel Xeon Gold 2-\u0433\u043e \u0438 3-\u0433\u043e \u043f\u043e\u043a\u043e\u043b\u0435\u043d\u0438\u0439, \u0434\u043e 10 \u043d\u043e\u0432\u0435\u0439\u0448\u0438\u0445 \u0432\u0438\u0434\u0435\u043e\u0443\u0441\u043a\u043e\u0440\u0438\u0442\u0435\u043b\u0435\u0439 RTX \u0438\nTesla \u0438 \u0434\u043e 8192 \u0413\u0411 RAM \u043d\u0430 \u0441\u0435\u0440\u0432\u0435\u0440, SSD- \u0438 NVMe-\u0434\u0438\u0441\u043a\u043e\u0432 \u0434\u043b\u044f \u0434\u0430\u0442\u0430-\u0446\u0435\u043d\u0442\u0440\u043e\u0432.\n\n\u0412\u044b\u0431\u0440\u0430\u0442\u044c dedicated server\n\nMarketplace\n\nUse popular and modern applications as effective tools for organizing your\nproject. Save time with pre-configured images that already have all the\nnecessary components installed.\n\nForget about manually downloading and installing the software \u2014 just deploy a\nvirtual server with a ready-made image.\n\n3DCUDA Docker / NGCFor gamesWindows imagesLinux images\n\nAll pre-installed images\n\n  * Features\n  * Prices\n  * FAQ\n  * Contact\n  * Login\n\n# Cloud servers with Tesla A100\n\nUnsurpassed acceleration for solving the most complex computational tasks of\nAI, data analysis and HPC\n\n## Graphics servers with Tesla A100\n\nAll graphics servers with Tesla A100 are based on two Intel Xeon Gold 6240R\nCPUs with a base clock speed of 2.4 GHz and a maximum clock speed with Turbo\nBoost technology of 4.0 GHz.\n\nEach processor contains two Intel\u00ae AVX-512 units and supports Intel\u00ae AVX-512\nDeep Learning Boost functions. This set of instructions speeds up\nmultiplication and addition operations with reduced accuracy, which are used\nin many internal cycles of the deep learning algorithm.\n\nEach server has 768 GB of DDR4 ECC Reg 2933 MHz RAM. Local storage with a\ntotal capacity of 3200 GB is organized on Intel\u00ae solid-state drives, designed\nspecifically for data centers.\n\n## GPU Tesla A100\n\nTesla A100 GPU provides unsurpassed acceleration for AI tasks, data analysis\nand for solving the most complex computing tasks. The A100 is the most\nproductive integrated platform for AI and HPC, allowing you to get real-time\nresults and deploy scalable solutions.\n\nWhen training deep learning algorithms, tensor cores with Tensor Float (TF32)\nsupport increase performance by 20 times, without requiring changes in the\ncode, and speed up the automatic function of working with different accuracy\nand FP16 by 2 times.\n\nDouble-precision tensor cores provide the greatest performance for high-\nperformance computing since the advent of the GPU. HPC applications can also\nuse TF32 to achieve up to 11 times the throughput for precise operations.\n\nData science specialists need to analyze, visualize large data sets and\nextract valuable information from them. To cope with workloads, servers\nequipped with A100 graphics accelerators provide the necessary computing power\nthanks to large amounts of high-speed memory with high bandwidth.\n\nVideo memory capacity | 80 GB  \n---|---  \nType of video memory | HBM2e  \nMemory bandwidth | 1935 Gb/s  \nEncode/decode | 1 encoder, 2 decoder (+AV1 decode)  \n  \n## GPU performance benchmarks\n\nPerformance benchmarks results in a virtual environment for 1 Tesla A100\ngraphics card.\n\n  * ### OctaneBench 2020\n\nup to\n\n500\n\npts\n\n  * ### Matrix multiply example\n\n4300\n\nGFlop/s\n\n  * ### Hashcat bcrypt\n\n117 000\n\nH/s\n\n  * \n\n## Basic configurations with Tesla A100 80 GB\n\nPrices:  Per hour Per month 25% discount with 30 days advance payment 35%\ndiscount with 60 days advance payment 50% discount with 60 days advance\npayment\n\nUSD RUB EUR KZT\n\n### Subscribe to the availability notification\n\nSpecify the number of required flavors .  \nWhen they become available, you will receive a notification by email.\n\nOK\n\nCancel\n\nYou successfully subscribed on notification.\n\nYou already subscribed on notification.\n\nYou already have reached the limit of TeslaA100 flavors.\n\nOK\n\nName | vCPU | RAM, MB | Disk, GB | GPU |  Price, tariff | Price, hour |\nPrice, month |  |  \n---|---|---|---|---|---|---|---|---|---  \nteslaa100-1.16.64.160 | 16 | 65536 | 160 | 1 |  | $2.35  | $1 692.35  |\nLaunch  \nteslaa100-1.16.128.160 | 16 | 131072 | 160 | 1 |  | $2.47  | $1 774.89  |\nLaunch  \nteslaa100-2.24.256.160 | 24 | 262144 | 160 | 2 |  | $4.87  | $3 503.80  |\nLaunch  \nteslaa100-3.32.384.160 | 32 | 393216 | 160 | 3 |  | $7.27  | $5 232.70  |\nLaunch  \nteslaa100-4.16.128.120 | 16 | 131072 | 120 | 4 |  | $8.84  | $6 366.48  |\nLaunch  \nteslaa100-4.16.256.120 | 16 | 262144 | 120 | 4 |  | $9.07  | $6 531.56  |\nLaunch  \nteslaa100-4.44.256.120 | 44 | 262288 | 120 | 4 |  | $9.23  | $6 644.60  |\nLaunch  \nteslaa100-4.44.512.160 | 44 | 524288 | 160 | 4 |  | $9.69  | $6 977.73  |\nLaunch  \n  \n\u2194\n\nCustom configuration\n\n### Request for custom configuration\n\nPlease write us about the required configuration in the chat.\n\nAll GPU servers\n\n## 100% performance\n\nEach physical core or GPU adapter assigned only to a single client.  \nIt means that:\n\n  * Available vCPU time is 100%\n  * Physical pass through of GPU inside a VM\n  * Less storage and network load on hypervisors, more storage and network performance for a client.\n\nUp to 75 000 IOPS1 for the RANDOM READ and up to 20 000 IOPS for the RANDOM\nWRITE for the Virtual Machines with local SSDs.\n\nUp to 22 500 IOPS1 for the RANDOM READ and up to 20 000 IOPS for the RANDOM\nWRITE for the Virtual Machines with block storage Volumes.\n\nYou can be sure that Virtual Machines are not sharing vCPU or GPU among each\nother.\n\n  1. IOPS \u2014 Input/Output Operations Per Second.\n\n## Answers to frequently asked questions\n\n#### What is the minimum rental period for a virtual GPU-server?\n\nYou can rent a virtual server for any period. Make a payment for any amount\nfrom 1.1 $ and work within the prepaid balance. When the work is completed,\ndelete the server to stop spending money.\n\n#### How quickly can I get started with a virtual GPU-server?\n\nYou create GPU-servers yourself in the control panel, choosing the hardware\nconfiguration and operating system. As a rule, the ordered capacities are\navailable for use within a few minutes.\n\nIf something went wrong-write to our round-the-clock support service:\nhttps://t.me/immerscloudsupport.\n\n#### What operating systems can be installed on a virtual GPU-server?\n\nYou can choose from basic images: Windows Server 2019, Windows Server 2022,\nUbuntu, Debian, CentOS, Fedora, OpenSUSE. Or use a pre-configured image from\nthe Marketplace.\n\nAll operating systems are installed automatically when the GPU-server is\ncreated.\n\n#### How to connect to a virtual GPU-server?\n\nBy default, we provide connection to Windows-based servers via RDP, and for\nLinux-based servers-via SSH.\n\nYou can configure any connection method that is convenient for you yourself.\n\n#### Is it possible to rent a virtual GPU-server with an custom configuration?\n\nYes, it is possible. Contact our round-the-clock support service\n(https://t.me/immerscloudsupport) and tell us what configuration you need.\n\n## A bit more about us\n\n  * ### Per-second billing\n\nand free VM pause (shelve). You pay for the actual use of your VMs\n\n  * ### 24/7/365\n\nTech support is always in touch in the chat and responds in a few minutes  \n  \n\n  * ### Free traffic\n\nSpeeds up to 2 Gb/s without paying for incoming and outgoing traffic  \n  \n\n  * ### Our data centers\n\nBuilt according to the TIER III standard\n\n  * ### 100% of power is yours\n\nWe do not share resources you have purchased with other users\n\n  * ### 20 000+\n\nClients trust us with their data and tasks\n\n  *   * \nSign up\n\n## Ready-made OS images with the required software\n\nCreate virtual servers using our pre-configured OS images with Windows or\nLinux and specialized pre-installed software.\n\n  * Basic images\n  * 3D\n  * AI\n  * Development\n  * \n\n  * Ubuntu\n\n\n\n  * Debian\n\n\n\n  * CentOS\n\n\n\n  * Fedora\n\n\n\n  * OpenSUSE\n\n\n\n  * MS Windows Server\n\n\n\n  * \n\n  * 3ds Max\n\n\n\n  * Cinema 4D\n\n\n\n  * Corona\n\n\n\n  * Deadline\n\n\n\n  * Blender\n\n\n\n  * Archicad\n\n\n\n  * \n\n  *   * Ubuntu\n\nGraphics drivers, CUDA, cuDNN\n\n  *   * MS Windows Server\n\nGraphics drivers, CUDA, cuDNN\n\n  *   * \n\n  * Nginx\n\n\n\n  * Apache\n\n\n\n  * Git\n\n\n\n  * Jupyter\n\n\n\n  * Django\n\n\n\n  * MySQL\n\n\n\n  * \n\nView all the pre-installed images in the Marketplace.\n\n## Pure OpenStack API\n\nDevelopers and system administrators can manage the cloud using the full\nOpenStack API.\n\nAuthenticate `ninja_user` example: ` $ curl -g -i -X POST\nhttps://api.immers.cloud:5000/v3/auth/tokens \\  \n-H \"Accept: application/json\" \\   \n-H \"Content-Type: application/json\" \\   \n-H \"User-Agent: YOUR-USER-AGENT\" \\   \n-d '{\"auth\": {\"identity\": {\"methods\": [\"password\"], \"password\": {\"user\": { \"name\": \"ninja_user\", \"password\": \"ninja_password\", \"domain\": {\"id\": \"default\"}}}}, \"scope\": {\"project\": {\"name\": \"ninja_user\", \"domain\": {\"id\": \"default\"}}}}}' `\n\nCreate `ninja_vm` example: ` $ curl -g -i -X POST\nhttps://api.immers.cloud:8774/v2.1/servers \\  \n-H \"Accept: application/json\" \\   \n-H \"Content-Type: application/json\" \\   \n-H \"User-Agent: YOUR-USER-AGENT\" \\   \n-H \"X-Auth-Token: YOUR-API-TOKEN\" \\   \n-d '{\"server\": {\"name\": \"ninja_vm\", \"imageRef\": \"8b85e210-d2c8-490a-a0ba-dc17183c0223\", \"key_name\": \"mykey01\", \"flavorRef\": \"8f9a148d-b258-42f7-bcc2-32581d86e1f1\", \"max_count\": 1, \"min_count\": 1, \"networks\": [{\"uuid\": \"cc5f6f4a-2c44-44a4-af9a-f8534e34d2b7\"}]}}' `\n\nSTOP `ninja_vm` example: ` $ curl -g -i -X POST\nhttps://api.immers.cloud:8774/v2.1/servers/{server_id}/action \\  \n-H \"Accept: application/json\" \\   \n-H \"Content-Type: application/json\" \\   \n-H \"User-Agent: YOUR-USER-AGENT\" \\   \n-H \"X-Auth-Token: YOUR-API-TOKEN\" \\   \n-d '{\"os-stop\" : null}' `\n\nSTART `ninja_vm` example: ` $ curl -g -i -X POST\nhttps://api.immers.cloud:8774/v2.1/servers/{server_id}/action \\  \n-H \"Accept: application/json\" \\   \n-H \"Content-Type: application/json\" \\   \n-H \"User-Agent: YOUR-USER-AGENT\" \\   \n-H \"X-Auth-Token: YOUR-API-TOKEN\" \\   \n-d '{\"os-start\" : null}' `\n\nSHELVE `ninja_vm` example: ` $ curl -g -i -X POST\nhttps://api.immers.cloud:8774/v2.1/servers/{server_id}/action \\  \n-H \"Accept: application/json\" \\   \n-H \"Content-Type: application/json\" \\   \n-H \"User-Agent: YOUR-USER-AGENT\" \\   \n-H \"X-Auth-Token: YOUR-API-TOKEN\" \\   \n-d '{\"shelve\" : null}' `\n\nDELETE `ninja_vm` example: ` $ curl -g -i -X DELETE\nhttps://api.immers.cloud:8774/v2.1/servers/{server_id} \\  \n-H \"User-Agent: YOUR-USER-AGENT\" \\   \n-H \"X-Auth-Token: YOUR-API-TOKEN\"   \n`\n\nDocumentation\n\nSignup\n\n## Any questions?\n\nWrite to us via live chat, email, or call by phone:  \n__@immerscloudsupport  \n__support@immers.cloud  \n__+7 499 110-44-94\n\n## Any questions?\n\nWrite to us via live chat, email, or call by phone:  \n__@immerscloudsupport __support@immers.cloud __+7 499 110-44-94 |  Sign up  \n---|---  \n  \n## Subscribe to our newsletter\n\nGet notifications about new promotions and special offers by email.\n\nSubscribe __\n\n I agree to the processing of personal data\n\n__Telegram support\n\n  * immers.cloud __\n  * GPU servers\n  * Tesla A100\n\n  * immers.cloud\n  * GPU instances\n  * RTX 3090\n  * RTX 3080\n  * Tesla A100\n  * RTX A5000\n  * Tesla A10\n  * RTX 2080 Ti\n  * Tesla A2\n  * Tesla T4\n  * Tesla V100\n  * CPU instances\n  * NVMe instances\n  * Dedicated servers\n  * Pre-installed images\n  * Preorder and announcements\n  * OpenStack API\n  * __\u0420\u0443\u0441\u0441\u043a\u0438\u0439\n\n  * Feedback\n  * Support\n  * Request for testing\n  * Contact\n\n  * Additionally\n  * Work in immers.cloud\n  * Migrate to the cloud\n  * Partnership\n  * About data center\n\n  * Legal information\n  * Privacy policy\n  * Terms of use\n  * Payment and refund terms\n  * Partnership program rules\n  * Certificates\n\n________\n\n\u00a9 2019\u20142023 immers.cloud platform\n\n",
    "links": "[{\"link\": \"https://en.immers.cloud/\", \"text\": \"\"}, {\"link\": \"https://en.immers.cloud/gpu/4090/\", \"text\": \"RTX 4090\"}, {\"link\": \"https://en.immers.cloud/gpu/3090/\", \"text\": \"RTX 3090\"}, {\"link\": \"https://en.immers.cloud/gpu/3080/\", \"text\": \"RTX 3080\"}, {\"link\": \"https://en.immers.cloud/gpu/a100/\", \"text\": \"Tesla A100\"}, {\"link\": \"https://en.immers.cloud/gpu/a5000/\", \"text\": \"RTX A5000\"}, {\"link\": \"https://en.immers.cloud/gpu/a10/\", \"text\": \"Tesla A10\"}, {\"link\": \"https://en.immers.cloud/gpu/2080ti/\", \"text\": \"RTX 2080 Ti\"}, {\"link\": \"https://en.immers.cloud/gpu/a2/\", \"text\": \"Tesla A2\"}, {\"link\": \"https://en.immers.cloud/gpu/t4/\", \"text\": \"Tesla T4\"}, {\"link\": \"https://en.immers.cloud/gpu/v100/\", \"text\": \"Tesla V100\"}, {\"link\": \"https://en.immers.cloud/gpu/\", \"text\": \"GPU servers\"}, {\"link\": \"https://en.immers.cloud/cpu/\", \"text\": \"SSD servers\"}, {\"link\": \"https://en.immers.cloud/cpu/nvme/\", \"text\": \"NVMe servers\"}, {\"link\": \"https://en.immers.cloud/cpu/\", \"text\": \"CPU servers\"}, {\"link\": \"https://en.immers.cloud/dedicated/\", \"text\": \"dedicated server\"}, {\"link\": \"https://en.immers.cloud/marketplace/windows/3D/\", \"text\": \"3D\"}, {\"link\": \"https://en.immers.cloud/marketplace/?search=cuda\", \"text\": \"CUDA\"}, {\"link\": \"https://en.immers.cloud/marketplace/?search=docker+ngc\", \"text\": \"Docker / NGC\"}, {\"link\": \"https://en.immers.cloud/marketplace/windows/gaming/\", \"text\": \"For games\"}, {\"link\": \"https://en.immers.cloud/marketplace/windows/\", \"text\": \"Windows images\"}, {\"link\": \"https://en.immers.cloud/marketplace/linux/\", \"text\": \"Linux images\"}, {\"link\": \"https://en.immers.cloud/marketplace/\", \"text\": \"pre-installed images\"}, {\"link\": \"https://en.immers.cloud/features/\", \"text\": \"Features\"}, {\"link\": \"https://en.immers.cloud/prices/\", \"text\": \"Prices\"}, {\"link\": \"https://en.immers.cloud/faq/\", \"text\": \"FAQ\"}, {\"link\": \"https://en.immers.cloud/contact/\", \"text\": \"Contact\"}, {\"link\": \"https://en.immers.cloud/signin/\", \"text\": \"Login\"}, {\"link\": \"https://en.immers.cloud/vm/create/?FlavorID=723\", \"text\": \"Launch\"}, {\"link\": \"https://en.immers.cloud/vm/create/?FlavorID=727\", \"text\": \"Launch\"}, {\"link\": \"https://en.immers.cloud/vm/create/?FlavorID=731\", \"text\": \"Launch\"}, {\"link\": \"https://en.immers.cloud/vm/create/?FlavorID=735\", \"text\": \"Launch\"}, {\"link\": \"https://en.immers.cloud/vm/create/?FlavorID=748\", \"text\": \"Launch\"}, {\"link\": \"https://en.immers.cloud/vm/create/?FlavorID=747\", \"text\": \"Launch\"}, {\"link\": \"https://en.immers.cloud/vm/create/?FlavorID=772\", \"text\": \"Launch\"}, {\"link\": \"https://en.immers.cloud/vm/create/?FlavorID=739\", \"text\": \"Launch\"}, {\"link\": \"https://en.immers.cloud/gpu/\", \"text\": \"GPU servers\"}, {\"link\": \"https://en.immers.cloud/marketplace/\", \"text\": \"from the Marketplace\"}, {\"link\": \"https://en.immers.cloud/signup/\", \"text\": \"Sign up\"}, {\"link\": \"https://en.immers.cloud/marketplace/\", \"text\": \"in the Marketplace\"}, {\"link\": \"https://en.immers.cloud/api/\", \"text\": \"Documentation\"}, {\"link\": \"https://en.immers.cloud/signup/\", \"text\": \"Signup\"}, {\"link\": \"https://en.immers.cloud/signup/\", \"text\": \"Sign up\"}, {\"link\": \"https://en.immers.cloud/privacy-policy/\", \"text\": \"processing\"}, {\"link\": \"https://en.immers.cloud/\", \"text\": \"\"}, {\"link\": \"https://en.immers.cloud/gpu/\", \"text\": \"GPU servers\"}, {\"link\": \"https://en.immers.cloud/gpu/\", \"text\": \"GPU instances\"}, {\"link\": \"https://en.immers.cloud/gpu/3090/\", \"text\": \"RTX 3090\"}, {\"link\": \"https://en.immers.cloud/gpu/3080/\", \"text\": \"RTX 3080\"}, {\"link\": \"https://en.immers.cloud/gpu/a100/\", \"text\": \"Tesla A100\"}, {\"link\": \"https://en.immers.cloud/gpu/a5000/\", \"text\": \"RTX A5000\"}, {\"link\": \"https://en.immers.cloud/gpu/a10/\", \"text\": \"Tesla A10\"}, {\"link\": \"https://en.immers.cloud/gpu/2080ti/\", \"text\": \"RTX 2080 Ti\"}, {\"link\": \"https://en.immers.cloud/gpu/a2/\", \"text\": \"Tesla A2\"}, {\"link\": \"https://en.immers.cloud/gpu/t4/\", \"text\": \"Tesla T4\"}, {\"link\": \"https://en.immers.cloud/gpu/v100/\", \"text\": \"Tesla V100\"}, {\"link\": \"https://en.immers.cloud/cpu/\", \"text\": \"CPU instances\"}, {\"link\": \"https://en.immers.cloud/cpu/nvme/\", \"text\": \"NVMe instances\"}, {\"link\": \"https://en.immers.cloud/dedicated/\", \"text\": \"Dedicated servers\"}, {\"link\": \"https://en.immers.cloud/marketplace/\", \"text\": \"Pre-installed images\"}, {\"link\": \"https://en.immers.cloud/announces/\", \"text\": \"Preorder and announcements\"}, {\"link\": \"https://en.immers.cloud/api/\", \"text\": \"OpenStack API\"}, {\"link\": \"https://en.immers.cloud/support/\", \"text\": \"Support\"}, {\"link\": \"https://en.immers.cloud/request-test/\", \"text\": \"Request for testing\"}, {\"link\": \"https://en.immers.cloud/contact/\", \"text\": \"Contact\"}, {\"link\": \"https://en.immers.cloud/job/\", \"text\": \"Work in immers.cloud\"}, {\"link\": \"https://en.immers.cloud/migration/\", \"text\": \"Migrate to the cloud\"}, {\"link\": \"https://en.immers.cloud/partnership/\", \"text\": \"Partnership\"}, {\"link\": \"https://en.immers.cloud/about/\", \"text\": \"About data center\"}, {\"link\": \"https://en.immers.cloud/privacy-policy/\", \"text\": \"Privacy policy\"}, {\"link\": \"https://en.immers.cloud/terms/\", \"text\": \"Terms of use\"}, {\"link\": \"https://en.immers.cloud/payments/\", \"text\": \"Payment and refund terms\"}, {\"link\": \"https://en.immers.cloud/partnership-rules/\", \"text\": \"Partnership program rules\"}, {\"link\": \"https://en.immers.cloud/certificate/\", \"text\": \"Certificates\"}]",
    "priceAndPlans": "**There is a discount from 25% to 50% on all GPU models for an advance payment\nof 1-2 months.**\n\nToggle navigation\n\n\u2122\n\n  * Products\n\nCloud servers\n\nCloud servers with per-second billing. Isolated resources will give maximum\nperformance for your project.\n\nGPU servers\n\nCloud servers with modern RTX and Tesla graphics accelerators for games,\nrendering, streaming, working with 3D graphics, artificial intelligence,\nblockchain.\n\nRTX 4090\n\nRTX 3090\n\nRTX 3080\n\nTesla A100\n\nRTX A5000\n\nTesla A10\n\nRTX 2080 Ti\n\nTesla A2\n\nTesla T4\n\nTesla V100\n\nAll GPU servers\n\nCPU servers\n\nCloud servers with high-performance Intel Xeon Gold second and third\ngenerations CPUs, available for 100% CPU time.\n\nSSD serversNVMe servers\n\nAll CPU servers\n\nDedicated servers\n\n\u0410\u0440\u0435\u043d\u0434\u0443\u0439\u0442\u0435 \u0444\u0438\u0437\u0438\u0447\u0435\u0441\u043a\u0438 \u0432\u044b\u0434\u0435\u043b\u0435\u043d\u043d\u044b\u0439 \u0441\u0435\u0440\u0432\u0435\u0440 \u043d\u0430 \u0434\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0441\u0440\u043e\u043a \u0441 \u043f\u043e\u043c\u0435\u0441\u044f\u0447\u043d\u043e\u0439 \u043e\u043f\u043b\u0430\u0442\u043e\u0439.\n\u0421\u043e\u0431\u0440\u0435\u0440\u0438\u0442\u0435 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044e \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0441\u043e\u0432\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043a\u043e\u043c\u043b\u0435\u043a\u0442\u0443\u044e\u0449\u0438\u0445: \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u043e\u0432\nIntel Xeon Gold 2-\u0433\u043e \u0438 3-\u0433\u043e \u043f\u043e\u043a\u043e\u043b\u0435\u043d\u0438\u0439, \u0434\u043e 10 \u043d\u043e\u0432\u0435\u0439\u0448\u0438\u0445 \u0432\u0438\u0434\u0435\u043e\u0443\u0441\u043a\u043e\u0440\u0438\u0442\u0435\u043b\u0435\u0439 RTX \u0438\nTesla \u0438 \u0434\u043e 8192 \u0413\u0411 RAM \u043d\u0430 \u0441\u0435\u0440\u0432\u0435\u0440, SSD- \u0438 NVMe-\u0434\u0438\u0441\u043a\u043e\u0432 \u0434\u043b\u044f \u0434\u0430\u0442\u0430-\u0446\u0435\u043d\u0442\u0440\u043e\u0432.\n\n\u0412\u044b\u0431\u0440\u0430\u0442\u044c dedicated server\n\nMarketplace\n\nUse popular and modern applications as effective tools for organizing your\nproject. Save time with pre-configured images that already have all the\nnecessary components installed.\n\nForget about manually downloading and installing the software \u2014 just deploy a\nvirtual server with a ready-made image.\n\n3DCUDA Docker / NGCFor gamesWindows imagesLinux images\n\nAll pre-installed images\n\n  * Features\n  * Prices\n  * FAQ\n  * Contact\n  * Login\n\n  * Home\n  * Cloud pricing\n\n# Cloud pricing\n\nUSD RUB EUR KZT\n\n## CPU\n\nOption | Price, hour | Price, month  \n---|---|---  \nvCPU, per core1 |  $0.0056  |  $4.03  \nRAM, per GB |  $0.0018  |  $1.29  \nCPU servers\n\n## GPU\n\nPrices:  Per hour Per month 25% discount with 30 days advance payment 35%\ndiscount with 60 days advance payment 50% discount with 60 days advance\npayment\n\nTariff prices applied only for:  Option | Price  \n---|---  \nRTX 4090 24GB PCI-E |  ~~~~ | $0.88  | $636.81  \nRTX 3090 24GB PCI-E |  ~~~~ | $0.65  | $467.53  \nRTX 3080 10GB PCI-E |  ~~~~ | $0.36  | $257.95  \nTesla A100 80GB PCI-E |  ~~~~ | $2.13  | $1 531.57  \nRTX A5000 24GB PCI-E |  ~~~~ | $0.45  | $322.44  \nTesla A10 24GB PCI-E |  ~~~~ | $0.31  | $225.71  \nRTX 2080 Ti 11GB PCI-E |  ~~~~ | $0.21  | $153.16  \nTesla A2 16GB PCI-E |  ~~~~ | $0.18  | $128.97  \nTesla T4 16GB PCI-E |  ~~~~ | $0.28  | $201.52  \nTesla V100 32GB PCI-E |  ~~~~ | $0.90  | $644.87  \nGPU servers\n\n## Storage\n\nOption | Price, hour | Price, month  \n---|---|---  \nSATA SSD (Local), per GB2 | $0.0001  | $0.08  \nNVMe SSD (Local), per GB2 |  $0.0002  |  $0.13  \nVolume (Volume-backed), per GB | \u2014 | $0.02  \nVolume SSD (Volume-backed), per GB | \u2014 | $0.10  \nSnapshot, per GB | \u2014 | $0.02  \nVolume Snapshot, per GB | Free  \n  \n## Network\n\nOption | Price, hour | Price, month  \n---|---|---  \nIP-address | $0.0017  | $1.21  \n  \n## Operating systems\n\nOption | Price, hour | Price, month  \n---|---|---  \nWindows Server 2019 Standard | $0.0840  | $60.46  \nWindows Server 2019 Datacenter edition, per core | $0.0159  | $11.41  \nWindows Server 2022 Standard | $0.0840  | $60.46  \nWindows Server 2022 Datacenter edition, per core | $0.0159  | $11.41  \n  \n  1. Isolated virtual core of 2-nd generation Intel\u00ae Xeon\u00ae Scalable (Cascade Lake) processors. Without overselling. \n  2. SATA SSD is the default option. To setup an NVMe instance choose Local instance and one of the NVMe configuration during Virtual Machine creation. \n\n__Telegram support\n\n  * immers.cloud\n  * GPU instances\n  * RTX 3090\n  * RTX 3080\n  * Tesla A100\n  * RTX A5000\n  * Tesla A10\n  * RTX 2080 Ti\n  * Tesla A2\n  * Tesla T4\n  * Tesla V100\n  * CPU instances\n  * NVMe instances\n  * Dedicated servers\n  * Pre-installed images\n  * Preorder and announcements\n  * OpenStack API\n  * __\u0420\u0443\u0441\u0441\u043a\u0438\u0439\n\n  * Feedback\n  * Support\n  * Request for testing\n  * Contact\n\n  * Additionally\n  * Work in immers.cloud\n  * Migrate to the cloud\n  * Partnership\n  * About data center\n\n  * Legal information\n  * Privacy policy\n  * Terms of use\n  * Payment and refund terms\n  * Partnership program rules\n  * Certificates\n\n________\n\n\u00a9 2019\u20142023 immers.cloud platform\n\n"
}