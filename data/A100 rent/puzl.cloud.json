{
    "summary": "\u00d7\n\nNotice\n\nWe and selected third parties use cookies or similar technologies for\ntechnical purposes and, with your consent, for other purposes as specified in\nthe cookie policy. Denying consent may make related features unavailable.\n\nUse the \u201cAccept\u201d button to consent. Use the \u201cReject\u201d button to continue\nwithout accepting.\n\nPress again to continue 0/2\n\nDetails\n\nRejectAccept\n\npuzl.cloud\n\n  * CI Runners for GitLab\n  * GPU cloud\n  * Marketplace\n  * Cloud-Native Platform Pricing\n  * Docs\n\n  * My Dashboard\n\n  * Sign Up\n\n# Ready-to-go  \ncloud GPUs\n\n* Per-second billing\n\n* Rent A100 by fractions to save costs\n\n* Run GPU in virtual machine or in container\n\nLearn more\n\n2x cheaper Nvidia A100 GPUs\n\nthan on AWS or Google Cloud\n\nLocated in the EU\n\n### Templates with popular machine learning tools\n\n### Choose the best GPU for deep learning in cloud\n\nCard| Price per hour2| FP32 (ML benchmarks score)1| FP64, TFLOPS (peak)|\nMemory, GB| CUDA cores  \n---|---|---|---|---|---  \n **\n\nA100\n\nby Puzl\n\n**| $1.60| 1| 9.7|\n\n40\n\nHBM2\n\n| 13824  \n **\n\nHalf of A100\n\nby Puzl, based on Nvidia MIG\n\n**|\n\n$0.80\n\nx0.5\n\n|\n\n0.57\n\n|\n\n4.85\n\nx0.5\n\n|\n\n20\n\nHBM2\n\n|\n\n5925\n\nx0.43  \n  \n**\n\nQuarter of A100\n\nby Puzl, based on Nvidia MIG\n\n**|\n\n$0.40\n\nx0.25\n\n|\n\n0.284\n\n|\n\n2.43\n\nx0.25\n\n|\n\n10\n\nHBM2\n\n|\n\n3950\n\nx0.29  \n  \n**\n\nA4000\n\n**|\n\n$0.46\n\nx0.29\n\n|\n\n0.347\n\n|\n\n0.6\n\nx0.06\n\n|\n\n16\n\nGDDR6\n\n|\n\n6144\n\nx0.44  \n  \n**\n\nA5000\n\n**|\n\n$0.84\n\nx0.52\n\n|\n\n0.546\n\n|\n\n0.87\n\nx0.09\n\n|\n\n24\n\nGDDR6\n\n|\n\n8192\n\nx0.59  \n  \n**Tesla T4**|\n\n$0.26\n\nx0.16\n\n|\n\n0.138\n\n|\n\n0.25\n\nx0.03\n\n|\n\n16\n\nGDDR6\n\n|\n\n2560\n\nx0.19  \n  \n**Tesla V100**|\n\n$1.17\n\nx0.73\n\n|\n\n0.415\n\n|\n\n7\n\nx0.72\n\n|\n\n16\n\nHBM2\n\n|\n\n5120\n\nx0.37  \n  \n* Benchmarks are made on instances with 1 GPU, 16GB RAM, 4vCPU and fast storage with similar IOPS and bandwidth rate.\n\n** Based on average normalized GPU score for ResNet, Inception and AlexNet\nbenchmarks. Normalization was performed to A100 score (1 is a score of A100).\n\n*** The minimum market price per 1 GPU on demand, taken from public price\nlists of popular cloud and hosting providers. Information is current as of\nFebruary 2022.\n\n**** Values for MIG based GPUs are approximate. Find more details about Nvidia\nMIG technology here.\n\n### Try new service\n\nreleased\n\nCI Runners for GitLab\n\nRequest Nvidia A100 GPUs directly from your GitLab pipelines. Turn GitLab into\nyour powerful MLOps platform!\n\nPay only for resources consumed by your pipelines.\n\nUse Nvidia A100 GPUs in your GitLab CI/CD.\n\nNo vendor lock-in: if unsatisfied, you can quickly switch to other options.\n\nExplore CI Runners\n\nGITLAB is a trademark of GitLab Inc. in the United States and other countries\nand regions.\n\nSave with committed usage\n\nCommit to consistent usage of GPU-hours and get reserved GPUs under a\ndiscounted price.\n\n-10%\n\n **1 month**  \ncommitment\n\n$1.44\n\n ~~$ 1.6~~\n\n **for 1 GPU-hour of Nvidia A100**\n\n-20%\n\n **6 months**  \ncommitment\n\n$1.28\n\n ~~$ 1.6~~\n\n **for 1 GPU-hour of Nvidia A100**\n\n-30%\n\n **2 years**  \ncommitment\n\n$1.12\n\n ~~$ 1.6~~\n\n **for 1 GPU-hour of Nvidia A100**\n\n-40%\n\n **3 years**  \ncommitment\n\n$0.96\n\n ~~$ 1.6~~\n\n **for 1 GPU-hour of Nvidia A100**\n\n### Running on professional server platforms  \nwith last generation AMD EPYC\u2122\n\nAMD EPYC\u2122 7502 3.3GHz\n\n*AMD, and the AMD Arrow logo, AMD EPYC and combinations thereof are trademarks of Advanced Micro Devices, Inc.\n\nAMD EPYC\u2122 CPU\n\nWith 2nd generation AMD processors you can allocate 196 vCPU and 10 GPU in one\ninstance.\n\nFlexible NVMe\u00ae-based data storage\n\nFast, reliable data storage for your datasets and trained models, runtime-\nextensible up to 4TB.\n\nFast ECC RAM\n\nDDR4 ECC 2.9Ghz memory with flexible allocation up to 1TB.\n\nConfigure\n\n### Zero infrastructure\n\nInstant  \nstart\n\nRun Kubernetes pods in seconds. Launch your code in containers or in virtual\nmachines.\n\nKubernetes  \nout of the box\n\nYou get full access to a separate Kubernetes namespace, pre-configured with\nall security policies needed.\n\nFair  \ncosts\n\nPay only for resources used by the running pods, no cluster maintenance fee.\n\n### Easy to deploy\n\nNo need to explore one more cloud API:  \nKubernetes is a new unified way to deploy your applications.\n\nUse DashboardUse Kubernetes API\n\n### Cloud Services\n\n###\n\n* Compute Resources\n* TCP/UDP Balancer\n* NVMe\u00ae-based Data Storage\n* Shared File System Data Storage\n* Cloud Marketplace\n* Pod Configurator\n* Resources\n\nHave questions?  \nAsk on Discord!\n\n  * Blog\n  * Documentation\n  * API\n  * Security\n\n  * Cookie Policy\n  * Privacy Policy\n  * Terms\n\n\u00a9 GPU Computing O\u00dc, 2023\n\nHarju maakond, Tallinn, Kesklinna linnaosa, Rotermanni tn 6, 10111 Estonia\n\nCompany code 14476114\n\nVAT number EE102212851\n\n",
    "links": "[{\"link\": \"https://puzl.cloud/terms/cookie-policy\", \"text\": \"cookie policy\"}, {\"link\": \"https://puzl.cloud/products/ci-runners-for-gitlab\", \"text\": \"CI Runners for GitLab\"}, {\"link\": \"https://puzl.cloud/gpu-cloud\", \"text\": \"GPU cloud\"}, {\"link\": \"https://puzl.cloud/cloud-marketplace\", \"text\": \"Marketplace\"}, {\"link\": \"https://puzl.cloud/pricing\", \"text\": \"Cloud-Native Platform Pricing\"}, {\"link\": \"https://puzl.cloud/products/ci-runners-for-gitlab\", \"text\": \"Explore CI Runners\"}, {\"link\": \"https://puzl.cloud/cloud-kubernetes/computing-resources\", \"text\": \"Compute Resources\"}, {\"link\": \"https://puzl.cloud/cloud-kubernetes/tcp-udp-balancer\", \"text\": \"TCP/UDP Balancer\"}, {\"link\": \"https://puzl.cloud/nvme-based-data-storage\", \"text\": \"\"}, {\"link\": \"https://puzl.cloud/shared-file-system-data-storage\", \"text\": \"Shared File System Data Storage\"}, {\"link\": \"https://puzl.cloud/cloud-marketplace\", \"text\": \"Cloud Marketplace\"}, {\"link\": \"https://puzl.cloud/cloud-kubernetes/configurator\", \"text\": \"Pod Configurator\"}, {\"link\": \"https://puzl.cloud/resources\", \"text\": \"Resources\"}, {\"link\": \"https://puzl.cloud/blog\", \"text\": \"Blog\"}, {\"link\": \"https://puzl.cloud/terms/cookie-policy\", \"text\": \"Cookie Policy\"}, {\"link\": \"https://puzl.cloud/terms/privacy-policy\", \"text\": \"Privacy Policy\"}, {\"link\": \"https://puzl.cloud/terms\", \"text\": \"Terms\"}]",
    "priceAndPlans": "\u00d7\n\nNotice\n\nWe and selected third parties use cookies or similar technologies for\ntechnical purposes and, with your consent, for other purposes as specified in\nthe cookie policy. Denying consent may make related features unavailable.\n\nUse the \u201cAccept\u201d button to consent. Use the \u201cReject\u201d button to continue\nwithout accepting.\n\nPress again to continue 0/2\n\nDetails\n\nRejectAccept\n\npuzl.cloud\n\n  * CI Runners for GitLab\n  * GPU cloud\n  * Marketplace\n  * Cloud-Native Platform Pricing\n  * Docs\n\n  * My Dashboard\n\n  * Sign Up\n\n# Ready-to-go  \ncloud GPUs\n\n* Per-second billing\n\n* Rent A100 by fractions to save costs\n\n* Run GPU in virtual machine or in container\n\nLearn more\n\n2x cheaper Nvidia A100 GPUs\n\nthan on AWS or Google Cloud\n\nLocated in the EU\n\n### Templates with popular machine learning tools\n\n### Choose the best GPU for deep learning in cloud\n\nCard| Price per hour2| FP32 (ML benchmarks score)1| FP64, TFLOPS (peak)|\nMemory, GB| CUDA cores  \n---|---|---|---|---|---  \n **\n\nA100\n\nby Puzl\n\n**| $1.60| 1| 9.7|\n\n40\n\nHBM2\n\n| 13824  \n **\n\nHalf of A100\n\nby Puzl, based on Nvidia MIG\n\n**|\n\n$0.80\n\nx0.5\n\n|\n\n0.57\n\n|\n\n4.85\n\nx0.5\n\n|\n\n20\n\nHBM2\n\n|\n\n5925\n\nx0.43  \n  \n**\n\nQuarter of A100\n\nby Puzl, based on Nvidia MIG\n\n**|\n\n$0.40\n\nx0.25\n\n|\n\n0.284\n\n|\n\n2.43\n\nx0.25\n\n|\n\n10\n\nHBM2\n\n|\n\n3950\n\nx0.29  \n  \n**\n\nA4000\n\n**|\n\n$0.46\n\nx0.29\n\n|\n\n0.347\n\n|\n\n0.6\n\nx0.06\n\n|\n\n16\n\nGDDR6\n\n|\n\n6144\n\nx0.44  \n  \n**\n\nA5000\n\n**|\n\n$0.84\n\nx0.52\n\n|\n\n0.546\n\n|\n\n0.87\n\nx0.09\n\n|\n\n24\n\nGDDR6\n\n|\n\n8192\n\nx0.59  \n  \n**Tesla T4**|\n\n$0.26\n\nx0.16\n\n|\n\n0.138\n\n|\n\n0.25\n\nx0.03\n\n|\n\n16\n\nGDDR6\n\n|\n\n2560\n\nx0.19  \n  \n**Tesla V100**|\n\n$1.17\n\nx0.73\n\n|\n\n0.415\n\n|\n\n7\n\nx0.72\n\n|\n\n16\n\nHBM2\n\n|\n\n5120\n\nx0.37  \n  \n* Benchmarks are made on instances with 1 GPU, 16GB RAM, 4vCPU and fast storage with similar IOPS and bandwidth rate.\n\n** Based on average normalized GPU score for ResNet, Inception and AlexNet\nbenchmarks. Normalization was performed to A100 score (1 is a score of A100).\n\n*** The minimum market price per 1 GPU on demand, taken from public price\nlists of popular cloud and hosting providers. Information is current as of\nFebruary 2022.\n\n**** Values for MIG based GPUs are approximate. Find more details about Nvidia\nMIG technology here.\n\n### Try new service\n\nreleased\n\nCI Runners for GitLab\n\nRequest Nvidia A100 GPUs directly from your GitLab pipelines. Turn GitLab into\nyour powerful MLOps platform!\n\nPay only for resources consumed by your pipelines.\n\nUse Nvidia A100 GPUs in your GitLab CI/CD.\n\nNo vendor lock-in: if unsatisfied, you can quickly switch to other options.\n\nExplore CI Runners\n\nGITLAB is a trademark of GitLab Inc. in the United States and other countries\nand regions.\n\nSave with committed usage\n\nCommit to consistent usage of GPU-hours and get reserved GPUs under a\ndiscounted price.\n\n-10%\n\n **1 month**  \ncommitment\n\n$1.44\n\n ~~$ 1.6~~\n\n **for 1 GPU-hour of Nvidia A100**\n\n-20%\n\n **6 months**  \ncommitment\n\n$1.28\n\n ~~$ 1.6~~\n\n **for 1 GPU-hour of Nvidia A100**\n\n-30%\n\n **2 years**  \ncommitment\n\n$1.12\n\n ~~$ 1.6~~\n\n **for 1 GPU-hour of Nvidia A100**\n\n-40%\n\n **3 years**  \ncommitment\n\n$0.96\n\n ~~$ 1.6~~\n\n **for 1 GPU-hour of Nvidia A100**\n\n### Running on professional server platforms  \nwith last generation AMD EPYC\u2122\n\nAMD EPYC\u2122 7502 3.3GHz\n\n*AMD, and the AMD Arrow logo, AMD EPYC and combinations thereof are trademarks of Advanced Micro Devices, Inc.\n\nAMD EPYC\u2122 CPU\n\nWith 2nd generation AMD processors you can allocate 196 vCPU and 10 GPU in one\ninstance.\n\nFlexible NVMe\u00ae-based data storage\n\nFast, reliable data storage for your datasets and trained models, runtime-\nextensible up to 4TB.\n\nFast ECC RAM\n\nDDR4 ECC 2.9Ghz memory with flexible allocation up to 1TB.\n\nConfigure\n\n### Zero infrastructure\n\nInstant  \nstart\n\nRun Kubernetes pods in seconds. Launch your code in containers or in virtual\nmachines.\n\nKubernetes  \nout of the box\n\nYou get full access to a separate Kubernetes namespace, pre-configured with\nall security policies needed.\n\nFair  \ncosts\n\nPay only for resources used by the running pods, no cluster maintenance fee.\n\n### Easy to deploy\n\nNo need to explore one more cloud API:  \nKubernetes is a new unified way to deploy your applications.\n\nUse DashboardUse Kubernetes API\n\n### Cloud Services\n\n###\n\n* Compute Resources\n* TCP/UDP Balancer\n* NVMe\u00ae-based Data Storage\n* Shared File System Data Storage\n* Cloud Marketplace\n* Pod Configurator\n* Resources\n\nHave questions?  \nAsk on Discord!\n\n  * Blog\n  * Documentation\n  * API\n  * Security\n\n  * Cookie Policy\n  * Privacy Policy\n  * Terms\n\n\u00a9 GPU Computing O\u00dc, 2023\n\nHarju maakond, Tallinn, Kesklinna linnaosa, Rotermanni tn 6, 10111 Estonia\n\nCompany code 14476114\n\nVAT number EE102212851\n\n"
}