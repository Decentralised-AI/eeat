{
    "summary": "MENU\n\n  * Research\n\nResearch\n\n    * AI Use Cases\n    * Blockchain Use Cases\n    * Conversational AI\n    * Data Cleaning\n    * Data Collection\n    * Digital Transformation\n    * IoT\n    * AutoML\n    * Quantum Computing\n    * Process Mining\n    * Robotic Process Automation (RPA)\n    * Synthetic Data\n    * All\n\n  * Solutions\n\nSolutions\n\n    * Conversational AI\n    * Data Collection\n    * Process Mining\n    * Recommendation Engines\n    * RPA\n    * Synthetic Data\n    * Web Data\n    * All\n\n  * Guides\n\nGuides\n\n    * Proxy Services\n    * Shortlist Vendors\n\n  * For Vendors\n\nFor Vendors\n\n    * Claim Your Solution\n    * Identify Top Channels in Your Domain\n\n  * Research __\n    * AI Use Cases\n    * Blockchain Use Cases\n    * Conversational AI\n    * Data Cleaning\n    * Data Collection\n    * Digital Transformation\n    * IoT\n    * AutoML\n    * Quantum Computing\n    * Process Mining\n    * Robotic Process Automation (RPA)\n    * Synthetic Data\n    * All\n  * Solutions __\n    * Conversational AI\n    * Data Collection\n    * Process Mining\n    * Recommendation Engines\n    * RPA\n    * Synthetic Data\n    * Web Data\n    * All\n  * Guides __\n    * Proxy Services\n    * Shortlist Vendors\n  * For Vendors __\n    * Claim Your Solution\n    * Identify Top Channels in Your Domain\n  * \n\nAccelerator\n\n# Cloud GPUs for Deep Learning: Availability& Price / Performance\n\nUpdated on **November 26, 2023**     |     6 minute read\n\nUpdated on **November 26, 2023**  \n6 minute read\n\nAuthor  \n**Cem Dilmegani**\n\nTable of contents  \n\n  * Cloud GPU price per throughput\n  * Cloud GPU availability in different clouds\n  * Other cloud GPU considerations\n  * Buy GPUs or rent cloud GPUs\n  * What are the top cloud GPU hardware?\n  * What are the top cloud GPU platforms?\n  * What is a cloud GPU?\n  * What are the functions/application areas of cloud GPUs?\n  * Notes\n\nShare article  \n\nIf you are flexible about the GPU model, identify the most cost-effective\ncloud GPU\n\nIf you prefer a specific model (e.g. A100), identify the GPU cloud providers\noffering it.\n\nIf undecided between on-prem and the cloud, explore whether to buy or rent\nGPUs on the cloud.\n\n## Cloud GPU price per throughput\n\nTwo common pricing models for GPUs are \u201con-demand\u201d and \u201cspot\u201d instances.\n\n### On-demand GPUs from big tech cloud providers\n\nThis is the most straightforward pricing model where you pay for the compute\ncapacity by the hour or second, depending on what you use with no long-term\ncommitments or upfront payments. These instances are recommended for users who\nprefer the flexibility of a cloud GPU platform without any up-front payment or\nlong-term commitment. On-demand instances are usually more expensive than spot\ninstances, but they provide guaranteed uninterrupted capacity.\n\nShow 102550100 entries\n\nSearch:\n\nCloud| GPU Type / Memory*| # of GPUs| On-demand $| Throughput**| Throughput**\n/ $***  \n---|---|---|---|---|---  \nAzure| A100 / 80 GB| 1| 3.67| 232| 63  \nAzure| A100 / 80 GB| 4| 14.69| 821| 56  \nAzure| A100 / 80 GB| 2| 7.35| 406| 55  \nGCP| A100 / 40 GB| 1| 3.67| 179| 49  \nAzure| A100 / 80 GB| 8| 37.18| 1,362| 37  \nAWS| A100 / 80 GB| 8| 40.97| 1,362| 33  \nGCP| V100 / 16 GB| 1| 2.95| 42| 14  \nAWS| V100 / 16 GB| 1| 3.06| 42| 14  \nAzure| V100 / 16 GB| 1| 3.06| 42| 14  \nGCP| V100 / 16 GB| 2| 5.91| 77| 13  \n  \nShowing 1 to 10 of 16 entries\n\nPrevious12Next\n\n* Memory and GPU model are not the only parameters. CPUs and RAM can also be important, however, they are not the primary criteria that shape cloud GPU performance. Therefore, for simplicity, we have not included number of CPUs or RAM in these tables.\n\n** **Training throughput** is a good metric to measure relative GPU\neffectiveness. It measures the number of tokens processed per second by the\nGPU for a language model (i.e. bert_base_squad).1Go to footnote Please note\nthat these throughput values should serve as high level guidelines. The same\nhardware would have a significantly different throughput for your workload\nsince there is significant throughput difference even between LLMs running on\nthe same hardware.2Go to footnote\n\n*** **Excludes cost of storage, network performance, ingress/egress** etc.\nThis is only the GPU cost.3Go to footnote\n\n### On-demand GPUs from other cloud providers\n\nShow 102550100 entries\n\nSearch:\n\nCloud| GPU Type / Memory*| # of GPUs| On-demand $| Throughput**| Throughput**\n/ $***  \n---|---|---|---|---|---  \nSeeweb| RTX A6000 / 48 GB| 2| 1.480| 179| 121  \nLatitude.sh| H100 (80 GB)| 8| 35.2| 2,693| 77  \nTensorDock| A100 / 80 GB| 4| 1.200| 821| 684  \nVast.ai| V100 / 16 GB| 8| 0.944| 289| 306  \nVast.ai| V100 / 16 GB| 2| 0.358| 77| 215  \nTensorDock| A100 / 80 GB| 1| 1.200| 232| 193  \nTensorDock| V100 / 16 GB| 1| 0.220| 42| 191  \nTensorDock| A100 / 80 GB| 1| 1.400| 232| 165  \nJarvislabs| A100 / 40 GB| 1| 1.1| 179| 163  \nLambda| A100 / 40 GB| 1| 1.1| 179| 163  \n  \nShowing 1 to 10 of 81 entries\n\nPrevious12345\u20269Next\n\n### Spot GPUs\n\nShow 102550100 entries\n\nSearch:\n\nCloud| GPU Type / Memory*| # of GPUs| Spot| Throughput**| Throughput** / $***  \n---|---|---|---|---|---  \nAzure| A100 / 80 GB| 1| 0.76| 232| 303  \nAzure| A100 / 80 GB| 4| 3.05| 821| 269  \nAzure| A100 / 80 GB| 2| 1.53| 406| 266  \nJarvislabs| A100 / 40 GB| 1| 0.79| 179| 227  \nGCP| A100 / 40 GB| 1| 1.62| 179| 111  \nAWS| V100 / 16 GB| 1| 0.92| 42| 46  \nAWS| V100 / 16 GB| 4| 3.67| 153| 42  \nAzure| V100 / 16 GB| 1| 1.04| 42| 40  \nAWS| V100 / 16 GB| 8| 7.34| 289| 39  \nAzure| V100 / 16 GB| 2| 2.08| 77| 37  \n  \nShowing 1 to 10 of 11 entries\n\nPrevious12Next\n\nIn all these throughput per dollar tables:\n\n  * Not all possible configurations are listed, more commonly used, deep learning focused configurations are included.\n  * West or Central US regions were used where possible\n  * These are the list prices for each category, high volume buyers can possibly get better pricing\n\nFinally, it is good to clarify what \u201cspot\u201d means. Spot resources are:\n\n\u2013 **Interruptible** so users need to keep on recording their progress. For\nexample, Amazon EC2 P3, which provides V100 32 GB, is one of the most\nfrequently interrupted Amazon spot services.4Go to footnote\n\n\u2013 **Offered on a dynamic, market-driven basis**. The price for these GPU\nresources can fluctuate based on supply and demand, and users typically bid on\nthe available spot capacity. If a user\u2019s bid is higher than the current spot\nprice, their requested instances will run.\n\n## Cloud GPU availability in different clouds\n\nInput the model that you want in the search box to identify all cloud\nproviders that offer it:\n\nShow 102550100 entries\n\nSearch:\n\nProvider| GPU| Multi-GPU| On-demand $ per single GPU hour***  \n---|---|---|---  \nLatitude.sh| H100 (80 GB)| 1, 4, 8x| 4.40  \nLatitude.sh| A100 (80 GB)| 8x| 23.2  \nSeeweb| RTXA6000 (48 GB)| 1, 2, 3, 4, 5x| 0.74  \nSeeweb| RTXA6000 (24 GB)| 1, 2, 3, 4, 5x| 0.64  \nSeeweb| A30 (24 GB)| 1, 2, 3, 4, 5x| 0.64  \nSeeweb| L4 (24 GB)| 1, 2, 3, 4, 5x| 0.38  \nSeeweb| A100 (80 GB)| 1, 2, 3, 4, 5x| 2.22  \nAWS| M60 8 GB| 1, 2, 4x| 1.14  \nAWS| T4 16 GB| 1, 2, 4, 8x| 1.20  \nAWS| A10G 24 GB| 1, 4, 8x| 1.62  \n  \nShowing 1 to 10 of 116 entries\n\nPrevious12345\u202612Next\n\n**** Computed values. This was needed when single GPU instances were not\navailable.5Go to footnote 6Go to footnote\n\n## Other cloud GPU considerations\n\n**Availability** : Not all GPUs listed above may be available due to capacity\nconstraints of the cloud providers and increasing demand for generative AI.\n\n**Data security** : For example, cloud GPU marketplaces like Vast.ai offer\nsignificantly lower prices but depending on the specific resource requested,\nthe data security of the workload could be impacted, givings hosts the\ncapability to access workloads. Since we prioritized enterprise GPU needs,\nVast.ai wasn\u2019t included in this benchmark.\n\n**Ease of use** : Documentation quality is a subjective metric but developers\nprefer some cloud providers\u2019 documentation over others. In this discussion,\nGCP\u2019s documentation was mentioned as lower quality than other tech giants\u2019.7Go\nto footnote\n\n**Familiarity** : Even though cloud providers put significant effort into\nmaking their services easy-to-use, there is a learning curve. That is why\nmajor cloud providers have certifications systems in place. Therefore, for\nsmall workloads, the cost savings of using a low cost provider may be less\nthan the opportunity cost of the time it takes a developer to learn how to use\ntheir cloud GPU offering.\n\n## Buy GPUs or rent cloud GPUs\n\nBuying makes sense\n\n\u2013 If your company has the know-how and preference to **host the servers or\nmanage colocated servers**.\n\n\u2013 For **uninterruptible workloads** : For the volume of GPUs for which you can\nensure a high utilization (e.g. more than 80%) for a year or more.8Go to\nfootnote\n\n\u2013 For **interruptible workloads** : The high utilization period quoted above\nneeds to be a few times longer since on-demand (uninterruptible computing)\nprices tends to be a few times more expensive than spot (interruptible\ncomputing) prices.\n\nOur recommendation for businesses with heavy GPU workloads is a mix of owned\nand rented GPUs where guaranteed demand runs on owned GPUs and variable demand\nruns on the cloud. This is why tech giants like Facebook are building their\nown GPU clusters including hundreds of GPUs.9Go to footnote\n\nBuyers may be tempted to consider consumer GPUs which offer a better\nprice/performance ratio however, the EULA of their software prohibits their\nuse in data centers.10Go to footnote Therefore, they are not a good fit for\nmachine learning except for minor testing workloads on data scientists\u2019\nmachines.\n\n## What are the top cloud GPU hardware?\n\nAlmost all cloud GPUs use Nvidia GPU instances. AMD and other providers also\noffer GPUs however due to various reasons (e.g. limited developer adoption,\nlower price per performance etc.), their GPUs are not as widely demanded as\nNvidia GPUs.\n\nTo see cloud GPU providers that offer non-Nvidia GPUs, please check out the\ncomprehensive list of cloud GPU providers.\n\nRead about all AI chips / hardware.\n\n## What are the top cloud GPU platforms?\n\nTop cloud GPU providers are:\n\n  * AWS\n  * Microsoft Azure\n  * CoreWeave\n  * Google Cloud Platform (GCP)\n  * IBM Cloud\n  * Jarvis Labs\n  * Lambda Labs\n  * NVIDIA DGX Cloud\n  * Oracle Cloud Infrastructure (OCI)\n  * Paperspace CORE\n\nFor more on these providers, check out cloud gpu providers.\n\nIf you are unclear about what cloud GPUs are, here is more context:\n\n## What is a cloud GPU?\n\nUnlike a CPU, which may have a relatively small number of cores optimized for\nsequential serial processing, a GPU can have hundreds or even thousands of\nsmaller cores designed for multi-threading and handling parallel processing\nworkloads.\n\nA cloud GPU refers to a certain way of GPU usage that\u2019s provided as a service\nthrough cloud computing platforms. Much like traditional cloud services, a\ncloud gpu allows you to access high-performance computing resources spot or\non-demand, without the need for upfront capital investment in hardware.\n\n## What are the functions/application areas of cloud GPUs?\n\nCloud GPUs are primarily used for processing tasks that require high\ncomputational power. Here are some of the primary uses for cloud GPUs:\n\n### Machine Learning and AI\n\nGPUs are particularly effective at handling the complex calculations required\nfor machine learning (ML) and artificial intelligence (AI) models. They can\nprocess multiple computations in parallel, making them suitable for training\nlarge neural networks and algorithms.\n\n#### Deep learning\n\nDeep learning is a sub-field of machine learning. Deep learning algorithms\ngreatly benefit from the parallel processing capabilities of GPUs, making\ntraining and inference faster and more efficient.\n\n### Data processing\n\n#### Data analysis\n\nGPUs are used to accelerate computing and data processing tasks, such as Big\nData analysis and real-time analytics. They can handle high-throughput,\nparallel processing tasks more efficiently than CPUs.\n\n#### Scientific computing\n\nIn scientific research, cloud GPUs can handle computations for simulations,\nbioinformatics, quantum chemistry, weather modeling, and more.\n\n#### Simulations\n\nCertain complex simulations can run more efficiently on GPUs.\n\n### Gaming & entertainment\n\nCloud GPUs are used to provide cloud gaming services, such as Google\u2019s Stadia\nor NVIDIA\u2019s GeForce Now, where the game runs on a server in the cloud, and the\nrendered frames are streamed to the player\u2019s device. This allows high-quality\ngaming without the need for a powerful local machine.\n\n#### Graphics rendering\n\nGPUs were initially designed to handle computer graphics, and they still excel\nin this area. Cloud GPUs are used for 3D modeling and rendering, 3D\nvisualizations, virtual reality (VR), computer-aided design (CAD), and\ncomputer-generated imagery (CGI).\n\n#### Video processing\n\nThey\u2019re used in video encoding and decoding, video editing, color correction,\neffects rendering, and other video processing tasks.\n\n### Cryptocurrency mining\n\nGPUs are also used in tasks like cryptocurrency mining. However application-\nspecific integrated circuits (ASICs) are offering better economics for more\ncommonly mined crypto currencies.\n\n## Notes\n\nCloud providers are constantly updating their offering, part of this research\ncould be outdated.\n\nAIMultiple\u2019s research is sponsored by cloud GPU providers. Sponsors can be\nidentified by links to their websites and they are ranked at the top of lists\nthat they participate in.\n\n### External links\n\n  1. Deep Learning GPU Benchmarks, Lambda Labs, Retrieved July 15, 2023\n  2. Open LLM-Perf Leaderboard, Hugging Face, Retrieved July 15, 2023\n  3. \u201cthe-full-stack/website/docs/cloud-gpus\u201c, _GitHub_ , Retrieved July 15, 2023\n  4. Spot Instance advisor, _Amazon_ , Retrieved July 19, 2023\n  5. The Ultimate Guide to Cloud GPU Providers, _Paperspace_ , Retrieved July 15, 2023\n  6. CloudOptimizer, _CloudOptimizer_ , Retrieved July 15, 2023\n  7. Cloud GPU Resources and Pricing, _Hacker News_ , Retrieved July 16, 2023\n  8. Cloud GPU Resources and Pricing, _Hacker News_ , Retrieved July 16, 2023\n  9. Meta Works with NVIDIA to Build Massive AI Research Supercomputer, _Nvidia_ , Retrieved July 16, 2023\n  10. License For Customer Use of NVIDIA GeForce Software, _Nvidia_ , Retrieved July 16, 2023\n\n  \n  \n\nShare on **LinkedIn**\n\nShare on **Twitter**\n\nCem Dilmegani\n\nCem has been the principal analyst at AIMultiple since 2017. AIMultiple\ninforms hundreds of thousands of businesses (as per similarWeb) including 60%\nof Fortune 500 every month.  \n  \nCem's work has been cited by leading global publications including Business\nInsider, Forbes, Washington Post, global firms like Deloitte, HPE, NGOs like\nWorld Economic Forum and supranational organizations like European Commission.\nYou can see more reputable companies and media that referenced AIMultiple.  \n  \nThroughout his career, Cem served as a tech consultant, tech buyer and tech\nentrepreneur. He advised enterprises on their technology decisions at McKinsey\n& Company and Altman Solon for more than a decade. He also published a\nMcKinsey report on digitalization.  \n  \nHe led technology strategy and procurement of a telco while reporting to the\nCEO. He has also led commercial growth of deep tech company Hypatos that\nreached a 7 digit annual recurring revenue and a 9 digit valuation from 0\nwithin 2 years. Cem's work in Hypatos was covered by leading technology\npublications like TechCrunch and Business Insider.  \n  \nCem regularly speaks at international technology conferences. He graduated\nfrom Bogazici University as a computer engineer and holds an MBA from Columbia\nBusiness School.\n\n**RELATED RESEARCH**  \n\nAccelerator\n\n### Top 10 Serverless GPUs: A comprehensive vendor selection\n\nAccelerator\n\n### Top 10 Cloud GPU Providers in 2023\n\nAccelerator\n\n### What is Accelerated Computing? Benefits & Use Cases in 2023\n\n**Leave a Reply**  \nYOUR EMAIL ADDRESS WILL NOT BE PUBLISHED. REQUIRED FIELDS ARE MARKED *  \n  \nComment *  \n  \nPOST COMMENT\n\n#### 0 Comments\n\nStay up-to-date on B2B Tech\n\n**Cem Dilmegani**  \nPrincipal Analyst\n\nFollow on\n\nSubscribe to the latest news &  \nupdates from our experts  \n  \nBy checking this box, you confirm that you have read and agreed to our terms\nand conditions.\n\nSolutions RPA Data Annotation Process Mining Recommendation Engine Voice Bots\nAll\n\nFor Tech Users Shortlist Solutions Get Advice\n\nVendors Claim Your Product Learn Best Practices\n\nInvestors Identify Hidden Gems Tech Firms By Country Tech Firms By City\n\nAIMultiple Mission About Career Contact LinkedIn Twitter\n\nBusinesses face the most complex technology landscape. To solve a single\nproblem, firms can leverage hundreds of solution categories with hundreds of\nvendors in each category. We bring transparency and data-driven decision\nmaking to emerging tech procurement of enterprises. Use our vendor lists or\nresearch articles to identify how technologies like AI / machine learning /\ndata science, IoT, process mining, RPA, synthetic data can transform your\nbusiness.  \nData-driven, Transparent, Practical New Tech Industry Analysis  \n  \nTerms of Use \\- Privacy Policy  \n  \n\u00a9 Copyright 2023 AIMultiple\n\nX\n\n",
    "links": "[{\"link\": \"https://research.aimultiple.com/\", \"text\": \"\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/#cloud-gpu-price-per-throughput\", \"text\": \"Cloud GPU price per throughput\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/#cloud-gpu-availability-in-different-clouds\", \"text\": \"Cloud GPU availability in different clouds\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/#other-cloud-gpu-considerations\", \"text\": \"Other cloud GPU considerations\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/#buy-gpus-or-rent-cloud-gpus\", \"text\": \"Buy GPUs or rent cloud GPUs\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/#what-are-the-top-cloud-gpu-hardware\", \"text\": \"What are the top cloud GPU hardware?\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/#what-are-the-top-cloud-gpu-platforms\", \"text\": \"What are the top cloud GPU platforms?\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/#what-is-a-cloud-gpu\", \"text\": \"What is a cloud GPU?\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/#what-are-the-functions-application-areas-of-cloud-gpus\", \"text\": \"What are the functions/application areas of cloud GPUs?\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/#notes\", \"text\": \"Notes\"}, {\"link\": \"https://www.linkedin.com/sharing/share-offsite/?url=https://research.aimultiple.com/cloud-gpu/\", \"text\": \"\"}, {\"link\": \"https://twitter.com/share?url=https://research.aimultiple.com/cloud-gpu/\", \"text\": \"\"}, {\"link\": \"https://research.aimultiple.com/cloud-gpu/\", \"text\": \"\"}, {\"link\": \"https://research.aimultiple.com/\", \"text\": \"\"}, {\"link\": \"https://research.aimultiple.com/category/vendors/\", \"text\": \"Learn Best Practices\"}, {\"link\": \"https://research.aimultiple.com/vc-database/\", \"text\": \"Identify Hidden Gems\"}]",
    "priceAndPlans": "MENU\n\n  * Research\n\nResearch\n\n    * AI Use Cases\n    * Blockchain Use Cases\n    * Conversational AI\n    * Data Cleaning\n    * Data Collection\n    * Digital Transformation\n    * IoT\n    * AutoML\n    * Quantum Computing\n    * Process Mining\n    * Robotic Process Automation (RPA)\n    * Synthetic Data\n    * All\n\n  * Solutions\n\nSolutions\n\n    * Conversational AI\n    * Data Collection\n    * Process Mining\n    * Recommendation Engines\n    * RPA\n    * Synthetic Data\n    * Web Data\n    * All\n\n  * Guides\n\nGuides\n\n    * Proxy Services\n    * Shortlist Vendors\n\n  * For Vendors\n\nFor Vendors\n\n    * Claim Your Solution\n    * Identify Top Channels in Your Domain\n\n  * Research __\n    * AI Use Cases\n    * Blockchain Use Cases\n    * Conversational AI\n    * Data Cleaning\n    * Data Collection\n    * Digital Transformation\n    * IoT\n    * AutoML\n    * Quantum Computing\n    * Process Mining\n    * Robotic Process Automation (RPA)\n    * Synthetic Data\n    * All\n  * Solutions __\n    * Conversational AI\n    * Data Collection\n    * Process Mining\n    * Recommendation Engines\n    * RPA\n    * Synthetic Data\n    * Web Data\n    * All\n  * Guides __\n    * Proxy Services\n    * Shortlist Vendors\n  * For Vendors __\n    * Claim Your Solution\n    * Identify Top Channels in Your Domain\n  * \n\nAccelerator\n\n# Cloud GPUs for Deep Learning: Availability& Price / Performance\n\nUpdated on **November 26, 2023**     |     6 minute read\n\nUpdated on **November 26, 2023**  \n6 minute read\n\nAuthor  \n**Cem Dilmegani**\n\nTable of contents  \n\n  * Cloud GPU price per throughput\n  * Cloud GPU availability in different clouds\n  * Other cloud GPU considerations\n  * Buy GPUs or rent cloud GPUs\n  * What are the top cloud GPU hardware?\n  * What are the top cloud GPU platforms?\n  * What is a cloud GPU?\n  * What are the functions/application areas of cloud GPUs?\n  * Notes\n\nShare article  \n\nIf you are flexible about the GPU model, identify the most cost-effective\ncloud GPU\n\nIf you prefer a specific model (e.g. A100), identify the GPU cloud providers\noffering it.\n\nIf undecided between on-prem and the cloud, explore whether to buy or rent\nGPUs on the cloud.\n\n## Cloud GPU price per throughput\n\nTwo common pricing models for GPUs are \u201con-demand\u201d and \u201cspot\u201d instances.\n\n### On-demand GPUs from big tech cloud providers\n\nThis is the most straightforward pricing model where you pay for the compute\ncapacity by the hour or second, depending on what you use with no long-term\ncommitments or upfront payments. These instances are recommended for users who\nprefer the flexibility of a cloud GPU platform without any up-front payment or\nlong-term commitment. On-demand instances are usually more expensive than spot\ninstances, but they provide guaranteed uninterrupted capacity.\n\nShow 102550100 entries\n\nSearch:\n\nCloud| GPU Type / Memory*| # of GPUs| On-demand $| Throughput**| Throughput**\n/ $***  \n---|---|---|---|---|---  \nAzure| A100 / 80 GB| 1| 3.67| 232| 63  \nAzure| A100 / 80 GB| 4| 14.69| 821| 56  \nAzure| A100 / 80 GB| 2| 7.35| 406| 55  \nGCP| A100 / 40 GB| 1| 3.67| 179| 49  \nAzure| A100 / 80 GB| 8| 37.18| 1,362| 37  \nAWS| A100 / 80 GB| 8| 40.97| 1,362| 33  \nGCP| V100 / 16 GB| 1| 2.95| 42| 14  \nAWS| V100 / 16 GB| 1| 3.06| 42| 14  \nAzure| V100 / 16 GB| 1| 3.06| 42| 14  \nGCP| V100 / 16 GB| 2| 5.91| 77| 13  \n  \nShowing 1 to 10 of 16 entries\n\nPrevious12Next\n\n* Memory and GPU model are not the only parameters. CPUs and RAM can also be important, however, they are not the primary criteria that shape cloud GPU performance. Therefore, for simplicity, we have not included number of CPUs or RAM in these tables.\n\n** **Training throughput** is a good metric to measure relative GPU\neffectiveness. It measures the number of tokens processed per second by the\nGPU for a language model (i.e. bert_base_squad).1Go to footnote Please note\nthat these throughput values should serve as high level guidelines. The same\nhardware would have a significantly different throughput for your workload\nsince there is significant throughput difference even between LLMs running on\nthe same hardware.2Go to footnote\n\n*** **Excludes cost of storage, network performance, ingress/egress** etc.\nThis is only the GPU cost.3Go to footnote\n\n### On-demand GPUs from other cloud providers\n\nShow 102550100 entries\n\nSearch:\n\nCloud| GPU Type / Memory*| # of GPUs| On-demand $| Throughput**| Throughput**\n/ $***  \n---|---|---|---|---|---  \nSeeweb| RTX A6000 / 48 GB| 2| 1.480| 179| 121  \nLatitude.sh| H100 (80 GB)| 8| 35.2| 2,693| 77  \nTensorDock| A100 / 80 GB| 4| 1.200| 821| 684  \nVast.ai| V100 / 16 GB| 8| 0.944| 289| 306  \nVast.ai| V100 / 16 GB| 2| 0.358| 77| 215  \nTensorDock| A100 / 80 GB| 1| 1.200| 232| 193  \nTensorDock| V100 / 16 GB| 1| 0.220| 42| 191  \nTensorDock| A100 / 80 GB| 1| 1.400| 232| 165  \nJarvislabs| A100 / 40 GB| 1| 1.1| 179| 163  \nLambda| A100 / 40 GB| 1| 1.1| 179| 163  \n  \nShowing 1 to 10 of 81 entries\n\nPrevious12345\u20269Next\n\n### Spot GPUs\n\nShow 102550100 entries\n\nSearch:\n\nCloud| GPU Type / Memory*| # of GPUs| Spot| Throughput**| Throughput** / $***  \n---|---|---|---|---|---  \nAzure| A100 / 80 GB| 1| 0.76| 232| 303  \nAzure| A100 / 80 GB| 4| 3.05| 821| 269  \nAzure| A100 / 80 GB| 2| 1.53| 406| 266  \nJarvislabs| A100 / 40 GB| 1| 0.79| 179| 227  \nGCP| A100 / 40 GB| 1| 1.62| 179| 111  \nAWS| V100 / 16 GB| 1| 0.92| 42| 46  \nAWS| V100 / 16 GB| 4| 3.67| 153| 42  \nAzure| V100 / 16 GB| 1| 1.04| 42| 40  \nAWS| V100 / 16 GB| 8| 7.34| 289| 39  \nAzure| V100 / 16 GB| 2| 2.08| 77| 37  \n  \nShowing 1 to 10 of 11 entries\n\nPrevious12Next\n\nIn all these throughput per dollar tables:\n\n  * Not all possible configurations are listed, more commonly used, deep learning focused configurations are included.\n  * West or Central US regions were used where possible\n  * These are the list prices for each category, high volume buyers can possibly get better pricing\n\nFinally, it is good to clarify what \u201cspot\u201d means. Spot resources are:\n\n\u2013 **Interruptible** so users need to keep on recording their progress. For\nexample, Amazon EC2 P3, which provides V100 32 GB, is one of the most\nfrequently interrupted Amazon spot services.4Go to footnote\n\n\u2013 **Offered on a dynamic, market-driven basis**. The price for these GPU\nresources can fluctuate based on supply and demand, and users typically bid on\nthe available spot capacity. If a user\u2019s bid is higher than the current spot\nprice, their requested instances will run.\n\n## Cloud GPU availability in different clouds\n\nInput the model that you want in the search box to identify all cloud\nproviders that offer it:\n\nShow 102550100 entries\n\nSearch:\n\nProvider| GPU| Multi-GPU| On-demand $ per single GPU hour***  \n---|---|---|---  \nLatitude.sh| H100 (80 GB)| 1, 4, 8x| 4.40  \nLatitude.sh| A100 (80 GB)| 8x| 23.2  \nSeeweb| RTXA6000 (48 GB)| 1, 2, 3, 4, 5x| 0.74  \nSeeweb| RTXA6000 (24 GB)| 1, 2, 3, 4, 5x| 0.64  \nSeeweb| A30 (24 GB)| 1, 2, 3, 4, 5x| 0.64  \nSeeweb| L4 (24 GB)| 1, 2, 3, 4, 5x| 0.38  \nSeeweb| A100 (80 GB)| 1, 2, 3, 4, 5x| 2.22  \nAWS| M60 8 GB| 1, 2, 4x| 1.14  \nAWS| T4 16 GB| 1, 2, 4, 8x| 1.20  \nAWS| A10G 24 GB| 1, 4, 8x| 1.62  \n  \nShowing 1 to 10 of 116 entries\n\nPrevious12345\u202612Next\n\n**** Computed values. This was needed when single GPU instances were not\navailable.5Go to footnote 6Go to footnote\n\n## Other cloud GPU considerations\n\n**Availability** : Not all GPUs listed above may be available due to capacity\nconstraints of the cloud providers and increasing demand for generative AI.\n\n**Data security** : For example, cloud GPU marketplaces like Vast.ai offer\nsignificantly lower prices but depending on the specific resource requested,\nthe data security of the workload could be impacted, givings hosts the\ncapability to access workloads. Since we prioritized enterprise GPU needs,\nVast.ai wasn\u2019t included in this benchmark.\n\n**Ease of use** : Documentation quality is a subjective metric but developers\nprefer some cloud providers\u2019 documentation over others. In this discussion,\nGCP\u2019s documentation was mentioned as lower quality than other tech giants\u2019.7Go\nto footnote\n\n**Familiarity** : Even though cloud providers put significant effort into\nmaking their services easy-to-use, there is a learning curve. That is why\nmajor cloud providers have certifications systems in place. Therefore, for\nsmall workloads, the cost savings of using a low cost provider may be less\nthan the opportunity cost of the time it takes a developer to learn how to use\ntheir cloud GPU offering.\n\n## Buy GPUs or rent cloud GPUs\n\nBuying makes sense\n\n\u2013 If your company has the know-how and preference to **host the servers or\nmanage colocated servers**.\n\n\u2013 For **uninterruptible workloads** : For the volume of GPUs for which you can\nensure a high utilization (e.g. more than 80%) for a year or more.8Go to\nfootnote\n\n\u2013 For **interruptible workloads** : The high utilization period quoted above\nneeds to be a few times longer since on-demand (uninterruptible computing)\nprices tends to be a few times more expensive than spot (interruptible\ncomputing) prices.\n\nOur recommendation for businesses with heavy GPU workloads is a mix of owned\nand rented GPUs where guaranteed demand runs on owned GPUs and variable demand\nruns on the cloud. This is why tech giants like Facebook are building their\nown GPU clusters including hundreds of GPUs.9Go to footnote\n\nBuyers may be tempted to consider consumer GPUs which offer a better\nprice/performance ratio however, the EULA of their software prohibits their\nuse in data centers.10Go to footnote Therefore, they are not a good fit for\nmachine learning except for minor testing workloads on data scientists\u2019\nmachines.\n\n## What are the top cloud GPU hardware?\n\nAlmost all cloud GPUs use Nvidia GPU instances. AMD and other providers also\noffer GPUs however due to various reasons (e.g. limited developer adoption,\nlower price per performance etc.), their GPUs are not as widely demanded as\nNvidia GPUs.\n\nTo see cloud GPU providers that offer non-Nvidia GPUs, please check out the\ncomprehensive list of cloud GPU providers.\n\nRead about all AI chips / hardware.\n\n## What are the top cloud GPU platforms?\n\nTop cloud GPU providers are:\n\n  * AWS\n  * Microsoft Azure\n  * CoreWeave\n  * Google Cloud Platform (GCP)\n  * IBM Cloud\n  * Jarvis Labs\n  * Lambda Labs\n  * NVIDIA DGX Cloud\n  * Oracle Cloud Infrastructure (OCI)\n  * Paperspace CORE\n\nFor more on these providers, check out cloud gpu providers.\n\nIf you are unclear about what cloud GPUs are, here is more context:\n\n## What is a cloud GPU?\n\nUnlike a CPU, which may have a relatively small number of cores optimized for\nsequential serial processing, a GPU can have hundreds or even thousands of\nsmaller cores designed for multi-threading and handling parallel processing\nworkloads.\n\nA cloud GPU refers to a certain way of GPU usage that\u2019s provided as a service\nthrough cloud computing platforms. Much like traditional cloud services, a\ncloud gpu allows you to access high-performance computing resources spot or\non-demand, without the need for upfront capital investment in hardware.\n\n## What are the functions/application areas of cloud GPUs?\n\nCloud GPUs are primarily used for processing tasks that require high\ncomputational power. Here are some of the primary uses for cloud GPUs:\n\n### Machine Learning and AI\n\nGPUs are particularly effective at handling the complex calculations required\nfor machine learning (ML) and artificial intelligence (AI) models. They can\nprocess multiple computations in parallel, making them suitable for training\nlarge neural networks and algorithms.\n\n#### Deep learning\n\nDeep learning is a sub-field of machine learning. Deep learning algorithms\ngreatly benefit from the parallel processing capabilities of GPUs, making\ntraining and inference faster and more efficient.\n\n### Data processing\n\n#### Data analysis\n\nGPUs are used to accelerate computing and data processing tasks, such as Big\nData analysis and real-time analytics. They can handle high-throughput,\nparallel processing tasks more efficiently than CPUs.\n\n#### Scientific computing\n\nIn scientific research, cloud GPUs can handle computations for simulations,\nbioinformatics, quantum chemistry, weather modeling, and more.\n\n#### Simulations\n\nCertain complex simulations can run more efficiently on GPUs.\n\n### Gaming & entertainment\n\nCloud GPUs are used to provide cloud gaming services, such as Google\u2019s Stadia\nor NVIDIA\u2019s GeForce Now, where the game runs on a server in the cloud, and the\nrendered frames are streamed to the player\u2019s device. This allows high-quality\ngaming without the need for a powerful local machine.\n\n#### Graphics rendering\n\nGPUs were initially designed to handle computer graphics, and they still excel\nin this area. Cloud GPUs are used for 3D modeling and rendering, 3D\nvisualizations, virtual reality (VR), computer-aided design (CAD), and\ncomputer-generated imagery (CGI).\n\n#### Video processing\n\nThey\u2019re used in video encoding and decoding, video editing, color correction,\neffects rendering, and other video processing tasks.\n\n### Cryptocurrency mining\n\nGPUs are also used in tasks like cryptocurrency mining. However application-\nspecific integrated circuits (ASICs) are offering better economics for more\ncommonly mined crypto currencies.\n\n## Notes\n\nCloud providers are constantly updating their offering, part of this research\ncould be outdated.\n\nAIMultiple\u2019s research is sponsored by cloud GPU providers. Sponsors can be\nidentified by links to their websites and they are ranked at the top of lists\nthat they participate in.\n\n### External links\n\n  1. Deep Learning GPU Benchmarks, Lambda Labs, Retrieved July 15, 2023\n  2. Open LLM-Perf Leaderboard, Hugging Face, Retrieved July 15, 2023\n  3. \u201cthe-full-stack/website/docs/cloud-gpus\u201c, _GitHub_ , Retrieved July 15, 2023\n  4. Spot Instance advisor, _Amazon_ , Retrieved July 19, 2023\n  5. The Ultimate Guide to Cloud GPU Providers, _Paperspace_ , Retrieved July 15, 2023\n  6. CloudOptimizer, _CloudOptimizer_ , Retrieved July 15, 2023\n  7. Cloud GPU Resources and Pricing, _Hacker News_ , Retrieved July 16, 2023\n  8. Cloud GPU Resources and Pricing, _Hacker News_ , Retrieved July 16, 2023\n  9. Meta Works with NVIDIA to Build Massive AI Research Supercomputer, _Nvidia_ , Retrieved July 16, 2023\n  10. License For Customer Use of NVIDIA GeForce Software, _Nvidia_ , Retrieved July 16, 2023\n\n  \n  \n\nShare on **LinkedIn**\n\nShare on **Twitter**\n\nCem Dilmegani\n\nCem has been the principal analyst at AIMultiple since 2017. AIMultiple\ninforms hundreds of thousands of businesses (as per similarWeb) including 60%\nof Fortune 500 every month.  \n  \nCem's work has been cited by leading global publications including Business\nInsider, Forbes, Washington Post, global firms like Deloitte, HPE, NGOs like\nWorld Economic Forum and supranational organizations like European Commission.\nYou can see more reputable companies and media that referenced AIMultiple.  \n  \nThroughout his career, Cem served as a tech consultant, tech buyer and tech\nentrepreneur. He advised enterprises on their technology decisions at McKinsey\n& Company and Altman Solon for more than a decade. He also published a\nMcKinsey report on digitalization.  \n  \nHe led technology strategy and procurement of a telco while reporting to the\nCEO. He has also led commercial growth of deep tech company Hypatos that\nreached a 7 digit annual recurring revenue and a 9 digit valuation from 0\nwithin 2 years. Cem's work in Hypatos was covered by leading technology\npublications like TechCrunch and Business Insider.  \n  \nCem regularly speaks at international technology conferences. He graduated\nfrom Bogazici University as a computer engineer and holds an MBA from Columbia\nBusiness School.\n\n**RELATED RESEARCH**  \n\nAccelerator\n\n### Top 10 Serverless GPUs: A comprehensive vendor selection\n\nAccelerator\n\n### Top 10 Cloud GPU Providers in 2023\n\nAccelerator\n\n### What is Accelerated Computing? Benefits & Use Cases in 2023\n\n**Leave a Reply**  \nYOUR EMAIL ADDRESS WILL NOT BE PUBLISHED. REQUIRED FIELDS ARE MARKED *  \n  \nComment *  \n  \nPOST COMMENT\n\n#### 0 Comments\n\nStay up-to-date on B2B Tech\n\n**Cem Dilmegani**  \nPrincipal Analyst\n\nFollow on\n\nSubscribe to the latest news &  \nupdates from our experts  \n  \nBy checking this box, you confirm that you have read and agreed to our terms\nand conditions.\n\nSolutions RPA Data Annotation Process Mining Recommendation Engine Voice Bots\nAll\n\nFor Tech Users Shortlist Solutions Get Advice\n\nVendors Claim Your Product Learn Best Practices\n\nInvestors Identify Hidden Gems Tech Firms By Country Tech Firms By City\n\nAIMultiple Mission About Career Contact LinkedIn Twitter\n\nBusinesses face the most complex technology landscape. To solve a single\nproblem, firms can leverage hundreds of solution categories with hundreds of\nvendors in each category. We bring transparency and data-driven decision\nmaking to emerging tech procurement of enterprises. Use our vendor lists or\nresearch articles to identify how technologies like AI / machine learning /\ndata science, IoT, process mining, RPA, synthetic data can transform your\nbusiness.  \nData-driven, Transparent, Practical New Tech Industry Analysis  \n  \nTerms of Use \\- Privacy Policy  \n  \n\u00a9 Copyright 2023 AIMultiple\n\nX\n\n"
}