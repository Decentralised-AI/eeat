{
    "cloud.google.com": {
        "product_name": "Google Cloud GPUs",
        "key_features": {
            "range_of_gpu_types": "NVIDIA H100, L4, P100, P4, T4, V100, and A100 GPUs",
            "flexible_performance": "Optimally balance the processor, memory, high performance disk, and up to 8 GPUs per instance for individual workloads",
            "benefits_of_google_cloud": "Access to industry-leading storage, networking, and data analytics technologies"
        },
        "whats_new": {
            "blog_post": "A3 supercomputers with NVIDIA H100 GPUs, purpose-built for AI",
            "report": "Introducing G2 VMs with NVIDIA L4 GPUs \u2014 a cloud-industry first",
            "video": "Next: An overview of Cloud GPU for ML and HPC",
            "event": "Webinar: 8 reasons to run your ML workloads on NVIDIA T4 GPUs"
        },
        "documentation": {
            "gpu_on_compute_engine": "Provides GPUs that can be added to virtual machine instances",
            "adding_removing_gpus": "Tutorial on how to add or remove GPUs from a Compute Engine VM",
            "installing_gpu_drivers": "Guide on installing NVIDIA proprietary drivers after creating an instance with GPUs",
            "gpu_on_kubernetes_engine": "How to use GPU hardware accelerators in Google Kubernetes Engine clusters\u2019 nodes",
            "using_gpus_for_training_models": "Accelerate the training process for deep learning models like image classification, video analysis, and natural language processing",
            "attaching_gpus_to_dataproc_clusters": "Attach GPUs to the master and worker Compute Engine nodes in a Dataproc cluster to accelerate specific workloads"
        },
        "pricing": "For information about GPU pricing for the different GPU types and regions available on Compute Engine, refer to the GPU pricing document",
        "call_to_action": "Start building on Google Cloud with $300 in free credits and 20+ always free products. Contact sales for help getting started, or find a trusted partner to work with.",
        "pricesAndPlans": {
            "status": "success",
            "priceAndPlans": {
                "GPUCloud": {
                    "pricing": "Flexible pricing and machine customizations to optimize for your workload",
                    "types": [
                        "NVIDIA H100",
                        "L4",
                        "P100",
                        "P4",
                        "T4",
                        "V100",
                        "A100"
                    ]
                }
            }
        }
    },
    "www.nvidia.com": {
        "gpu_cloud_products": [
            {
                "name": "NVIDIA GPU Cloud",
                "call_to_action": "Contact NVIDIA for a demo",
                "usecases": [
                    "AI Training",
                    "AI Inference",
                    "HPC",
                    "Graphics Visualization"
                ],
                "solutions": "NVIDIA platforms are powering next-generation capabilities in AI, HPC, and graphics, pushing the boundaries of what\u2019s possible. They offer solutions for AI training, AI inference, HPC, and graphics visualization.",
                "key_features": "NVIDIA GPU Cloud offers breakthrough graphics performance, minimized cloud Opex with GPU acceleration, simplified IT management and scalability, performance-optimized software stack, and enterprise-grade support in the cloud."
            }
        ],
        "pricesAndPlans": {
            "status": "Not found",
            "priceAndPlans": {}
        }
    },
    "www.runpod.io": {
        "product_name": "RunPod",
        "call_to_action": "Sign Up",
        "usecases": [
            "Developing AI applications",
            "Training AI models",
            "Scaling AI models for production"
        ],
        "solutions": [
            "Rapid access to powerful GPUs",
            "Streamlined training process for AI models",
            "Scalable serverless endpoints for production deployment"
        ],
        "key_features": {
            "template_environments": "Over 50 template environments for quick setup",
            "global_interoperability": "Select from 30+ regions across North America, Europe, and South America",
            "limitless_storage": "Ultra-fast NVMe storage for datasets and models",
            "autoscaling_serverless_endpoints": "Autoscaling from 0 to 100s of GPUs in seconds",
            "real_time_logs_metrics": "Seamless debugging with access to GPU, CPU, Memory, and other metrics",
            "pay_per_use": "Pay per second for serverless endpoints",
            "security_compliance": "Built on enterprise-grade GPUs with world-class compliance and security standards",
            "flashboot_technology": "Lightning fast cold-starts with Flashboot technology"
        },
        "pricesAndPlans": {
            "status": "success",
            "priceAndPlans": {
                "A100": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": 1.99,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": 15.92,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        }
                    },
                    "8x GPU": {
                        "Spot": {
                            "1hr": "-",
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": "-",
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        }
                    }
                },
                "H100": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": 4.69,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": 37.52,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        }
                    },
                    "8x GPU": {
                        "Spot": {
                            "1hr": 2.49,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": 3.89,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        }
                    }
                },
                "H100 PCIe": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": 4.49,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": 35.92,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        }
                    },
                    "8x GPU": {
                        "Spot": {
                            "1hr": 2.49,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": 3.69,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        }
                    }
                },
                "A40": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": 0.49,
                            "1 Month": 0.75,
                            "3 Month": 0.71,
                            "6 Month": 0.67
                        },
                        "On-Demand": {
                            "1hr": 0.79,
                            "1 Month": 0.75,
                            "3 Month": 0.71,
                            "6 Month": 0.67
                        }
                    }
                },
                "RTX 6000 Ada": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": "-",
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": 1.14,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        }
                    }
                },
                "RTX A6000": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": 0.49,
                            "1 Month": 0.75,
                            "3 Month": 0.71,
                            "6 Month": 0.67
                        },
                        "On-Demand": {
                            "1hr": 0.79,
                            "1 Month": 0.75,
                            "3 Month": 0.71,
                            "6 Month": 0.67
                        }
                    }
                },
                "RTX 3090": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": "-",
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": 0.44,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        }
                    }
                },
                "RTX 4090": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": 0.49,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": 0.74,
                            "1 Month": "-",
                            "3 Month": "-",
                            "6 Month": "-"
                        }
                    }
                },
                "L4": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": "-",
                            "1 Month": 0.42,
                            "3 Month": 0.39,
                            "6 Month": 0.37
                        },
                        "On-Demand": {
                            "1hr": 0.44,
                            "1 Month": 0.42,
                            "3 Month": 0.39,
                            "6 Month": 0.37
                        }
                    }
                },
                "RTX A5000": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": "-",
                            "1 Month": 0.42,
                            "3 Month": 0.39,
                            "6 Month": 0.37
                        },
                        "On-Demand": {
                            "1hr": 0.44,
                            "1 Month": 0.42,
                            "3 Month": 0.39,
                            "6 Month": 0.37
                        }
                    }
                },
                "RTX 4000 Ada": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": "-",
                            "1 Month": 0.39,
                            "3 Month": 0.37,
                            "6 Month": "-"
                        },
                        "On-Demand": {
                            "1hr": 0.44,
                            "1 Month": 0.39,
                            "3 Month": 0.37,
                            "6 Month": "-"
                        }
                    }
                },
                "RTX A4500": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": 0.22,
                            "1 Month": 0.34,
                            "3 Month": 0.32,
                            "6 Month": 0.3
                        },
                        "On-Demand": {
                            "1hr": 0.36,
                            "1 Month": 0.34,
                            "3 Month": 0.32,
                            "6 Month": 0.3
                        }
                    }
                },
                "RTX A4000": {
                    "1x GPU": {
                        "Spot": {
                            "1hr": "-",
                            "1 Month": 0.32,
                            "3 Month": 0.3,
                            "6 Month": 0.28
                        },
                        "On-Demand": {
                            "1hr": 0.34,
                            "1 Month": 0.32,
                            "3 Month": 0.3,
                            "6 Month": 0.28
                        }
                    }
                },
                "Community Cloud": {
                    "A100 80GB": {
                        "1x GPU": {
                            "Spot": {
                                "1hr": 0.89,
                                "On-Demand": 1.69
                            },
                            "8x GPU": {
                                "Spot": "-",
                                "On-Demand": "-"
                            }
                        }
                    },
                    "H100 80GB SXM5": {
                        "1x GPU": {
                            "Spot": {
                                "1hr": 2.49,
                                "On-Demand": 3.89
                            }
                        }
                    },
                    "H100 80GB PCIe": {
                        "1x GPU": {
                            "Spot": {
                                "1hr": 2.49,
                                "On-Demand": 3.69
                            }
                        }
                    },
                    "A40": {
                        "1x GPU": {
                            "Spot": {
                                "1hr": 0.34,
                                "On-Demand": 0.69
                            }
                        }
                    },
                    "RTX 6000 Ada": {
                        "1x GPU": {
                            "Spot": {
                                "1hr": 0.69,
                                "On-Demand": 0.99
                            }
                        }
                    },
                    "RTX A6000": {
                        "1x GPU": {
                            "Spot": {
                                "1hr": 0.34,
                                "On-Demand": 0.69
                            }
                        }
                    }
                }
            }
        }
    },
    "www.coreweave.com": {
        "product_name": "CoreWeave Cloud",
        "call_to_action": "Get in Touch",
        "use_cases": [
            "VFX & Rendering",
            "Machine Learning & AI",
            "Inference Service",
            "Pixel Streaming"
        ],
        "solutions": "CoreWeave Cloud is a specialized cloud provider, delivering a massive scale of GPUs on top of the industry\u2019s fastest and most flexible infrastructure.",
        "key_features": {
            "gpu_compute": {
                "description": "The industry\u2019s broadest range of NVIDIA GPUs, highly configurable and highly available.",
                "gpu_skus": "11+ NVIDIA GPU SKUs",
                "availability": "Available on demand"
            },
            "cpu_compute": {
                "description": "Massive scale of CPU-only instances when GPU acceleration isn\u2019t required.",
                "processors": "Intel Xeon and AMD Epyc",
                "scalability": "Scale in seconds"
            },
            "kubernetes": {
                "description": "Fully managed Kubernetes, delivering the performance of bare-metal without the infrastructure overhead.",
                "features": [
                    "Spin-up new instances in seconds",
                    "Responsive auto-scaling across thousands of GPUs"
                ]
            },
            "virtual_servers": {
                "description": "Easily deploy and manage NVIDIA GPU accelerated and CPU-only Virtual Servers.",
                "platforms": "Linux, Windows or bring your own ISO",
                "additional_feature": "Out-of-the-box desktop streaming via Teradici and Parsec"
            },
            "storage": {
                "description": "Distributed and fault tolerant storage, with triple replication, managed separately from compute.",
                "capabilities": [
                    "Easily resize volumes and scale capacity",
                    "IOPS and throughput optimized"
                ]
            },
            "networking": {
                "description": "Endless horizontal scaling with routing, switching, firewalling and load-balancing built into the network fabric.",
                "advantages": [
                    "Built to power HPC workloads with ease",
                    "Scale to 100Gbps+"
                ]
            }
        },
        "pricesAndPlans": {
            "status": "success",
            "priceAndPlans": {
                "GPU Cloud Pricing": {
                    "NVIDIA HGX H100": {
                        "VRAM (GB)": 80,
                        "Max vCPUs per GPU": 48,
                        "Max RAM (GB) per GPU": 256,
                        "GPU Component Cost Per Hour": "$4.76"
                    },
                    "NVIDIA H100 PCIe": {
                        "VRAM (GB)": 80,
                        "Max vCPUs per GPU": 48,
                        "Max RAM (GB) per GPU": 256,
                        "GPU Component Cost Per Hour": "$4.25"
                    },
                    "A100 80GB NVLINK": {
                        "VRAM (GB)": 80,
                        "Max vCPUs per GPU": 48,
                        "Max RAM (GB) per GPU": 256,
                        "GPU Component Cost Per Hour": "$2.21"
                    },
                    "A100 80GB PCIe": {
                        "VRAM (GB)": 80,
                        "Max vCPUs per GPU": 48,
                        "Max RAM (GB) per GPU": 256,
                        "GPU Component Cost Per Hour": "$2.21"
                    },
                    "A100 40GB NVLINK": {
                        "VRAM (GB)": 40,
                        "Max vCPUs per GPU": 48,
                        "Max RAM (GB) per GPU": 256,
                        "GPU Component Cost Per Hour": "$2.06"
                    },
                    "A100 40GB PCIe": {
                        "VRAM (GB)": 40,
                        "Max vCPUs per GPU": 48,
                        "Max RAM (GB) per GPU": 256,
                        "GPU Component Cost Per Hour": "$2.06"
                    },
                    "A40": {
                        "VRAM (GB)": 48,
                        "Max vCPUs per GPU": 48,
                        "Max RAM (GB) per GPU": 256,
                        "GPU Component Cost Per Hour": "$1.28"
                    },
                    "RTX A6000": {
                        "VRAM (GB)": 48,
                        "Max vCPUs per GPU": 48,
                        "Max RAM (GB) per GPU": 256,
                        "GPU Component Cost Per Hour": "$1.28"
                    },
                    "RTX A5000": {
                        "VRAM (GB)": 24,
                        "Max vCPUs per GPU": 36,
                        "Max RAM (GB) per GPU": 128,
                        "GPU Component Cost Per Hour": "$0.77"
                    },
                    "RTX A4000": {
                        "VRAM (GB)": 16,
                        "Max vCPUs per GPU": 36,
                        "Max RAM (GB) per GPU": 128,
                        "GPU Component Cost Per Hour": "$0.61"
                    },
                    "Quadro RTX 5000": {
                        "VRAM (GB)": 16,
                        "Max vCPUs per GPU": 36,
                        "Max RAM (GB) per GPU": 128,
                        "GPU Component Cost Per Hour": "$0.57"
                    },
                    "Quadro RTX 4000": {
                        "VRAM (GB)": 8,
                        "Max vCPUs per GPU": 36,
                        "Max RAM (GB) per GPU": 128,
                        "GPU Component Cost Per Hour": "$0.24"
                    },
                    "Tesla V100 NVLINK": {
                        "VRAM (GB)": 16,
                        "Max vCPUs per GPU": 36,
                        "Max RAM (GB) per GPU": 128,
                        "GPU Component Cost Per Hour": "$0.80"
                    }
                },
                "CPU Cloud Pricing": {
                    "AMD EPYC Milan": {
                        "RAM per vCPU": 4,
                        "Cost Per vCPU": "$0.035"
                    },
                    "AMD EPYC Rome": {
                        "RAM per vCPU": 4,
                        "Cost Per vCPU": "$0.03"
                    },
                    "Intel Xeon Scalable": {
                        "RAM per vCPU": 4,
                        "Cost Per vCPU": "$0.03"
                    },
                    "Intel Xeon v4": {
                        "RAM per vCPU": 4,
                        "Cost Per vCPU": "$0.02"
                    },
                    "Intel Xeon v3": {
                        "RAM per vCPU": 4,
                        "Cost Per vCPU": "$0.0125"
                    }
                },
                "Storage": {
                    "HDD (Block or Shared Filesystem)": "$0.04 per GB / month",
                    "NVMe (Block or Shared Filesystem)": "$0.07 per GB / month",
                    "Object Storage": "$0.03 per GB / month",
                    "Block Storage (HDD)": "$0.04 per GB / month",
                    "Block Storage (NVMe)": "$0.07 per GB / month"
                },
                "Networking": {
                    "Public IP Address": "$4.00 per IP / month",
                    "Burstable IP Address": "$10.00 per IP / month",
                    "VPC": "$20.00 per VPC / month"
                }
            }
        }
    },
    "lambdalabs.com": {
        "product_name": "Lambda Cloud",
        "call_to_action": "Sign up for free",
        "usecases": [
            "AI model building and fine-tuning",
            "High-bandwidth GPU-to-GPU communication",
            "Hosting Generative AI apps",
            "Accessing cloud GPUs for machine learning",
            "On-demand GPU cloud pricing",
            "Reserved Cloud Cluster pricing"
        ],
        "solutions": [
            "Cloud Clusters",
            "Datacenter solutions (Echelon Clusters, Hyperplane Server, Scalar Server, NVIDIA DGX Systems, NVIDIA GH200, NVIDIA H100 & H200, GPU Colocation)",
            "Desktop solutions (Vector GPU Workstation, Tensorbook GPU Laptop)"
        ],
        "key_features": {
            "NVIDIA GPU Options": [
                "H100 SXM",
                "H100 PCIe",
                "A100 SXM",
                "A100 PCIe",
                "A10",
                "A6000",
                "Tesla V100",
                "Quadro RTX 6000"
            ],
            "GPU Instance Types": [
                "1x, 2x, 4x, or 8x GPUs"
            ],
            "Storage Options": [
                "High-speed filesystem for GPU instances",
                "Shared filesystems"
            ],
            "Pricing Model": [
                "Pay-by-the-second billing",
                "Transparent pricing"
            ],
            "Pre-configured Environment": [
                "One-click Jupyter access",
                "Pre-installed with popular ML frameworks"
            ],
            "Scalability": [
                "Enhanced scalability",
                "Automate workflow with Lambda Cloud API"
            ],
            "Reserved Cloud Cluster Options": [
                "Reserved",
                "Sprint"
            ]
        },
        "pricesAndPlans": {
            "status": "Success",
            "priceAndPlans": {
                "8-GPU V100 instance": {
                    "price": "$4.40 / hr",
                    "features": {
                        "GPUs": "8x (16 GB) NVIDIA Tensor Core V100 SXM2 GPUs (with NVLink\u2122)",
                        "CPU": "92 vCPUs",
                        "System RAM": "448 GB",
                        "Temporary Local Storage": "6 TB NVMe",
                        "Network Interface": "10 Gbps (peak)"
                    }
                }
            }
        }
    },
    "blog.paperspace.com": {
        "Paperspace": {
            "call_to_action": "Contact Sales",
            "usecases": [
                "Machine Learning",
                "GPU Infrastructure",
                "Enterprise VDI",
                "Gaming",
                "Rendering, 3D Graphics & Simulation"
            ],
            "solutions": [
                "Build, train, deploy, and manage AI models",
                "Effortless infrastructure on-demand",
                "Cloud hosted desktops for both individuals and organizations"
            ],
            "key_features": "Simple management console, powerful API, desktop access for Windows and Linux systems, collaboration tools, limitless computing power, billed per second, discounts, wide range of GPU instances"
        },
        "pricesAndPlans": {
            "status": "found",
            "priceAndPlans": {
                "Gradient": {
                    "pricing": "Variable",
                    "freePlan": {
                        "features": [
                            "Free, dedicated cloud GPU instance",
                            "Up to 6 hours usage",
                            "Fully versioned notebooks"
                        ]
                    },
                    "paidPlans": {
                        "features": [
                            "Access to private notebooks",
                            "Pay-per-second cloud instances"
                        ]
                    }
                }
            }
        }
    }
}