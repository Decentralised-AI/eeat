{
    "summary": "RunPod\n\nPricingServerlessEndpointsBlogDocsSign UpLogin\n\n* * *\n\n# The Cloud Built for AI\n\n## Globally distributed GPU cloud built for production.\n\n **Develop** , **train** , and **scale** AI applications.\n\nStart Building\n\n# Develop, train, and scale AI models.\n\n# All in one cloud.\n\nDevelop\n\nWith over 50 template environments, you're just three clicks away from a fully\nconfigured development workspace.\n\nTrain\n\nRunPod is engineered to streamline the training process, allowing you to\nbenchmark and train your models efficiently.\n\nScale\n\nDeploy your models to production and scale from 0 to millions of inference\nrequests with our Serverless endpoints.\n\n## Launch a GPU instance in seconds\n\nRun any GPU workload seamlessly, so you can focus less on ML ops and more on\nbuilding your application.\n\n50+ Template Environments\n\nChoose from 50+ templates ready out-of-the-box, or bring your own custom\ncontainer.\n\nPyTorch\n\nTensoflow\n\nAxolotl\n\nStable Diffusion\n\nDreambooth\n\nTheBloke LLMs\n\nA1111\n\n50+ Others\n\nGlobal Interoperability\n\nSelect from 30+ regions across North America, Europe, and South America.\n\nLimitless Storage\n\nUltra-fast NVMe storage for your datasets and models, so you can rapidly scale\ndevelopment.\n\nDeploy in Seconds\n\nConfigure your deployment and launch in seconds.\n\n0%\n\n500 MiB/s\n\nGet Started\n\nA100\n\n80 GB\n\n* * *\n\n* * *\n\n$1.99 / hr\n\nH100\n\n80 GB\n\n* * *\n\n* * *\n\n$4.49 / hr\n\nA40\n\n48 GB\n\n* * *\n\n* * *\n\n$0.79 / hr\n\nRTX 4090\n\n24 GB\n\n* * *\n\n* * *\n\n$0.74 / hr\n\nRTX A6000\n\n48 GB\n\n* * *\n\n* * *\n\n$0.79 / hr\n\nSee all GPUs\n\n## Scale inference on your models with Serverless\n\nCreate production-ready endpoints that autoscale from 0 to 100s of GPUs in\nseconds. Only pay for the resources you use.\n\n99.99%\n\nguaranteed uptime\n\n13\n\nregions\n\n10PB+\n\nnetwork storage\n\n2,492,586,952\n\nrequests\n\nAutoscale to Millions of Requests\n\nScale inference, or fine-tuning workloads to thousands of concurrent GPUs and\nback to zero in seconds.\n\nZero Ops Overhead\n\nRunPod handles all the operational aspects of your infrastructure from\ndeploying to scaling.\n\nReal-time Logs and Metrics\n\nSeamlessly debug containers with access to GPU, CPU, Memory, and other\nmetrics. You can monitor logs in real-time.\n\nEliminate Idle GPU Costs\n\nPay per second. You only pay when your endpoint receives and processes a\nrequest.\n\nSecure and Compliant\n\nServerless is built on enterprise-grade GPUs with world-class compliance and\nsecurity standards.\n\nLightning Fast Cold-Start\n\nWith Flashboot, watch your cold-starts drop to sub 500 milliseconds.\n\nFlashBoot\n\n* * *\n\nP70 Cold-Start\n\nP90\n\nStableDiffusion\n\n* * *\n\n235ms\n\n262ms\n\nWhisper\n\n* * *\n\n1,278ms\n\n13,471ms\n\n# Join over 100,000 developers using RunPod\n\nGPU InstancesServerlessAI Endpoints\n\nLaunch a GPU instance in seconds\n\nKickstart your development with minimal configuration using RunPod's on-demand\nGPU instances. Our platform is engineered to provide you with rapid access to\npowerful GPUs, facilitating a smooth start for machine learning and AI\ndevelopment.\n\nGPU Instances\n\nYour browser does not support the video tag.\n\n## Launch your AI application in seconds\n\nExperience the most cost-effective GPU cloud platform built for production.\n\nGet Started\n\nPRODUCTS\n\nSecure Cloud  \nCommunity Cloud  \nServerless  \nAI Endpoints\n\nRESOURCES\n\nAPI Docs  \nFAQ  \nBlog  \nBecome a Host\n\nCOMPANY\n\nAbout  \nCookie Policy  \nDisclaimer  \nPrivacy Policy  \nTerms of Service\n\nCONTACT\n\nContact Us  \nDiscord  \nhelp@runpod.io  \nreferrals@runpod.io\n\n\u00a9 RunPod 2023\n\nPeople illustrations by Storyset\n\n",
    "links": "[{\"link\": \"https://www.runpod.io/\", \"text\": \"\"}, {\"link\": \"https://www.runpod.io/gpu-instance/pricing\", \"text\": \"Pricing\"}, {\"link\": \"https://www.runpod.io/serverless-gpu\", \"text\": \"Serverless\"}, {\"link\": \"https://www.runpod.io/endpoints\", \"text\": \"Endpoints\"}, {\"link\": \"https://www.runpod.io/console/signup\", \"text\": \"Sign Up\"}, {\"link\": \"https://www.runpod.io/console/login\", \"text\": \"Login\"}, {\"link\": \"https://www.runpod.io/console/gpu-secure-cloud\", \"text\": \"\"}, {\"link\": \"https://www.runpod.io/console/templates\", \"text\": \"50+ Others\"}, {\"link\": \"https://www.runpod.io/console/gpu-secure-cloud\", \"text\": \"\"}, {\"link\": \"https://www.runpod.io/gpu-instance/pricing\", \"text\": \"See all GPUs\"}, {\"link\": \"https://www.runpod.io/console/gpu-secure-cloud\", \"text\": \"GPU Instances\"}, {\"link\": \"https://www.runpod.io/console/gpu-secure-cloud\", \"text\": \"\"}, {\"link\": \"https://www.runpod.io/console/gpu-secure-cloud\", \"text\": \"Secure Cloud\"}, {\"link\": \"https://www.runpod.io/console/gpu-cloud\", \"text\": \"Community Cloud\"}, {\"link\": \"https://www.runpod.io/console/serverless\", \"text\": \"Serverless\"}, {\"link\": \"https://www.runpod.io/endpoints\", \"text\": \"AI Endpoints\"}, {\"link\": \"https://www.runpod.io/console/host/docs/faq\", \"text\": \"Become a Host\"}, {\"link\": \"https://www.runpod.io/about\", \"text\": \"About\"}, {\"link\": \"https://www.runpod.io/legal/cookie-policy\", \"text\": \"Cookie Policy\"}, {\"link\": \"https://www.runpod.io/legal/disclaimer\", \"text\": \"Disclaimer\"}, {\"link\": \"https://www.runpod.io/legal/privacy-policy\", \"text\": \"Privacy Policy\"}, {\"link\": \"https://www.runpod.io/legal/terms-of-service\", \"text\": \"Terms of Service\"}, {\"link\": \"https://www.runpod.io/contact\", \"text\": \"Contact Us\"}, {\"link\": \"https://www.runpod.io/\", \"text\": \"help@runpod.io\"}, {\"link\": \"https://www.runpod.io/\", \"text\": \"referrals@runpod.io\"}]",
    "priceAndPlans": "RunPod\n\nPricingServerlessEndpointsBlogDocsSign UpLogin\n\n* * *\n\n# GPU Instance Pricing\n\n **5x cheaper** than other clouds\n\nAutoscale with Serverless with cold-start in milliseconds.\n\nServerless Pricing\n\nSecure Cloud\n\n| 1x GPU  \n$/hr| 8x GPU  \n$/hr  \n---|---|---  \n  \nA100 80GB\n\n80 GB VRAM\n\n125 GB RAM  8 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n1.99\n\n1 Month\n\n-\n\n3 Month\n\n-\n\n6 Month\n\n-\n\n|\n\n-\n\n15.92\n\n-\n\n-\n\n-  \n  \nA100 SXM 80GB\n\n80 GB VRAM\n\n125 GB RAM  16 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n2.29\n\n1 Month\n\n-\n\n3 Month\n\n-\n\n6 Month\n\n-\n\n|\n\n-\n\n18.32\n\n-\n\n-\n\n-  \n  \nH100 80GB SXM5\n\n80 GB VRAM\n\n251 GB RAM  26 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n4.69\n\n1 Month\n\n-\n\n3 Month\n\n-\n\n6 Month\n\n-\n\n|\n\n-\n\n37.52\n\n-\n\n-\n\n-  \n  \nH100 80GB PCIe\n\n80 GB VRAM\n\n250 GB RAM  16 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n4.49\n\n1 Month\n\n-\n\n3 Month\n\n-\n\n6 Month\n\n-\n\n|\n\n-\n\n35.92\n\n-\n\n-\n\n-  \n  \nA40\n\n48 GB VRAM\n\n50 GB RAM  4 vCPU\n\n|\n\nSpot\n\n0.49\n\nOn-Demand\n\n0.79\n\n1 Month\n\n0.75\n\n3 Month\n\n0.71\n\n6 Month\n\n0.67\n\n|\n\n3.92\n\n6.32\n\n6\n\n5.68\n\n5.36  \n  \nL40\n\n48 GB VRAM\n\n58 GB RAM  16 vCPU\n\n|\n\nSpot\n\n0.69\n\nOn-Demand\n\n1.14\n\n1 Month\n\n1.08\n\n3 Month\n\n1.02\n\n6 Month\n\n0.97\n\n|\n\n5.52\n\n9.12\n\n8.64\n\n8.16\n\n7.76  \n  \nRTX 6000 Ada\n\n48 GB VRAM\n\n62 GB RAM  14 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n1.14\n\n1 Month\n\n-\n\n3 Month\n\n-\n\n6 Month\n\n-\n\n|\n\n-\n\n9.12\n\n-\n\n-\n\n-  \n  \nRTX A6000\n\n48 GB VRAM\n\n50 GB RAM  8 vCPU\n\n|\n\nSpot\n\n0.49\n\nOn-Demand\n\n0.79\n\n1 Month\n\n0.75\n\n3 Month\n\n0.71\n\n6 Month\n\n0.67\n\n|\n\n3.92\n\n6.32\n\n6\n\n5.68\n\n5.36  \n  \nRTX 3090\n\n24 GB VRAM\n\n27 GB RAM  5 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.44\n\n1 Month\n\n-\n\n3 Month\n\n-\n\n6 Month\n\n-\n\n|\n\n-\n\n3.52\n\n-\n\n-\n\n-  \n  \nRTX 4090\n\n24 GB VRAM\n\n30 GB RAM  4 vCPU\n\n|\n\nSpot\n\n0.49\n\nOn-Demand\n\n0.74\n\n1 Month\n\n-\n\n3 Month\n\n-\n\n6 Month\n\n-\n\n|\n\n3.92\n\n5.92\n\n-\n\n-\n\n-  \n  \nL4\n\n24 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.44\n\n1 Month\n\n0.42\n\n3 Month\n\n0.39\n\n6 Month\n\n0.37\n\n|\n\n-\n\n3.52\n\n3.36\n\n3.12\n\n2.96  \n  \nRTX A5000\n\n24 GB VRAM\n\n29 GB RAM  4 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.44\n\n1 Month\n\n0.42\n\n3 Month\n\n0.39\n\n6 Month\n\n0.37\n\n|\n\n-\n\n3.52\n\n3.36\n\n3.12\n\n2.96  \n  \nRTX 4000 Ada\n\n20 GB VRAM\n\n31 GB RAM  5 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.44\n\n1 Month\n\n0.39\n\n3 Month\n\n0.37\n\n6 Month\n\n-\n\n|\n\n-\n\n3.52\n\n3.12\n\n2.96\n\n-  \n  \nRTX A4500\n\n20 GB VRAM\n\n29 GB RAM  4 vCPU\n\n|\n\nSpot\n\n0.22\n\nOn-Demand\n\n0.36\n\n1 Month\n\n0.34\n\n3 Month\n\n0.32\n\n6 Month\n\n0.3\n\n|\n\n1.76\n\n2.88\n\n2.72\n\n2.56\n\n2.4  \n  \nRTX A4000\n\n16 GB VRAM\n\n23 GB RAM  6 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.34\n\n1 Month\n\n0.32\n\n3 Month\n\n0.3\n\n6 Month\n\n0.28\n\n|\n\n-\n\n2.72\n\n2.56\n\n2.4\n\n2.24  \n  \nDeploy Now\n\nCommunity Cloud\n\n| 1x GPU  \n$/hr| 8x GPU  \n$/hr  \n---|---|---  \n  \nA100 80GB\n\n80 GB VRAM\n\n125 GB RAM  8 vCPU\n\n|\n\nSpot\n\n0.89\n\nOn-Demand\n\n1.69\n\n|\n\n7.12\n\n13.52  \n  \nH100 80GB SXM5\n\n80 GB VRAM\n\n251 GB RAM  26 vCPU\n\n|\n\nSpot\n\n2.49\n\nOn-Demand\n\n3.89\n\n|\n\n19.92\n\n31.12  \n  \nH100 80GB PCIe\n\n80 GB VRAM\n\n250 GB RAM  16 vCPU\n\n|\n\nSpot\n\n2.49\n\nOn-Demand\n\n3.69\n\n|\n\n19.92\n\n29.52  \n  \nA40\n\n48 GB VRAM\n\n50 GB RAM  4 vCPU\n\n|\n\nSpot\n\n0.34\n\nOn-Demand\n\n0.69\n\n|\n\n2.72\n\n5.52  \n  \nRTX 6000 Ada\n\n48 GB VRAM\n\n62 GB RAM  14 vCPU\n\n|\n\nSpot\n\n0.69\n\nOn-Demand\n\n0.99\n\n|\n\n5.52\n\n7.92  \n  \nRTX A6000\n\n48 GB VRAM\n\n50 GB RAM  8 vCPU\n\n|\n\nSpot\n\n0.34\n\nOn-Demand\n\n0.69\n\n|\n\n2.72\n\n5.52  \n  \nRTX 5000 Ada\n\n32 GB VRAM\n\n62 GB RAM  14 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.69\n\n|\n\n-\n\n5.52  \n  \nV100 SXM2 32GB\n\n32 GB VRAM\n\n62 GB RAM  20 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.39\n\n|\n\n-\n\n3.12  \n  \nA30\n\n24 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n0.19\n\nOn-Demand\n\n0.29\n\n|\n\n1.52\n\n2.32  \n  \nRTX 3090\n\n24 GB VRAM\n\n27 GB RAM  5 vCPU\n\n|\n\nSpot\n\n0.19\n\nOn-Demand\n\n0.29\n\n|\n\n1.52\n\n2.32  \n  \nRTX 3090 Ti\n\n24 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n0.2\n\nOn-Demand\n\n0.36\n\n|\n\n1.6\n\n2.88  \n  \nRTX 4090\n\n24 GB VRAM\n\n30 GB RAM  4 vCPU\n\n|\n\nSpot\n\n0.39\n\nOn-Demand\n\n0.59\n\n|\n\n3.12\n\n4.72  \n  \nRTX A5000\n\n24 GB VRAM\n\n29 GB RAM  4 vCPU\n\n|\n\nSpot\n\n0.19\n\nOn-Demand\n\n0.29\n\n|\n\n1.52\n\n2.32  \n  \nRTX 4000 Ada\n\n20 GB VRAM\n\n31 GB RAM  5 vCPU\n\n|\n\nSpot\n\n0.15\n\nOn-Demand\n\n0.25\n\n|\n\n1.2\n\n2  \n  \nRTX 4000 Ada SFF\n\n20 GB VRAM\n\n23 GB RAM  7 vCPU\n\n|\n\nSpot\n\n0.15\n\nOn-Demand\n\n0.25\n\n|\n\n1.2\n\n2  \n  \nRTX A4500\n\n20 GB VRAM\n\n29 GB RAM  4 vCPU\n\n|\n\nSpot\n\n0.15\n\nOn-Demand\n\n0.21\n\n|\n\n1.2\n\n1.68  \n  \nRTX 4080\n\n16 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.35\n\n|\n\n-\n\n2.8  \n  \nRTX A4000\n\n16 GB VRAM\n\n23 GB RAM  6 vCPU\n\n|\n\nSpot\n\n0.15\n\nOn-Demand\n\n0.19\n\n|\n\n1.2\n\n1.52  \n  \nV100 FHHL\n\n16 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n0.19\n\nOn-Demand\n\n0.28\n\n|\n\n1.52\n\n2.24  \n  \nTesla V100\n\n16 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n0.19\n\nOn-Demand\n\n0.28\n\n|\n\n1.52\n\n2.24  \n  \nV100 SXM2\n\n16 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n0.15\n\nOn-Demand\n\n0.29\n\n|\n\n1.2\n\n2.32  \n  \nRTX 3080 Ti\n\n12 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n0.15\n\nOn-Demand\n\n0.19\n\n|\n\n1.2\n\n1.52  \n  \nRTX 4070 Ti\n\n12 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n0.15\n\nOn-Demand\n\n0.25\n\n|\n\n1.2\n\n2  \n  \nRTX 3080\n\n10 GB VRAM\n\n13 GB RAM  16 vCPU\n\n|\n\nSpot\n\n0.15\n\nOn-Demand\n\n0.18\n\n|\n\n1.2\n\n1.44  \n  \nRTX 3070\n\n8 GB VRAM\n\nGB RAM   vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.17\n\n|\n\n-\n\n1.36  \n  \nRTX A2000\n\n6 GB VRAM\n\n35 GB RAM  9 vCPU\n\n|\n\nSpot\n\n-\n\nOn-Demand\n\n0.17\n\n|\n\n-\n\n1.36  \n  \nDeploy Now\n\n## Storage Pricing\n\n **Pod Volume / Container Disk**  \n$0.10/GB/Month on running pods  \n$0.20/GB/Month for idle volume\n\n **Network Storage**  \n$0.07/GB/Month  \n$0.05/GB/Month for 1TB or more\n\n## Bandwidth Pricing\n\nIt's FREE!  \nNo hidden internet bandwidth costs.\n\nDon't see a machine configuration that you like?\n\nDon't want to use containers?\n\n **We provide custom solutions too!**\n\nContact Us\n\nPRODUCTS\n\nSecure Cloud  \nCommunity Cloud  \nServerless  \nAI Endpoints\n\nRESOURCES\n\nAPI Docs  \nFAQ  \nBlog  \nBecome a Host\n\nCOMPANY\n\nAbout  \nCookie Policy  \nDisclaimer  \nPrivacy Policy  \nTerms of Service\n\nCONTACT\n\nContact Us  \nDiscord  \nhelp@runpod.io  \nreferrals@runpod.io\n\n\u00a9 RunPod 2023\n\nPeople illustrations by Storyset\n\n"
}