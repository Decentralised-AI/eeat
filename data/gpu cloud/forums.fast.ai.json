{
    "summary": "fast.ai Course Forums\n\n#  Cloud GPUs: Comparison and Free Credits\n\nDeep Learning\n\nhcarlens (Harald)  February 2, 2022, 11:58am  1\n\nThought this might be useful to some of you here who like me only have a small\nlocal GPU and rely on cloud GPUs for larger training runs!\n\nI created a page that compares Cloud GPU Services. You can look for specific\nGPU models, pricing (static at the moment but hoping to make this dynamic\nsoon), and features like notebooks/SSH/data persistence. It also lists the\namount available in free credits for each service, and some of the links have\ncustom discount codes to get additional free credits.\n\nimage1832\u00d7764 89.8 KB\n\nHope it\u2019s useful, let me know what you think!\n\n5 Likes\n\njules43 (Jules)  February 8, 2022, 7:27am  2\n\nVery useful comparison. The Google Cloud spot price for V100 is $0.74. I\u2019m\ncurious as to why you use the non-preemptible one.\n\n2 Likes\n\nhcarlens (Harald)  February 8, 2022, 9:31am  3\n\nThanks! That\u2019s a really good point. We\u2019re making a lot of simplifications on\nthe page - e.g. in reality pricing is different per region, pricing isn\u2019t\nactually static over time, and we\u2019re not accounting for the value of other\ncharacteristics of the VM it\u2019s attached to. (e.g. pricing per vCPU, SSD vs\nHDD, RAM\u2026).\n\nBut you\u2019re right - maybe the fact that we\u2019re only looking at on-demand VMs and\nexcluding preemptible ones makes GCP and AWS look more expensive than they\nwould be in practice. We picked the on-demand ones because that\u2019s most similar\nto what competitors offer (apart from maybe vast.ai).\n\nRight now we\u2019re trying to see how much interest there is in a comparison\nservice like this, and if it\u2019s sufficient then we\u2019d spend time developing it\nfurther.\n\nTo address your point we could add a filter at the top to say \u201cinclude\npreemptible instances\u201d - do you think that would work well?\n\n1 Like\n\njhadjar (Jugurtha Hadjar)  February 8, 2022, 1:41pm  4\n\nInteresting. I opened an issue recently,\nhttps://github.com/fastai/course20/issues/66, to add our service.\n\nI wonder how it would fit in this list because it allows you to use your\ncompute from GCP, AWS, Azure, DigitalOcean directly to run notebooks on\niko.ai.\n\nFor example, someone might apply for free credits on GCP, create a Kubernetes\ncluster (GKE), then get the config and use it to run the fast.ai notebooks.\nGiven the resources are expensive, we automatically shut down idle notebook\nservers (that is: when there neither is user activity, _nor_ computation or a\nbusy cell).\n\nThe long running-notebooks can also run in the background in an ephemeral\nfashion: we use the compute just for the duration of the notebook job and that\nrepresents quite large savings as well.\n\nI\u2019d appreciate feedback on the issue as well.\n\nAre you using this for the Google pricing: GPU pricing | Compute Engine:\nVirtual Machines (VMs) | Google Cloud\n\nhushitz February 8, 2022, 2:23pm  5\n\nI second the need for spot pricing to be included - for anyone who is at all\nprice-sensitive, that\u2019s the only relevant metric. Your proposed service\nbasically only appeals to people who are price-sensitive, so you\u2019re not doing\nanyone a service by ignoring that.\n\nThis site is super useful for finding the best spot-price of any AWS instance\nglobally: Cheapest Amazon EC2 Spot Price Region \\- this shows p3.2xlarge (so a\nsingle V100) at $0.92/hr currently, which takes AWS from the most expensive to\nthe second-cheapest in your list (well, third cheapest if the google spot\nprice from the earlier post is added). That makes your list largely irrelevant\nwithout taking spot pricing into account.\n\n1 Like\n\nhcarlens (Harald)  February 8, 2022, 3:21pm  6\n\nFair point, thanks! I\u2019ll have a think about this, but based on what both of\nyou have said it probably makes sense to showing spot/preemptible by default,\nand adding a caveat about that for anyone who\u2019s looking for on-demand\nspecifically.\n\nhcarlens (Harald)  February 9, 2022, 6:37pm  7\n\n@hushitz @jules43 I\u2019ve updated it to use spot/preemptible prices for AWS and\nGCP GPUs, thanks again for the feedback.\n\nI\u2019ve also moved this page to its own domain now, to better represent that it\u2019s\nfocused on cloud GPU services: cloud-gpus.com.\n\nAny further feedback please keep it coming\n\nOh and it\u2019s all open source - code here in case you\u2019re interested:\nhttps://github.com/cloud-gpus/cloud-gpus.github.io\n\n@jhadjar looks interesting. Reminds me a bit of this open source library,\nSpotty, which allows you to make use of spot instances effectively:\nhttps://github.com/spotty-cloud/spotty\n\n1 Like\n\njules43 (Jules)  February 10, 2022, 6:34am  8\n\nPutting in the spot price as the default is fantastic, thanks. It\u2019s also\nreally interesting to see how much the price varies between the different\ncompanies.\n\npurplemango June 28, 2022, 7:33pm  9\n\nI\u2019d like to add another platform to this awesome list! It\u2019s Q Blocks -\ndecentralized GPU computing platform.\n\nThey have community and data center nodes with on-demand global access. 3090s\nare available on it around $0.75/hr and A100s around $2.5/hr. I\u2019ve seen the\nprices to be stable from a long period on it.\n\n  * Home \n  * Categories \n  * FAQ/Guidelines \n  * Terms of Service \n  * Privacy Policy \n\nPowered by Discourse, best viewed with JavaScript enabled\n\nSkip to main content\n\nSign UpLog In\n\n  *   * \n\n#\n\nCloud GPUs: Comparison and Free Credits\n\nDeep Learning\n\nYou have selected **0** posts.\n\nselect all\n\ncancel selecting\n\nFeb 2022\n\n1 / 9\n\nFeb 2022\n\nJun 2022\n\nhcarlensHarald\n\n1\n\nFeb '22\n\nThought this might be useful to some of you here who like me only have a small\nlocal GPU and rely on cloud GPUs for larger training runs!\n\nI created a page that compares Cloud GPU Services 217. You can look for\nspecific GPU models, pricing (static at the moment but hoping to make this\ndynamic soon), and features like notebooks/SSH/data persistence. It also lists\nthe amount available in free credits for each service, and some of the links\nhave custom discount codes to get additional free credits.\n\nimage1832\u00d7764 89.8 KB\n\nHope it\u2019s useful, let me know what you think!\n\n5\n\n  * #### created\n\nFeb '22\n\n  * #### last reply\n\nJun '22\n\n  * 8\n\n#### replies\n\n  * 2.2k\n\n#### views\n\n  * 5\n\n#### users\n\n  * 10\n\n#### likes\n\n  * 7\n\n#### links\n\n  * 4\n\n2\n\njules43Jules\n\nFeb '22\n\nVery useful comparison. The Google Cloud spot price for V100 is $0.74. I\u2019m\ncurious as to why you use the non-preemptible one.\n\n2\n\nhcarlensHarald\n\nFeb '22\n\nThanks! That\u2019s a really good point. We\u2019re making a lot of simplifications on\nthe page - e.g. in reality pricing is different per region, pricing isn\u2019t\nactually static over time, and we\u2019re not accounting for the value of other\ncharacteristics of the VM it\u2019s attached to. (e.g. pricing per vCPU, SSD vs\nHDD, RAM\u2026).\n\nBut you\u2019re right - maybe the fact that we\u2019re only looking at on-demand VMs and\nexcluding preemptible ones makes GCP and AWS look more expensive than they\nwould be in practice. We picked the on-demand ones because that\u2019s most similar\nto what competitors offer (apart from maybe vast.ai).\n\nRight now we\u2019re trying to see how much interest there is in a comparison\nservice like this, and if it\u2019s sufficient then we\u2019d spend time developing it\nfurther.\n\nTo address your point we could add a filter at the top to say \u201cinclude\npreemptible instances\u201d - do you think that would work well?\n\n1 Reply\n\n1\n\njhadjarJugurtha Hadjar\n\nFeb '22\n\nInteresting. I opened an issue recently,\nhttps://github.com/fastai/course20/issues/66 12, to add our service.\n\nI wonder how it would fit in this list because it allows you to use your\ncompute from GCP, AWS, Azure, DigitalOcean directly to run notebooks on\niko.ai.\n\nFor example, someone might apply for free credits on GCP, create a Kubernetes\ncluster (GKE), then get the config and use it to run the fast.ai notebooks.\nGiven the resources are expensive, we automatically shut down idle notebook\nservers (that is: when there neither is user activity, _nor_ computation or a\nbusy cell).\n\nThe long running-notebooks can also run in the background in an ephemeral\nfashion: we use the compute just for the duration of the notebook job and that\nrepresents quite large savings as well.\n\nI\u2019d appreciate feedback on the issue as well.\n\nAre you using this for the Google pricing: GPU pricing  |  Compute Engine:\nVirtual Machines (VMs)  |  Google Cloud 8\n\nhushitz\n\nhcarlens\n\nFeb '22\n\nI second the need for spot pricing to be included - for anyone who is at all\nprice-sensitive, that\u2019s the only relevant metric. Your proposed service\nbasically only appeals to people who are price-sensitive, so you\u2019re not doing\nanyone a service by ignoring that.\n\nThis site is super useful for finding the best spot-price of any AWS instance\nglobally: Cheapest Amazon EC2 Spot Price Region 13 \\- this shows p3.2xlarge\n(so a single V100) at $0.92/hr currently, which takes AWS from the most\nexpensive to the second-cheapest in your list (well, third cheapest if the\ngoogle spot price from the earlier post is added). That makes your list\nlargely irrelevant without taking spot pricing into account.\n\n1\n\nhcarlensHarald\n\nFeb '22\n\nFair point, thanks! I\u2019ll have a think about this, but based on what both of\nyou have said it probably makes sense to showing spot/preemptible by default,\nand adding a caveat about that for anyone who\u2019s looking for on-demand\nspecifically.\n\nhcarlensHarald\n\nFeb '22\n\n@hushitz @jules43 I\u2019ve updated it to use spot/preemptible prices for AWS and\nGCP GPUs, thanks again for the feedback.\n\nI\u2019ve also moved this page to its own domain now, to better represent that it\u2019s\nfocused on cloud GPU services: cloud-gpus.com 42.\n\nAny further feedback please keep it coming\n\nOh and it\u2019s all open source - code here in case you\u2019re interested:\nhttps://github.com/cloud-gpus/cloud-gpus.github.io 22\n\n@jhadjar looks interesting. Reminds me a bit of this open source library,\nSpotty, which allows you to make use of spot instances effectively:\nhttps://github.com/spotty-cloud/spotty 8\n\n1\n\njules43Jules\n\nFeb '22\n\nPutting in the spot price as the default is fantastic, thanks. It\u2019s also\nreally interesting to see how much the price varies between the different\ncompanies.\n\n5 months later\n\npurplemango\n\nJun '22\n\nI\u2019d like to add another platform to this awesome list! It\u2019s Q Blocks -\ndecentralized GPU computing platform.\n\nThey have community and data center nodes with on-demand global access. 3090s\nare available on it around $0.75/hr and A100s around $2.5/hr. I\u2019ve seen the\nprices to be stable from a long period on it.\n\nReply\n\n  \n\n\u200b\n\n\u200b  Invalid date  \u200b Invalid date\n\n",
    "links": "[{\"link\": \"https://forums.fast.ai/\", \"text\": \"\\n    fast.ai Course Forums\\n  \"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389\", \"text\": \"Cloud GPUs: Comparison and Free Credits\"}, {\"link\": \"https://forums.fast.ai/u/hushitz\", \"text\": \"@hushitz\"}, {\"link\": \"https://forums.fast.ai/u/jules43\", \"text\": \"@jules43\"}, {\"link\": \"https://forums.fast.ai/u/jhadjar\", \"text\": \"@jhadjar\"}, {\"link\": \"https://forums.fast.ai/\", \"text\": \"Home \"}, {\"link\": \"https://forums.fast.ai/categories\", \"text\": \"Categories \"}, {\"link\": \"https://forums.fast.ai/guidelines\", \"text\": \"FAQ/Guidelines \"}, {\"link\": \"https://forums.fast.ai/tos\", \"text\": \"Terms of Service \"}, {\"link\": \"https://forums.fast.ai/privacy\", \"text\": \"Privacy Policy \"}, {\"link\": \"https://forums.fast.ai/\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389\", \"text\": \"\\n                Cloud GPUs: Comparison and Free Credits\\n              \"}, {\"link\": \"https://forums.fast.ai/c/deep-learning/18\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"hcarlens\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"Harald\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389\", \"text\": \"Feb '22\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389/9\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/jules43\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/purplemango\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/jules43\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/jules43\", \"text\": \"jules43\"}, {\"link\": \"https://forums.fast.ai/u/jules43\", \"text\": \"Jules\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389/2\", \"text\": \"Feb '22\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"hcarlens\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"Harald\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389/3\", \"text\": \"Feb '22\"}, {\"link\": \"https://forums.fast.ai/u/jhadjar\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/jhadjar\", \"text\": \"jhadjar\"}, {\"link\": \"https://forums.fast.ai/u/jhadjar\", \"text\": \"Jugurtha Hadjar\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389/4\", \"text\": \"Feb '22\"}, {\"link\": \"https://forums.fast.ai/u/hushitz\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/hushitz\", \"text\": \"hushitz\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389/5\", \"text\": \"Feb '22\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"hcarlens\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"Harald\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389/6\", \"text\": \"Feb '22\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"hcarlens\"}, {\"link\": \"https://forums.fast.ai/u/hcarlens\", \"text\": \"Harald\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389/7\", \"text\": \"Feb '22\"}, {\"link\": \"https://forums.fast.ai/u/hushitz\", \"text\": \"@hushitz\"}, {\"link\": \"https://forums.fast.ai/u/jules43\", \"text\": \"@jules43\"}, {\"link\": \"https://forums.fast.ai/u/jhadjar\", \"text\": \"@jhadjar\"}, {\"link\": \"https://forums.fast.ai/u/jules43\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/jules43\", \"text\": \"jules43\"}, {\"link\": \"https://forums.fast.ai/u/jules43\", \"text\": \"Jules\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389/8\", \"text\": \"Feb '22\"}, {\"link\": \"https://forums.fast.ai/u/purplemango\", \"text\": \"\"}, {\"link\": \"https://forums.fast.ai/u/purplemango\", \"text\": \"purplemango\"}, {\"link\": \"https://forums.fast.ai/t/cloud-gpus-comparison-and-free-credits/93389/9\", \"text\": \"Jun '22\"}]",
    "priceAndPlans": "fast.ai Course Forums\n\n#  Cost effectiveness of the different Cloud/Server renting options\n\nPart 1 (2017)\n\ntenoke November 3, 2017, 12:30pm  1\n\nNot everyone has their own server (and some of us missed out on the free aws\ncredits) so I am aiming to compile a list of the different Cloud options for\ndoing ML and their cost-effectiveness.\n\n  1. Not everyone knows of them, but for a while the chepest option for full time use has been hetzner with their 1080, 64gb ram dedicated server for 100/120 euro a month, with a setup fee of another 100/120 euros.\n\n  2. AWS (familiar to most here). K80 - $0.9 for p2.xlarge (as low as $0.1703 with spot pricing). M60 - $1.14 for g3.4xlarge (as low as $0.4 with spot pricing). V100 - p3.2xlarge - $3.06 per Hour ($0.613 for spot).  \nOn demand pricing Spot pricing \\- some are available only in specific regions\n(like Oregon), and they have a few more options\n\n  3. GCP \\- $0.70/0.77 per hour (gets as low as $0.49) for half a K80 or $2.30/2.53 for P100 (gets as low as $1.61).\n\n  4. Azure \\- K80/P100/P40 - $0.9/hr, M60 - $1.093/hr. Seems like a surprisingly good option, but haven\u2019t heard of many people using them.\n\n  5. Crestle \\- again, familiar to most here - $0.34/hr for K80.\n\n  6. Paperspace \\- P5000 for $0.65/hr, P6000 for $0.9/hr, V100 for $2.30/hr\n\nAnd then there are some monthly options that are a bit worse than hetzner - 1,\n2, 3, and some hourly options that are a bit worse than the rest e.g. -\nFloydhub \\- $0.7 for K80\n\nI haven\u2019t (recently) made the calculations of what is most cost-effective and\nI haven\u2019t tried most of the options. It\u2019d be very helpful if others can chime\nin, and we can compile any providers I might\u2019ve missed, and the best options\ndepending on what one wants to do, e.g.  \n_Hetzner_ for **full-time use** , _AWS/Azure_ for **hourly** , _Crestle_ for\n**fast-setup, cheap hourly** , etc.\n\nSome additional metrics like flops, or time to run a model on the different\nGPUs can also be useful.\n\nBest case scenario, it\u2019d be nice if we can turn this thread into a Wiki and\nkeep it up-to-date, as a sort of sister thread to the Making your own server\none.\n\n13 Likes\n\nAI Saturdays - Study Chapters in your city\n\nsvaisakh (Vaisakh)  November 4, 2017, 1:17pm  2\n\nI\u2019ve used FloydHub, Crestle and Paperspace.\n\nThese are my preliminary thoughts.\n\n**FloydHub** has a unique structure that takes getting used to.  \nYou create a new \u2018Project\u2019 and attach data to it.  \nThen, you can have a series of \u2018jobs\u2019 via .py scripts or Jupyter Notebooks.  \nThe workflow is not very intuitive IMO.  \nTheir Pricing is a bit higher compared to the other two ($0.75/h for a K80\neven at their highest $100/mo plan).\n\nRegardless, they have good funding (Y-Combinator), are on an aggressive growth\nspurt (improvements every few weeks), and have two dedicated co-founders in\n@sai and @narenst.  \nThings can only get better.\n\n**Crestle** , on the other hand, scores a 10/10 on the \u2018intuitiveness\u2019 scale.  \nIt literally cannot get any easier to do Deep Learning on the cloud.  \nYou just sign-up and BOOM - there\u2019s a Jupyter Notebook staring at you with\nunlimited home storage.  \nTwo of the things apart from the simplicity, that I like about them, is that:\n\n  1. You can switch between CPU and GPU using a neat little toggle switch. This saves you a ton of money considering the fact that most of your time will be spent coding and debugging. Very little time is spent on the \u2018training\u2019. This makes it easier to tinker with your code without worrying too much about the cost.\n\n  2. You get your own home directory, unlike FloydHub. This is much closer to what you actually would have in your local setup. It makes it easier to share files between notebooks and save data in a folder without having to worry about \u2018mounting\u2019 it. Whereas in Floyd, if you need to download a dataset (say from Kaggle using the CLI tool), you need to first run a job. Then you\u2019ll have to \u2018mount\u2019 the output of this \u2018job\u2019 which contains this data every single time you want to use it.\n\nCreated by our own @anurag, Crestle gives the same amount of compute (K80) at\nabout half the price ($0.34/h vs FloydHub\u2019s $0.75/h at best).\n\nThe only downside is the storage costs - $0.014/GB/day. So, if you\u2019re using\n~50GB (say), it\u2019ll end up costing you ~$20/mo.  \nAgain, this depends if you intend to persist the data (which for most purposes\nyou won\u2019t need to).\n\n> **Beware, though that both FloydHub and Crestle use EFS for handling file\n> storage**\n\nThis means, for instance, that you will have a painful time handling a large\nnumber of small files (which is what most datasets in Deep Learning/CV have).  \nI took me an hour and a half to extract the StateFarm dataset on both\nplatforms!\n\n**Paperspace** alleviates most of these problems.  \nYou get a full Desktop experience (not just a CLI).  \nThey have a P4000 GPU (comparable to the K80) at $0.4/h. But also, you can\nhave a P5000 ($0.65/h), a P6000 ($0.9/h almost 3x the performance of the K80 -\ncomparable to the 1080Ti).  \nThey also have the latest V100 (only AWS and Paperspace have them as of now)\nat $2.3/h!  \nYou can also subscribe monthly at a discount although Hetzner would be much\nmore cost-effective in that case.  \nThey currently have 3 data centres (2 in the US and 1 in Amsterdam) and are\nexpanding.\n\nApart from the straightforward, familiar experience and workflow (it\u2019s like\nyour own computer - only not local), the big upside for me is the SSD storage\n(not EFS unlike the other two). StateFarm only took a few seconds to extract -\nmuch like my local build (which is what you expect).  \nAlso, the storage starts at $5/mo for 50GB (against ~$20/mo in Crestle\u2019s case)\nand increases in $1 increments up to 250GB. The maximum is 2TB for $40/mo.\n\n_Paperspace also has a dedicated VM specifically for FastAI_.\n\nIn summary, if you\u2019re just getting started with Deep Learning, I\u2019d recommend\nCrestle for its sheer simplicity.\n\nIf you want a full cloud desktop and SSD, use Paperspace.\n\nI would recommend against using FloydHub for now.\n\nIf you ask me, personally, Paperspace is the winner for me. A personal cloud\ndesktop which I can customize according to my will and treat just like my\nlocal build seals the deal. Also, they have multiple GPU options and\ndatacentres and lower pricing.\n\n14 Likes\n\nsai (Sai Prashanth Soundararaj)  November 4, 2017, 4:46pm  3\n\nThanks for the thoughtful comparison, @svaisakh! (I\u2019m one of the co-founders\nat FloydHub)\n\n  * As of last week, **FloydHub offers SSD storage for all jobs**. No more EFS, so dealing with large number of files should be blazing fast\n\n  * We hear your feedback about making the Jupyter Notebook workflow more intuitive. We\u2019re working on it, and will have some improvements to share soon!\n\nFor the time being - a _Project_ is like a Github repo, a collection of your\njobs and data. Here\u2019s a quick 3-step tutorial to start running your Jupyter\nNotebook on FloydHub:\nhttps://docs.floydhub.com/getstarted/quick_start_jupyter/\n\n  * Pricing: Our current pricing is tiered, with the cheapest being $0.59/hr for K80 GPU (with the 100 hour _GPU Powerup_ ). We\u2019re working on a much simpler pricing plan, which should be out in a couple of weeks. Will update here then.\n\n  * GPUs: We currently have the Tesla K80 GPUs. We will be offering V100 very soon.\n\n  * We have a dedicated page for Fast AI: https://www.floydhub.com/explore/courses/fast-ai-part-1. This has all the class projects and datasets, along with instructions on how to get started easily.\n\nOther feature that FloydHub offers are version control and reproducibility -\nyou have full history and reproducibility of all your experiments, including\ncomparing and resuming your work.\n\nOverall, thanks for your feedback! We hear you and are actively working\ntowards making FloydHub more useful for you guys. I\u2019ll be around to answer\nquestions, or take suggestions/feedback.\n\n9 Likes\n\nwgpubs (WG)  November 4, 2017, 5:58pm  4\n\nNice writeup!\n\nFor me, I\u2019m sticking with AWS for the time being for three reasons:\n\n  1. That it represents what most companies are using in the real-world\n  2. That I\u2019ve automated the startup/shutdown via bash scripts so that I don\u2019t even need to touch the AWS console and have Jupyter notebook running in < 60 seconds.\n  3. The $500 credit.\n\nI really like paperspace and would be tempted to switch, or at least split my\ndevelopment time, working on it, if they matched the sweet deal we got from\nAmazon.\n\n4 Likes\n\nsvaisakh (Vaisakh)  November 5, 2017, 2:19am  5\n\nThanks, @sai.  \nWouldn\u2019t expect any less of you guys.\n\nThe SSD alone is a huge improvement for me.\n\nI guess I did forget to mention that the FloydHub workflow gives you full\nversion control - which is unique among all providers as far as I see.\n\nGood luck moving forward.\n\nP.S. Bring on the V100s, baby\n\ndc333 (doug chang)  November 8, 2017, 6:26pm  6\n\nNvidia GPU cloud is free. At least for now. https://www.nvidia.com/en-us/gpu-\ncloud/?ncid=pa-pai-\nnsdplgnclh3-25128&gclid=Cj0KCQiA84rQBRDCARIsAPO8RFwZ6c0Mbr1-iZt4KbPB65kCy6uMjzxOXPk2OguyJRR2Gv_Nyh6riP8aAn4oEALw_wcB\n\ntenoke November 8, 2017, 11:36pm  7\n\nAs far as I can tell this is just software (docker images), not free gpu time\nor something.\n\ndc333 (doug chang)  November 10, 2017, 1:43am  8\n\nMy bad: this one is free: https://research.google.com/colaboratory/faq.html\n\nI am using it now\u2026 you have to use TF though. Should work for your class\nprojects. Well if you convert from pytorch back to tf.\n\n1 Like\n\nsvaisakh (Vaisakh)  November 10, 2017, 8:56am  9\n\nInteresting\n\nSeems invite only.  \nDetails are sparse.\n\n@dc333, if you\u2019ve got access to it, could you please share your experience?\n\nWhat\u2019s the config like?  \nI don\u2019t think a GPU is included, in which case it won\u2019t take us very far.\n\ndc333 (doug chang)  November 20, 2017, 10:58pm  10\n\n!pip install -q\nhttp://download.pytorch.org/whl/cu75/torch-0.2.0.post3-cp27-cp27mu-\nmanylinux1_x86_64.whl  \n!pip install future\n\ncolab runs torch\u2026\n\ntenoke November 21, 2017, 11:55am  11\n\nUpdate: GCP lowers GPU pricing by up to 36%: K80 at 40c/hr and P100 at\n$1.46/hr\n\nmalrod December 24, 2017, 11:11am  12\n\n**Cresle** currently gives only 1 free hour of GPU usage, and **cost 0.59$/h**\n.  \nAt this moment **Google Cloud** is cheaper at **0.49$/h** for K80, comes with\n300$ free credit and was surprising easy to set up even for a beginner like\nme.\n\nSo, atm google cloud seems like a great option - about 600 hours of free gpu\nuse, and relatively easy to set up.  \nAlso it\u2019s possible to choose p100 instead of k80, which costs 1.6$/h\n\nsvaisakh (Vaisakh)  December 26, 2017, 3:59pm  14\n\n@malrod,  \nI tried Google Cloud (a.k.a GCP).  \nIt seems that GPUs cannot be provisioned under the free trial.\n\nHave you successfully managed to create and use a GPU instance?\n\nmalrod December 27, 2017, 5:29am  15\n\n@svaisakh You can use your 300$ credit for GPUs ! But you need to increase you\nGPU quotas first (they are at 0 as a default -that\u2019s why you cannot lauch a\nGPU instance straight-away).  \nGo to quotas page ( _compute engine- >quotas-> edit quotas_) and request an\nincrease in K80 and/or preemtible K80 in your zone - the process is automatic\nand it should be increased within minutes.  \nhttps://cloud.google.com/compute/quotas  \nYou\u2019ll be asked to upgrade your account first, meaning that **after** using\nall 300$ of free credit you\u2019ll be automatically charged for any additional\nuse. But as long as you have any promotional funds left, they\u2019ll be used\nfirst.  \nSounds too good to be true, but with K80 costing 0.49$/h and preemptible k80\nat 0.22$/h, that works out to be hundreds of hours of free GPU use.\n\nI used K80, preemptible (spot) K80 and P100 and the billing details tell me\nthat I spent 7.7$ and have 292$ remaining on my account and total amount\nbilled is 0$:\n\n    \n    \n    Credits\n    Promotion ID\tExpires\tPromotion value\tAmount remaining\n    Free Trial \t17 Dec 2018\t$300.00\t        $292.26\n\n1 Like\n\nsvaisakh (Vaisakh)  December 27, 2017, 7:05am  16\n\nWow!\n\nAnd I always thought the \u2018upgrade\u2019 meant they\u2019d get rid of the promotional\ncredits.\n\nGuess I should start reading more carefully.\n\nThanks a lot @malrod\n\ntgb417 (Tom Brown)  January 1, 2018, 9:03pm  18\n\nI\u2019ve discovered the following educational discount. I\u2019m going to ask to see if\nthis can be used in conjunction with the fast.ai course.\n\npaperspace.com\n\n### Paperspace\n\nCloud Machine Learning, AI, and effortless GPU infrastructure\n\n\u2026 Time Passes \u2026\n\nIt looks like they have granted me a discount code. Looks like you will have\nto ask for your own code if you are in any way associated with an educational\ninstitution.\n\nJust waiting for my Umbuto 16.04 in the East Coast region on a box with a\nP4000 GPU.\n\n\u2026 More time Passes \u2026  \nI was refused a P4000 GPU. I\u2019m using the GPU+ Quadro M4000 30 GB RAM based\nsystem.\n\naseem January 2, 2018, 10:40am  19\n\nI am not sure but you can get max 30$ from paperspace\n\nFirst create the account via Fast AI Promo link\n\nhttps://www.paperspace.com/&R=FASTAI15\n\nOnce account is created go to Billing, Don\u2019t add your credit card just go to\nbilling\n\nadd this as promo code **DDQRI0U** you would get 10$\n\nNow on the Machine tab create your machine as instructed in the video\n\nBelow the credit card tab there is another promo tab\n\nadd this as promo code **HNGPU5** you would get another 5 $\n\nonce you do this then add your credit card details. You would have 30$\n\n3 Likes\n\nsourabhXIII February 18, 2018, 7:04am  20\n\naseem:\n\n> HNGPU5\n\nAlas. This code has expired.\n\ntenoke February 23, 2018, 4:37pm  21\n\nFor those that already have access to Google\u2019s TPUs here is a benchmark making\nthe rounds, which suggests that TPUs are significantly more cost-effective (in\nat least some cases) than at least the V100s and P100s available on\ngoogle/aws.  \nHN Discussion mentions some caveats.\n\n1 Like\n\naseem March 6, 2018, 2:27am  22\n\ntry **LAUNCH5PX** instead of the **HNGPU5**\n\n**next page \u2192**\n\n  * Home \n  * Categories \n  * FAQ/Guidelines \n  * Terms of Service \n  * Privacy Policy \n\nPowered by Discourse, best viewed with JavaScript enabled\n\nSkip to main content\n\nSign UpLog In\n\n  *   * \n\n#\n\nCost effectiveness of the different Cloud/Server renting options\n\nPart 1 (2017)\n\nYou have selected **0** posts.\n\nselect all\n\ncancel selecting\n\nNov 2017\n\n1 / 26\n\nNov 2017\n\nMay 2018\n\ntenoke\n\n1\n\nNov '17\n\nNot everyone has their own server (and some of us missed out on the free aws\ncredits) so I am aiming to compile a list of the different Cloud options for\ndoing ML and their cost-effectiveness.\n\n  1. Not everyone knows of them, but for a while the chepest option for full time use has been hetzner with their 1080, 64gb ram dedicated server 411 for 100/120 euro a month, with a setup fee of another 100/120 euros.\n\n  2. AWS (familiar to most here). K80 - $0.9 for p2.xlarge (as low as $0.1703 with spot pricing). M60 - $1.14 for g3.4xlarge (as low as $0.4 with spot pricing). V100 - p3.2xlarge - $3.06 per Hour ($0.613 for spot).  \nOn demand pricing 56 Spot pricing 115 \\- some are available only in specific\nregions (like Oregon), and they have a few more options\n\n  3. GCP 132 \\- $0.70/0.77 per hour (gets as low as $0.49) for half a K80 or $2.30/2.53 for P100 (gets as low as $1.61).\n\n  4. Azure 95 \\- K80/P100/P40 - $0.9/hr, M60 - $1.093/hr. Seems like a surprisingly good option, but haven\u2019t heard of many people using them.\n\n  5. Crestle 537 \\- again, familiar to most here - $0.34/hr for K80.\n\n  6. Paperspace 161 \\- P5000 for $0.65/hr, P6000 for $0.9/hr, V100 for $2.30/hr\n\nAnd then there are some monthly options that are a bit worse than hetzner - 1\n38, 2 25, 3 20, and some hourly options that are a bit worse than the rest\ne.g. - Floydhub 48 \\- $0.7 for K80\n\nI haven\u2019t (recently) made the calculations of what is most cost-effective and\nI haven\u2019t tried most of the options. It\u2019d be very helpful if others can chime\nin, and we can compile any providers I might\u2019ve missed, and the best options\ndepending on what one wants to do, e.g.  \n_Hetzner_ for **full-time use** , _AWS/Azure_ for **hourly** , _Crestle_ for\n**fast-setup, cheap hourly** , etc.\n\nSome additional metrics like flops, or time to run a model on the different\nGPUs can also be useful.\n\nBest case scenario, it\u2019d be nice if we can turn this thread into a Wiki and\nkeep it up-to-date, as a sort of sister thread to the Making your own server\none.\n\n13\n\n  * AI Saturdays - Study Chapters in your city3\n\n  * #### created\n\nNov '17\n\n  * #### last reply\n\nMay '18\n\n  * 25\n\n#### replies\n\n  * 18.8k\n\n#### views\n\n  * 11\n\n#### users\n\n  * 48\n\n#### likes\n\n  * 25\n\n#### links\n\n  * 7\n\n4\n\n3\n\nsvaisakhVaisakh\n\nNov '17\n\nI\u2019ve used FloydHub, Crestle and Paperspace.\n\nThese are my preliminary thoughts.\n\n**FloydHub** has a unique structure that takes getting used to.  \nYou create a new \u2018Project\u2019 and attach data to it.  \nThen, you can have a series of \u2018jobs\u2019 via .py scripts or Jupyter Notebooks.  \nThe workflow is not very intuitive IMO.  \nTheir Pricing is a bit higher compared to the other two ($0.75/h for a K80\neven at their highest $100/mo plan).\n\nRegardless, they have good funding (Y-Combinator), are on an aggressive growth\nspurt (improvements every few weeks), and have two dedicated co-founders in\n@sai and @narenst.  \nThings can only get better.\n\n**Crestle** , on the other hand, scores a 10/10 on the \u2018intuitiveness\u2019 scale.  \nIt literally cannot get any easier to do Deep Learning on the cloud.  \nYou just sign-up and BOOM - there\u2019s a Jupyter Notebook staring at you with\nunlimited home storage.  \nTwo of the things apart from the simplicity, that I like about them, is that:\n\n  1. You can switch between CPU and GPU using a neat little toggle switch. This saves you a ton of money considering the fact that most of your time will be spent coding and debugging. Very little time is spent on the \u2018training\u2019. This makes it easier to tinker with your code without worrying too much about the cost.\n\n  2. You get your own home directory, unlike FloydHub. This is much closer to what you actually would have in your local setup. It makes it easier to share files between notebooks and save data in a folder without having to worry about \u2018mounting\u2019 it. Whereas in Floyd, if you need to download a dataset (say from Kaggle using the CLI tool), you need to first run a job. Then you\u2019ll have to \u2018mount\u2019 the output of this \u2018job\u2019 which contains this data every single time you want to use it.\n\nCreated by our own @anurag, Crestle gives the same amount of compute (K80) at\nabout half the price ($0.34/h vs FloydHub\u2019s $0.75/h at best).\n\nThe only downside is the storage costs - $0.014/GB/day. So, if you\u2019re using\n~50GB (say), it\u2019ll end up costing you ~$20/mo.  \nAgain, this depends if you intend to persist the data (which for most purposes\nyou won\u2019t need to).\n\n> **Beware, though that both FloydHub and Crestle use EFS for handling file\n> storage**\n\nThis means, for instance, that you will have a painful time handling a large\nnumber of small files (which is what most datasets in Deep Learning/CV have).  \nI took me an hour and a half to extract the StateFarm dataset on both\nplatforms!\n\n**Paperspace** alleviates most of these problems.  \nYou get a full Desktop experience (not just a CLI).  \nThey have a P4000 GPU (comparable to the K80) at $0.4/h. But also, you can\nhave a P5000 ($0.65/h), a P6000 ($0.9/h almost 3x the performance of the K80 -\ncomparable to the 1080Ti).  \nThey also have the latest V100 (only AWS and Paperspace have them as of now)\nat $2.3/h!  \nYou can also subscribe monthly at a discount although Hetzner would be much\nmore cost-effective in that case.  \nThey currently have 3 data centres (2 in the US and 1 in Amsterdam) and are\nexpanding.\n\nApart from the straightforward, familiar experience and workflow (it\u2019s like\nyour own computer - only not local), the big upside for me is the SSD storage\n(not EFS unlike the other two). StateFarm only took a few seconds to extract -\nmuch like my local build (which is what you expect).  \nAlso, the storage starts at $5/mo for 50GB (against ~$20/mo in Crestle\u2019s case)\nand increases in $1 increments up to 250GB. The maximum is 2TB for $40/mo.\n\n_Paperspace also has a dedicated VM specifically for FastAI_.\n\nIn summary, if you\u2019re just getting started with Deep Learning, I\u2019d recommend\nCrestle for its sheer simplicity.\n\nIf you want a full cloud desktop and SSD, use Paperspace.\n\nI would recommend against using FloydHub for now.\n\nIf you ask me, personally, Paperspace is the winner for me. A personal cloud\ndesktop which I can customize according to my will and treat just like my\nlocal build seals the deal. Also, they have multiple GPU options and\ndatacentres and lower pricing.\n\n14\n\nsaiSai Prashanth Soundararaj\n\n2\n\nNov '17\n\nThanks for the thoughtful comparison, @svaisakh! (I\u2019m one of the co-founders\nat FloydHub)\n\n  * As of last week, **FloydHub offers SSD storage for all jobs**. No more EFS, so dealing with large number of files should be blazing fast\n\n  * We hear your feedback about making the Jupyter Notebook workflow more intuitive. We\u2019re working on it, and will have some improvements to share soon!\n\nFor the time being - a _Project_ is like a Github repo, a collection of your\njobs and data. Here\u2019s a quick 3-step tutorial to start running your Jupyter\nNotebook on FloydHub:\nhttps://docs.floydhub.com/getstarted/quick_start_jupyter/ 27\n\n  * Pricing: Our current pricing is tiered, with the cheapest being $0.59/hr for K80 GPU (with the 100 hour _GPU Powerup_ ). We\u2019re working on a much simpler pricing plan, which should be out in a couple of weeks. Will update here then.\n\n  * GPUs: We currently have the Tesla K80 GPUs. We will be offering V100 very soon.\n\n  * We have a dedicated page for Fast AI: https://www.floydhub.com/explore/courses/fast-ai-part-1 51. This has all the class projects and datasets, along with instructions on how to get started easily.\n\nOther feature that FloydHub offers are version control and reproducibility -\nyou have full history and reproducibility of all your experiments, including\ncomparing and resuming your work 7.\n\nOverall, thanks for your feedback! We hear you and are actively working\ntowards making FloydHub more useful for you guys. I\u2019ll be around to answer\nquestions, or take suggestions/feedback.\n\n1 Reply\n\n9\n\nwgpubsWGLeader\n\nNov '17\n\nNice writeup!\n\nFor me, I\u2019m sticking with AWS for the time being for three reasons:\n\n  1. That it represents what most companies are using in the real-world\n  2. That I\u2019ve automated the startup/shutdown via bash scripts so that I don\u2019t even need to touch the AWS console and have Jupyter notebook running in < 60 seconds.\n  3. The $500 credit.\n\nI really like paperspace and would be tempted to switch, or at least split my\ndevelopment time, working on it, if they matched the sweet deal we got from\nAmazon.\n\n4\n\nsvaisakhVaisakh\n\nsai\n\nNov '17\n\nThanks, @sai.  \nWouldn\u2019t expect any less of you guys.\n\nThe SSD alone is a huge improvement for me.\n\nI guess I did forget to mention that the FloydHub workflow gives you full\nversion control - which is unique among all providers as far as I see.\n\nGood luck moving forward.\n\nP.S. Bring on the V100s, baby\n\ndc333doug chang\n\nNov '17\n\nNvidia GPU cloud is free. At least for now. https://www.nvidia.com/en-us/gpu-\ncloud/?ncid=pa-pai-\nnsdplgnclh3-25128&gclid=Cj0KCQiA84rQBRDCARIsAPO8RFwZ6c0Mbr1-iZt4KbPB65kCy6uMjzxOXPk2OguyJRR2Gv_Nyh6riP8aAn4oEALw_wcB\n447\n\ntenoke\n\nNov '17\n\nAs far as I can tell this is just software (docker images), not free gpu time\nor something.\n\ndc333doug chang\n\nNov '17\n\nMy bad: this one is free: https://research.google.com/colaboratory/faq.html\n214\n\nI am using it now\u2026 you have to use TF though. Should work for your class\nprojects. Well if you convert from pytorch back to tf.\n\n1\n\nsvaisakhVaisakh\n\nNov '17\n\nInteresting\n\nSeems invite only.  \nDetails are sparse.\n\n@dc333, if you\u2019ve got access to it, could you please share your experience?\n\nWhat\u2019s the config like?  \nI don\u2019t think a GPU is included, in which case it won\u2019t take us very far.\n\n10 days later\n\ndc333doug chang\n\nNov '17\n\n!pip install -q\nhttp://download.pytorch.org/whl/cu75/torch-0.2.0.post3-cp27-cp27mu-\nmanylinux1_x86_64.whl 8  \n!pip install future\n\ncolab runs torch\u2026\n\ntenoke\n\nNov '17\n\nUpdate: GCP lowers GPU pricing by up to 36%: K80 at 40c/hr and P100 at\n$1.46/hr 81\n\n1 month later\n\nmalrod\n\nDec '17\n\n **Cresle** currently gives only 1 free hour of GPU usage, and **cost\n0.59$/h** .  \nAt this moment **Google Cloud** is cheaper at **0.49$/h** for K80, comes with\n300$ free credit and was surprising easy to set up even for a beginner like\nme.\n\nSo, atm google cloud seems like a great option - about 600 hours of free gpu\nuse, and relatively easy to set up.  \nAlso it\u2019s possible to choose p100 instead of k80, which costs 1.6$/h\n\nsvaisakhVaisakh\n\nDec '17\n\n@malrod,  \nI tried Google Cloud (a.k.a GCP).  \nIt seems that GPUs cannot be provisioned under the free trial.\n\nHave you successfully managed to create and use a GPU instance?\n\nmalrod\n\n4\n\nDec '17\n\n@svaisakh You can use your 300$ credit for GPUs ! But you need to increase you\nGPU quotas first (they are at 0 as a default -that\u2019s why you cannot lauch a\nGPU instance straight-away).  \nGo to quotas page ( _compute engine- >quotas-> edit quotas_) and request an\nincrease in K80 and/or preemtible K80 in your zone - the process is automatic\nand it should be increased within minutes.  \nhttps://cloud.google.com/compute/quotas 43  \nYou\u2019ll be asked to upgrade your account first, meaning that **after** using\nall 300$ of free credit you\u2019ll be automatically charged for any additional\nuse. But as long as you have any promotional funds left, they\u2019ll be used\nfirst.  \nSounds too good to be true, but with K80 costing 0.49$/h and preemptible k80\nat 0.22$/h, that works out to be hundreds of hours of free GPU use.\n\nI used K80, preemptible (spot) K80 and P100 and the billing details tell me\nthat I spent 7.7$ and have 292$ remaining on my account and total amount\nbilled is 0$:\n\n    \n    \n    Credits\n    Promotion ID\tExpires\tPromotion value\tAmount remaining\n    Free Trial \t17 Dec 2018\t$300.00\t        $292.26\n\n2 Replies\n\n1\n\nsvaisakhVaisakh\n\nDec '17\n\nWow!\n\nAnd I always thought the \u2018upgrade\u2019 meant they\u2019d get rid of the promotional\ncredits.\n\nGuess I should start reading more carefully.\n\nThanks a lot @malrod\n\ntgb417Tom Brown\n\n3\n\ntgb417\n\nJan '18\n\nI\u2019ve discovered the following educational discount. I\u2019m going to ask to see if\nthis can be used in conjunction with the fast.ai course.\n\npaperspace.com\n\n### Paperspace 10\n\nCloud Machine Learning, AI, and effortless GPU infrastructure\n\n\u2026 Time Passes \u2026\n\nIt looks like they have granted me a discount code. Looks like you will have\nto ask for your own code if you are in any way associated with an educational\ninstitution.\n\nJust waiting for my Umbuto 16.04 in the East Coast region on a box with a\nP4000 GPU.\n\n\u2026 More time Passes \u2026  \nI was refused a P4000 GPU. I\u2019m using the GPU+ Quadro M4000 30 GB RAM based\nsystem.\n\naseem\n\n1\n\nJan '18\n\nI am not sure but you can get max 30$ from paperspace\n\nFirst create the account via Fast AI Promo link\n\nhttps://www.paperspace.com/&R=FASTAI15 119\n\nOnce account is created go to Billing, Don\u2019t add your credit card just go to\nbilling\n\nadd this as promo code **DDQRI0U** you would get 10$\n\nNow on the Machine tab create your machine as instructed in the video\n\nBelow the credit card tab there is another promo tab\n\nadd this as promo code **HNGPU5** you would get another 5 $\n\nonce you do this then add your credit card details. You would have 30$\n\n3\n\n2 months later\n\nsourabhXIII\n\nFeb '18\n\naseem:\n\n> HNGPU5\n\nAlas. This code has expired.\n\n1 Reply\n\ntenoke\n\n1\n\nFeb '18\n\nFor those that already have access to Google\u2019s TPUs here is a benchmark 70\nmaking the rounds, which suggests that TPUs are significantly more cost-\neffective (in at least some cases) than at least the V100s and P100s available\non google/aws.  \nHN Discussion 32 mentions some caveats.\n\n1\n\n10 days later\n\naseem\n\nsourabhXIII\n\nMar '18\n\ntry **LAUNCH5PX** instead of the **HNGPU5**\n\n\u200b\n\n\u200b  Invalid date  \u200b Invalid date\n\n"
}