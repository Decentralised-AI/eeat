{
    "summary": "Skip to main content\n\n#  R for Data Science\n\n__Show table of contents\n\n## Table of contents\n\n  * Welcome\n  * 1 Introduction\n  * Explore\n  * 2 Introduction\n  * 3 Data visualisation\n  * 4 Workflow: basics\n  * 5 Data transformation\n  * 6 Workflow: scripts\n  * 7 Exploratory Data Analysis\n  * 8 Workflow: projects\n  * Wrangle\n  * 9 Introduction\n  * 10 Tibbles\n  * 11 Data import\n  * 12 Tidy data\n  * 13 Relational data\n  * 14 Strings\n  * 15 Factors\n  * 16 Dates and times\n  * Program\n  * 17 Introduction\n  * 18 Pipes\n  * 19 Functions\n  * 20 Vectors\n  * 21 Iteration\n  * Model\n  * 22 Introduction\n  * 23 Model basics\n  * 24 Model building\n  * 25 Many models\n  * Communicate\n  * 26 Introduction\n  * 27 R Markdown\n  * 28 Graphics for communication\n  * 29 R Markdown formats\n  * 30 R Markdown workflow\n\n#  5 Data transformation __\n\nYou\u2019re reading the first edition of R4DS; for the latest on this topic see the\n**Data transformation chapter** in the second edition.\n\n##  5.1 Introduction __\n\nVisualisation is an important tool for insight generation, but it is rare that\nyou get the data in exactly the right form you need. Often you\u2019ll need to\ncreate some new variables or summaries, or maybe you just want to rename the\nvariables or reorder the observations in order to make the data a little\neasier to work with. You\u2019ll learn how to do all that (and more!) in this\nchapter, which will teach you how to transform your data using the dplyr\npackage and a new dataset on flights departing New York City in 2013.\n\n###  5.1.1 Prerequisites __\n\nIn this chapter we\u2019re going to focus on how to use the dplyr package, another\ncore member of the tidyverse. We\u2019ll illustrate the key ideas using data from\nthe nycflights13 package, and use ggplot2 to help us understand the data.\n\n    \n    \n    library(nycflights13)\n    library(tidyverse)\n\n __\n\nTake careful note of the conflicts message that\u2019s printed when you load the\ntidyverse. It tells you that dplyr overwrites some functions in base R. If you\nwant to use the base version of these functions after loading dplyr, you\u2019ll\nneed to use their full names: `stats::filter()` and `stats::lag()`.\n\n###  5.1.2 nycflights13 __\n\nTo explore the basic data manipulation verbs of dplyr, we\u2019ll use\n`nycflights13::flights`. This data frame contains all 336,776 flights that\ndeparted from New York City in 2013. The data comes from the US Bureau of\nTransportation Statistics, and is documented in `?flights`.\n\n    \n    \n    flights\n    #> # A tibble: 336,776 \u00d7 19\n    #>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    #>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n    #> 1  2013     1     1      517            515         2      830            819\n    #> 2  2013     1     1      533            529         4      850            830\n    #> 3  2013     1     1      542            540         2      923            850\n    #> 4  2013     1     1      544            545        -1     1004           1022\n    #> 5  2013     1     1      554            600        -6      812            837\n    #> 6  2013     1     1      554            558        -4      740            728\n    #> # \u2139 336,770 more rows\n    #> # \u2139 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n    #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n    #> #   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n __\n\nYou might notice that this data frame prints a little differently from other\ndata frames you might have used in the past: it only shows the first few rows\nand all the columns that fit on one screen. (To see the whole dataset, you can\nrun `View(flights)` which will open the dataset in the RStudio viewer). It\nprints differently because it\u2019s a **tibble**. Tibbles are data frames, but\nslightly tweaked to work better in the tidyverse. For now, you don\u2019t need to\nworry about the differences; we\u2019ll come back to tibbles in more detail in\nwrangle.\n\nYou might also have noticed the row of three (or four) letter abbreviations\nunder the column names. These describe the type of each variable:\n\n  * `int` stands for integers.\n\n  * `dbl` stands for doubles, or real numbers.\n\n  * `chr` stands for character vectors, or strings.\n\n  * `dttm` stands for date-times (a date + a time).\n\nThere are three other common types of variables that aren\u2019t used in this\ndataset but you\u2019ll encounter later in the book:\n\n  * `lgl` stands for logical, vectors that contain only `TRUE` or `FALSE`.\n\n  * `fctr` stands for factors, which R uses to represent categorical variables with fixed possible values.\n\n  * `date` stands for dates.\n\n###  5.1.3 dplyr basics __\n\nIn this chapter you are going to learn the five key dplyr functions that allow\nyou to solve the vast majority of your data manipulation challenges:\n\n  * Pick observations by their values (`filter()`).\n  * Reorder the rows (`arrange()`).\n  * Pick variables by their names (`select()`).\n  * Create new variables with functions of existing variables (`mutate()`).\n  * Collapse many values down to a single summary (`summarise()`).\n\nThese can all be used in conjunction with `group_by()` which changes the scope\nof each function from operating on the entire dataset to operating on it\ngroup-by-group. These six functions provide the verbs for a language of data\nmanipulation.\n\nAll verbs work similarly:\n\n  1. The first argument is a data frame.\n\n  2. The subsequent arguments describe what to do with the data frame, using the variable names (without quotes).\n\n  3. The result is a new data frame.\n\nTogether these properties make it easy to chain together multiple simple steps\nto achieve a complex result. Let\u2019s dive in and see how these verbs work.\n\n##  5.2 Filter rows with `filter()` __\n\n`filter()` allows you to subset observations based on their values. The first\nargument is the name of the data frame. The second and subsequent arguments\nare the expressions that filter the data frame. For example, we can select all\nflights on January 1st with:\n\n    \n    \n    filter(flights, month == 1, day == 1)\n    #> # A tibble: 842 \u00d7 19\n    #>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    #>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n    #> 1  2013     1     1      517            515         2      830            819\n    #> 2  2013     1     1      533            529         4      850            830\n    #> 3  2013     1     1      542            540         2      923            850\n    #> 4  2013     1     1      544            545        -1     1004           1022\n    #> 5  2013     1     1      554            600        -6      812            837\n    #> 6  2013     1     1      554            558        -4      740            728\n    #> # \u2139 836 more rows\n    #> # \u2139 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n    #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n    #> #   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n __\n\nWhen you run that line of code, dplyr executes the filtering operation and\nreturns a new data frame. dplyr functions never modify their inputs, so if you\nwant to save the result, you\u2019ll need to use the assignment operator, `<-`:\n\n    \n    \n    jan1 <- filter(flights, month == 1, day == 1)\n\n __\n\nR either prints out the results, or saves them to a variable. If you want to\ndo both, you can wrap the assignment in parentheses:\n\n    \n    \n    (dec25 <- filter(flights, month == 12, day == 25))\n    #> # A tibble: 719 \u00d7 19\n    #>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    #>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n    #> 1  2013    12    25      456            500        -4      649            651\n    #> 2  2013    12    25      524            515         9      805            814\n    #> 3  2013    12    25      542            540         2      832            850\n    #> 4  2013    12    25      546            550        -4     1022           1027\n    #> 5  2013    12    25      556            600        -4      730            745\n    #> 6  2013    12    25      557            600        -3      743            752\n    #> # \u2139 713 more rows\n    #> # \u2139 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n    #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n    #> #   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n __\n\n###  5.2.1 Comparisons __\n\nTo use filtering effectively, you have to know how to select the observations\nthat you want using the comparison operators. R provides the standard suite:\n`>`, `>=`, `<`, `<=`, `!=` (not equal), and `==` (equal).\n\nWhen you\u2019re starting out with R, the easiest mistake to make is to use `=`\ninstead of `==` when testing for equality. When this happens you\u2019ll get an\ninformative error:\n\n    \n    \n    filter(flights, month = 1)\n    #> Error in `filter()`:\n    #> ! We detected a named input.\n    #> \u2139 This usually means that you've used `=` instead of `==`.\n    #> \u2139 Did you mean `month == 1`?\n\n __\n\nThere\u2019s another common problem you might encounter when using `==`: floating\npoint numbers. These results might surprise you!\n\n    \n    \n    sqrt(2) ^ 2 == 2\n    #> [1] FALSE\n    1 / 49 * 49 == 1\n    #> [1] FALSE\n\n __\n\nComputers use finite precision arithmetic (they obviously can\u2019t store an\ninfinite number of digits!) so remember that every number you see is an\napproximation. Instead of relying on `==`, use `near()`:\n\n    \n    \n    near(sqrt(2) ^ 2,  2)\n    #> [1] TRUE\n    near(1 / 49 * 49, 1)\n    #> [1] TRUE\n\n __\n\n###  5.2.2 Logical operators __\n\nMultiple arguments to `filter()` are combined with \u201cand\u201d: every expression\nmust be true in order for a row to be included in the output. For other types\nof combinations, you\u2019ll need to use Boolean operators yourself: `&` is \u201cand\u201d,\n`|` is \u201cor\u201d, and `!` is \u201cnot\u201d. Figure 5.1 shows the complete set of Boolean\noperations.\n\nFigure 5.1: Complete set of boolean operations. `x` is the left-hand circle,\n`y` is the right-hand circle, and the shaded region show which parts each\noperator selects.\n\nThe following code finds all flights that departed in November or December:\n\n    \n    \n    filter(flights, month == 11 | month == 12)\n\n __\n\nThe order of operations doesn\u2019t work like English. You can\u2019t write\n`filter(flights, month == (11 | 12))`, which you might literally translate\ninto \u201cfinds all flights that departed in November or December\u201d. Instead it\nfinds all months that equal `11 | 12`, an expression that evaluates to `TRUE`.\nIn a numeric context (like here), `TRUE` becomes one, so this finds all\nflights in January, not November or December. This is quite confusing!\n\nA useful short-hand for this problem is `x %in% y`. This will select every row\nwhere `x` is one of the values in `y`. We could use it to rewrite the code\nabove:\n\n    \n    \n    nov_dec <- filter(flights, month %in% c(11, 12))\n\n __\n\nSometimes you can simplify complicated subsetting by remembering De Morgan\u2019s\nlaw: `!(x & y)` is the same as `!x | !y`, and `!(x | y)` is the same as `!x &\n!y`. For example, if you wanted to find flights that weren\u2019t delayed (on\narrival or departure) by more than two hours, you could use either of the\nfollowing two filters:\n\n    \n    \n    filter(flights, !(arr_delay > 120 | dep_delay > 120))\n    filter(flights, arr_delay <= 120, dep_delay <= 120)\n\n __\n\nAs well as `&` and `|`, R also has `&&` and `||`. Don\u2019t use them here! You\u2019ll\nlearn when you should use them in conditional execution.\n\nWhenever you start using complicated, multipart expressions in `filter()`,\nconsider making them explicit variables instead. That makes it much easier to\ncheck your work. You\u2019ll learn how to create new variables shortly.\n\n###  5.2.3 Missing values __\n\nOne important feature of R that can make comparison tricky are missing values,\nor `NA`s (\u201cnot availables\u201d). `NA` represents an unknown value so missing\nvalues are \u201ccontagious\u201d: almost any operation involving an unknown value will\nalso be unknown.\n\n    \n    \n    NA > 5\n    #> [1] NA\n    10 == NA\n    #> [1] NA\n    NA + 10\n    #> [1] NA\n    NA / 2\n    #> [1] NA\n\n __\n\nThe most confusing result is this one:\n\n    \n    \n    NA == NA\n    #> [1] NA\n\n __\n\nIt\u2019s easiest to understand why this is true with a bit more context:\n\n    \n    \n    # Let x be Mary's age. We don't know how old she is.\n    x <- NA\n    \n    # Let y be John's age. We don't know how old he is.\n    y <- NA\n    \n    # Are John and Mary the same age?\n    x == y\n    #> [1] NA\n    # We don't know!\n\n __\n\nIf you want to determine if a value is missing, use `is.na()`:\n\n    \n    \n    is.na(x)\n    #> [1] TRUE\n\n __\n\n`filter()` only includes rows where the condition is `TRUE`; it excludes both\n`FALSE` and `NA` values. If you want to preserve missing values, ask for them\nexplicitly:\n\n    \n    \n    df <- tibble(x = c(1, NA, 3))\n    filter(df, x > 1)\n    #> # A tibble: 1 \u00d7 1\n    #>       x\n    #>   <dbl>\n    #> 1     3\n    filter(df, is.na(x) | x > 1)\n    #> # A tibble: 2 \u00d7 1\n    #>       x\n    #>   <dbl>\n    #> 1    NA\n    #> 2     3\n\n __\n\n###  5.2.4 Exercises __\n\n  1. Find all flights that\n\n    1. Had an arrival delay of two or more hours\n    2. Flew to Houston (`IAH` or `HOU`)\n    3. Were operated by United, American, or Delta\n    4. Departed in summer (July, August, and September)\n    5. Arrived more than two hours late, but didn\u2019t leave late\n    6. Were delayed by at least an hour, but made up over 30 minutes in flight\n    7. Departed between midnight and 6am (inclusive)\n  2. Another useful dplyr filtering helper is `between()`. What does it do? Can you use it to simplify the code needed to answer the previous challenges?\n\n  3. How many flights have a missing `dep_time`? What other variables are missing? What might these rows represent?\n\n  4. Why is `NA ^ 0` not missing? Why is `NA | TRUE` not missing? Why is `FALSE & NA` not missing? Can you figure out the general rule? (`NA * 0` is a tricky counterexample!)\n\n##  5.3 Arrange rows with `arrange()` __\n\n`arrange()` works similarly to `filter()` except that instead of selecting\nrows, it changes their order. It takes a data frame and a set of column names\n(or more complicated expressions) to order by. If you provide more than one\ncolumn name, each additional column will be used to break ties in the values\nof preceding columns:\n\n    \n    \n    arrange(flights, year, month, day)\n    #> # A tibble: 336,776 \u00d7 19\n    #>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    #>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n    #> 1  2013     1     1      517            515         2      830            819\n    #> 2  2013     1     1      533            529         4      850            830\n    #> 3  2013     1     1      542            540         2      923            850\n    #> 4  2013     1     1      544            545        -1     1004           1022\n    #> 5  2013     1     1      554            600        -6      812            837\n    #> 6  2013     1     1      554            558        -4      740            728\n    #> # \u2139 336,770 more rows\n    #> # \u2139 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n    #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n    #> #   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n __\n\nUse `desc()` to re-order by a column in descending order:\n\n    \n    \n    arrange(flights, desc(dep_delay))\n    #> # A tibble: 336,776 \u00d7 19\n    #>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    #>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n    #> 1  2013     1     9      641            900      1301     1242           1530\n    #> 2  2013     6    15     1432           1935      1137     1607           2120\n    #> 3  2013     1    10     1121           1635      1126     1239           1810\n    #> 4  2013     9    20     1139           1845      1014     1457           2210\n    #> 5  2013     7    22      845           1600      1005     1044           1815\n    #> 6  2013     4    10     1100           1900       960     1342           2211\n    #> # \u2139 336,770 more rows\n    #> # \u2139 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n    #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n    #> #   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n __\n\nMissing values are always sorted at the end:\n\n    \n    \n    df <- tibble(x = c(5, 2, NA))\n    arrange(df, x)\n    #> # A tibble: 3 \u00d7 1\n    #>       x\n    #>   <dbl>\n    #> 1     2\n    #> 2     5\n    #> 3    NA\n    arrange(df, desc(x))\n    #> # A tibble: 3 \u00d7 1\n    #>       x\n    #>   <dbl>\n    #> 1     5\n    #> 2     2\n    #> 3    NA\n\n __\n\n###  5.3.1 Exercises __\n\n  1. How could you use `arrange()` to sort all missing values to the start? (Hint: use `is.na()`).\n\n  2. Sort `flights` to find the most delayed flights. Find the flights that left earliest.\n\n  3. Sort `flights` to find the fastest (highest speed) flights.\n\n  4. Which flights travelled the farthest? Which travelled the shortest?\n\n##  5.4 Select columns with `select()` __\n\nIt\u2019s not uncommon to get datasets with hundreds or even thousands of\nvariables. In this case, the first challenge is often narrowing in on the\nvariables you\u2019re actually interested in. `select()` allows you to rapidly zoom\nin on a useful subset using operations based on the names of the variables.\n\n`select()` is not terribly useful with the flights data because we only have\n19 variables, but you can still get the general idea:\n\n    \n    \n    # Select columns by name\n    select(flights, year, month, day)\n    #> # A tibble: 336,776 \u00d7 3\n    #>    year month   day\n    #>   <int> <int> <int>\n    #> 1  2013     1     1\n    #> 2  2013     1     1\n    #> 3  2013     1     1\n    #> 4  2013     1     1\n    #> 5  2013     1     1\n    #> 6  2013     1     1\n    #> # \u2139 336,770 more rows\n    # Select all columns between year and day (inclusive)\n    select(flights, year:day)\n    #> # A tibble: 336,776 \u00d7 3\n    #>    year month   day\n    #>   <int> <int> <int>\n    #> 1  2013     1     1\n    #> 2  2013     1     1\n    #> 3  2013     1     1\n    #> 4  2013     1     1\n    #> 5  2013     1     1\n    #> 6  2013     1     1\n    #> # \u2139 336,770 more rows\n    # Select all columns except those from year to day (inclusive)\n    select(flights, -(year:day))\n    #> # A tibble: 336,776 \u00d7 16\n    #>   dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier\n    #>      <int>          <int>     <dbl>    <int>          <int>     <dbl> <chr>  \n    #> 1      517            515         2      830            819        11 UA     \n    #> 2      533            529         4      850            830        20 UA     \n    #> 3      542            540         2      923            850        33 AA     \n    #> 4      544            545        -1     1004           1022       -18 B6     \n    #> 5      554            600        -6      812            837       -25 DL     \n    #> 6      554            558        -4      740            728        12 UA     \n    #> # \u2139 336,770 more rows\n    #> # \u2139 9 more variables: flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n    #> #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>\n\n __\n\nThere are a number of helper functions you can use within `select()`:\n\n  * `starts_with(\"abc\")`: matches names that begin with \u201cabc\u201d.\n\n  * `ends_with(\"xyz\")`: matches names that end with \u201cxyz\u201d.\n\n  * `contains(\"ijk\")`: matches names that contain \u201cijk\u201d.\n\n  * `matches(\"(.)\\\\1\")`: selects variables that match a regular expression. This one matches any variables that contain repeated characters. You\u2019ll learn more about regular expressions in strings.\n\n  * `num_range(\"x\", 1:3)`: matches `x1`, `x2` and `x3`.\n\nSee `?select` for more details.\n\n`select()` can be used to rename variables, but it\u2019s rarely useful because it\ndrops all of the variables not explicitly mentioned. Instead, use `rename()`,\nwhich is a variant of `select()` that keeps all the variables that aren\u2019t\nexplicitly mentioned:\n\n    \n    \n    rename(flights, tail_num = tailnum)\n    #> # A tibble: 336,776 \u00d7 19\n    #>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    #>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n    #> 1  2013     1     1      517            515         2      830            819\n    #> 2  2013     1     1      533            529         4      850            830\n    #> 3  2013     1     1      542            540         2      923            850\n    #> 4  2013     1     1      544            545        -1     1004           1022\n    #> 5  2013     1     1      554            600        -6      812            837\n    #> 6  2013     1     1      554            558        -4      740            728\n    #> # \u2139 336,770 more rows\n    #> # \u2139 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n    #> #   tail_num <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n    #> #   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n __\n\nAnother option is to use `select()` in conjunction with the `everything()`\nhelper. This is useful if you have a handful of variables you\u2019d like to move\nto the start of the data frame.\n\n    \n    \n    select(flights, time_hour, air_time, everything())\n    #> # A tibble: 336,776 \u00d7 19\n    #>   time_hour           air_time  year month   day dep_time sched_dep_time\n    #>   <dttm>                 <dbl> <int> <int> <int>    <int>          <int>\n    #> 1 2013-01-01 05:00:00      227  2013     1     1      517            515\n    #> 2 2013-01-01 05:00:00      227  2013     1     1      533            529\n    #> 3 2013-01-01 05:00:00      160  2013     1     1      542            540\n    #> 4 2013-01-01 05:00:00      183  2013     1     1      544            545\n    #> 5 2013-01-01 06:00:00      116  2013     1     1      554            600\n    #> 6 2013-01-01 05:00:00      150  2013     1     1      554            558\n    #> # \u2139 336,770 more rows\n    #> # \u2139 12 more variables: dep_delay <dbl>, arr_time <int>, sched_arr_time <int>,\n    #> #   arr_delay <dbl>, carrier <chr>, flight <int>, tailnum <chr>, origin <chr>,\n    #> #   dest <chr>, distance <dbl>, hour <dbl>, minute <dbl>\n\n __\n\n###  5.4.1 Exercises __\n\n  1. Brainstorm as many ways as possible to select `dep_time`, `dep_delay`, `arr_time`, and `arr_delay` from `flights`.\n\n  2. What happens if you include the name of a variable multiple times in a `select()` call?\n\n  3. What does the `any_of()` function do? Why might it be helpful in conjunction with this vector?\n    \n        vars <- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\n\n __\n\n  4. Does the result of running the following code surprise you? How do the select helpers deal with case by default? How can you change that default?\n    \n        select(flights, contains(\"TIME\"))\n\n __\n\n##  5.5 Add new variables with `mutate()` __\n\nBesides selecting sets of existing columns, it\u2019s often useful to add new\ncolumns that are functions of existing columns. That\u2019s the job of `mutate()`.\n\n`mutate()` always adds new columns at the end of your dataset so we\u2019ll start\nby creating a narrower dataset so we can see the new variables. Remember that\nwhen you\u2019re in RStudio, the easiest way to see all the columns is `View()`.\n\n    \n    \n    flights_sml <- select(flights, \n      year:day, \n      ends_with(\"delay\"), \n      distance, \n      air_time\n    )\n    mutate(flights_sml,\n      gain = dep_delay - arr_delay,\n      speed = distance / air_time * 60\n    )\n    #> # A tibble: 336,776 \u00d7 9\n    #>    year month   day dep_delay arr_delay distance air_time  gain speed\n    #>   <int> <int> <int>     <dbl>     <dbl>    <dbl>    <dbl> <dbl> <dbl>\n    #> 1  2013     1     1         2        11     1400      227    -9  370.\n    #> 2  2013     1     1         4        20     1416      227   -16  374.\n    #> 3  2013     1     1         2        33     1089      160   -31  408.\n    #> 4  2013     1     1        -1       -18     1576      183    17  517.\n    #> 5  2013     1     1        -6       -25      762      116    19  394.\n    #> 6  2013     1     1        -4        12      719      150   -16  288.\n    #> # \u2139 336,770 more rows\n\n __\n\nNote that you can refer to columns that you\u2019ve just created:\n\n    \n    \n    mutate(flights_sml,\n      gain = dep_delay - arr_delay,\n      hours = air_time / 60,\n      gain_per_hour = gain / hours\n    )\n    #> # A tibble: 336,776 \u00d7 10\n    #>    year month   day dep_delay arr_delay distance air_time  gain hours\n    #>   <int> <int> <int>     <dbl>     <dbl>    <dbl>    <dbl> <dbl> <dbl>\n    #> 1  2013     1     1         2        11     1400      227    -9  3.78\n    #> 2  2013     1     1         4        20     1416      227   -16  3.78\n    #> 3  2013     1     1         2        33     1089      160   -31  2.67\n    #> 4  2013     1     1        -1       -18     1576      183    17  3.05\n    #> 5  2013     1     1        -6       -25      762      116    19  1.93\n    #> 6  2013     1     1        -4        12      719      150   -16  2.5 \n    #> # \u2139 336,770 more rows\n    #> # \u2139 1 more variable: gain_per_hour <dbl>\n\n __\n\nIf you only want to keep the new variables, use `transmute()`:\n\n    \n    \n    transmute(flights,\n      gain = dep_delay - arr_delay,\n      hours = air_time / 60,\n      gain_per_hour = gain / hours\n    )\n    #> # A tibble: 336,776 \u00d7 3\n    #>    gain hours gain_per_hour\n    #>   <dbl> <dbl>         <dbl>\n    #> 1    -9  3.78         -2.38\n    #> 2   -16  3.78         -4.23\n    #> 3   -31  2.67        -11.6 \n    #> 4    17  3.05          5.57\n    #> 5    19  1.93          9.83\n    #> 6   -16  2.5          -6.4 \n    #> # \u2139 336,770 more rows\n\n __\n\n###  5.5.1 Useful creation functions __\n\nThere are many functions for creating new variables that you can use with\n`mutate()`. The key property is that the function must be vectorised: it must\ntake a vector of values as input, return a vector with the same number of\nvalues as output. There\u2019s no way to list every possible function that you\nmight use, but here\u2019s a selection of functions that are frequently useful:\n\n  * Arithmetic operators: `+`, `-`, `*`, `/`, `^`. These are all vectorised, using the so called \u201crecycling rules\u201d. If one parameter is shorter than the other, it will be automatically extended to be the same length. This is most useful when one of the arguments is a single number: `air_time / 60`, `hours * 60 + minute`, etc.\n\nArithmetic operators are also useful in conjunction with the aggregate\nfunctions you\u2019ll learn about later. For example, `x / sum(x)` calculates the\nproportion of a total, and `y - mean(y)` computes the difference from the\nmean.\n\n  * Modular arithmetic: `%/%` (integer division) and `%%` (remainder), where `x == y * (x %/% y) + (x %% y)`. Modular arithmetic is a handy tool because it allows you to break integers up into pieces. For example, in the flights dataset, you can compute `hour` and `minute` from `dep_time` with:\n    \n        transmute(flights,\n      dep_time,\n      hour = dep_time %/% 100,\n      minute = dep_time %% 100\n    )\n    #> # A tibble: 336,776 \u00d7 3\n    #>   dep_time  hour minute\n    #>      <int> <dbl>  <dbl>\n    #> 1      517     5     17\n    #> 2      533     5     33\n    #> 3      542     5     42\n    #> 4      544     5     44\n    #> 5      554     5     54\n    #> 6      554     5     54\n    #> # \u2139 336,770 more rows\n\n __\n\n  * Logs: `log()`, `log2()`, `log10()`. Logarithms are an incredibly useful transformation for dealing with data that ranges across multiple orders of magnitude. They also convert multiplicative relationships to additive, a feature we\u2019ll come back to in modelling.\n\nAll else being equal, I recommend using `log2()` because it\u2019s easy to\ninterpret: a difference of 1 on the log scale corresponds to doubling on the\noriginal scale and a difference of -1 corresponds to halving.\n\n  * Offsets: `lead()` and `lag()` allow you to refer to leading or lagging values. This allows you to compute running differences (e.g. `x - lag(x)`) or find when values change (`x != lag(x)`). They are most useful in conjunction with `group_by()`, which you\u2019ll learn about shortly.\n    \n        (x <- 1:10)\n    #>  [1]  1  2  3  4  5  6  7  8  9 10\n    lag(x)\n    #>  [1] NA  1  2  3  4  5  6  7  8  9\n    lead(x)\n    #>  [1]  2  3  4  5  6  7  8  9 10 NA\n\n __\n\n  * Cumulative and rolling aggregates: R provides functions for running sums, products, mins and maxes: `cumsum()`, `cumprod()`, `cummin()`, `cummax()`; and dplyr provides `cummean()` for cumulative means. If you need rolling aggregates (i.e. a sum computed over a rolling window), try the RcppRoll package.\n    \n        x\n    #>  [1]  1  2  3  4  5  6  7  8  9 10\n    cumsum(x)\n    #>  [1]  1  3  6 10 15 21 28 36 45 55\n    cummean(x)\n    #>  [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5\n\n __\n\n  * Logical comparisons, `<`, `<=`, `>`, `>=`, `!=`, and `==`, which you learned about earlier. If you\u2019re doing a complex sequence of logical operations it\u2019s often a good idea to store the interim values in new variables so you can check that each step is working as expected.\n\n  * Ranking: there are a number of ranking functions, but you should start with `min_rank()`. It does the most usual type of ranking (e.g. 1st, 2nd, 2nd, 4th). The default gives smallest values the small ranks; use `desc(x)` to give the largest values the smallest ranks.\n    \n        y <- c(1, 2, 2, NA, 3, 4)\n    min_rank(y)\n    #> [1]  1  2  2 NA  4  5\n    min_rank(desc(y))\n    #> [1]  5  3  3 NA  2  1\n\n __\n\nIf `min_rank()` doesn\u2019t do what you need, look at the variants `row_number()`,\n`dense_rank()`, `percent_rank()`, `cume_dist()`, `ntile()`. See their help\npages for more details.\n\n    \n        row_number(y)\n    #> [1]  1  2  3 NA  4  5\n    dense_rank(y)\n    #> [1]  1  2  2 NA  3  4\n    percent_rank(y)\n    #> [1] 0.00 0.25 0.25   NA 0.75 1.00\n    cume_dist(y)\n    #> [1] 0.2 0.6 0.6  NA 0.8 1.0\n\n __\n\n###  5.5.2 Exercises __\n\n  1. Currently `dep_time` and `sched_dep_time` are convenient to look at, but hard to compute with because they\u2019re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight.\n\n  2. Compare `air_time` with `arr_time - dep_time`. What do you expect to see? What do you see? What do you need to do to fix it?\n\n  3. Compare `dep_time`, `sched_dep_time`, and `dep_delay`. How would you expect those three numbers to be related?\n\n  4. Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for `min_rank()`.\n\n  5. What does `1:3 + 1:10` return? Why?\n\n  6. What trigonometric functions does R provide?\n\n##  5.6 Grouped summaries with `summarise()` __\n\nThe last key verb is `summarise()`. It collapses a data frame to a single row:\n\n    \n    \n    summarise(flights, delay = mean(dep_delay, na.rm = TRUE))\n    #> # A tibble: 1 \u00d7 1\n    #>   delay\n    #>   <dbl>\n    #> 1  12.6\n\n __\n\n(We\u2019ll come back to what that `na.rm = TRUE` means very shortly.)\n\n`summarise()` is not terribly useful unless we pair it with `group_by()`. This\nchanges the unit of analysis from the complete dataset to individual groups.\nThen, when you use the dplyr verbs on a grouped data frame they\u2019ll be\nautomatically applied \u201cby group\u201d. For example, if we applied exactly the same\ncode to a data frame grouped by date, we get the average delay per date:\n\n    \n    \n    by_day <- group_by(flights, year, month, day)\n    summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 4\n    #> # Groups:   year, month [12]\n    #>    year month   day delay\n    #>   <int> <int> <int> <dbl>\n    #> 1  2013     1     1 11.5 \n    #> 2  2013     1     2 13.9 \n    #> 3  2013     1     3 11.0 \n    #> 4  2013     1     4  8.95\n    #> 5  2013     1     5  5.73\n    #> 6  2013     1     6  7.15\n    #> # \u2139 359 more rows\n\n __\n\nTogether `group_by()` and `summarise()` provide one of the tools that you\u2019ll\nuse most commonly when working with dplyr: grouped summaries. But before we go\nany further with this, we need to introduce a powerful new idea: the pipe.\n\n###  5.6.1 Combining multiple operations with the pipe __\n\nImagine that we want to explore the relationship between the distance and\naverage delay for each location. Using what you know about dplyr, you might\nwrite code like this:\n\n    \n    \n    by_dest <- group_by(flights, dest)\n    delay <- summarise(by_dest,\n      count = n(),\n      dist = mean(distance, na.rm = TRUE),\n      delay = mean(arr_delay, na.rm = TRUE)\n    )\n    delay <- filter(delay, count > 20, dest != \"HNL\")\n    \n    # It looks like delays increase with distance up to ~750 miles \n    # and then decrease. Maybe as flights get longer there's more \n    # ability to make up delays in the air?\n    ggplot(data = delay, mapping = aes(x = dist, y = delay)) +\n      geom_point(aes(size = count), alpha = 1/3) +\n      geom_smooth(se = FALSE)\n    #> `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n __\n\nThere are three steps to prepare this data:\n\n  1. Group flights by destination.\n\n  2. Summarise to compute distance, average delay, and number of flights.\n\n  3. Filter to remove noisy points and Honolulu airport, which is almost twice as far away as the next closest airport.\n\nThis code is a little frustrating to write because we have to give each\nintermediate data frame a name, even though we don\u2019t care about it. Naming\nthings is hard, so this slows down our analysis.\n\nThere\u2019s another way to tackle the same problem with the pipe, `%>%`:\n\n    \n    \n    delays <- flights %>% \n      group_by(dest) %>% \n      summarise(\n        count = n(),\n        dist = mean(distance, na.rm = TRUE),\n        delay = mean(arr_delay, na.rm = TRUE)\n      ) %>% \n      filter(count > 20, dest != \"HNL\")\n\n __\n\nThis focuses on the transformations, not what\u2019s being transformed, which makes\nthe code easier to read. You can read it as a series of imperative statements:\ngroup, then summarise, then filter. As suggested by this reading, a good way\nto pronounce `%>%` when reading code is \u201cthen\u201d.\n\nBehind the scenes, `x %>% f(y)` turns into `f(x, y)`, and `x %>% f(y) %>%\ng(z)` turns into `g(f(x, y), z)` and so on. You can use the pipe to rewrite\nmultiple operations in a way that you can read left-to-right, top-to-bottom.\nWe\u2019ll use piping frequently from now on because it considerably improves the\nreadability of code, and we\u2019ll come back to it in more detail in pipes.\n\nWorking with the pipe is one of the key criteria for belonging to the\ntidyverse. The only exception is ggplot2: it was written before the pipe was\ndiscovered. Unfortunately, the next iteration of ggplot2, ggvis, which does\nuse the pipe, isn\u2019t quite ready for prime time yet.\n\n###  5.6.2 Missing values __\n\nYou may have wondered about the `na.rm` argument we used above. What happens\nif we don\u2019t set it?\n\n    \n    \n    flights %>% \n      group_by(year, month, day) %>% \n      summarise(mean = mean(dep_delay))\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 4\n    #> # Groups:   year, month [12]\n    #>    year month   day  mean\n    #>   <int> <int> <int> <dbl>\n    #> 1  2013     1     1    NA\n    #> 2  2013     1     2    NA\n    #> 3  2013     1     3    NA\n    #> 4  2013     1     4    NA\n    #> 5  2013     1     5    NA\n    #> 6  2013     1     6    NA\n    #> # \u2139 359 more rows\n\n __\n\nWe get a lot of missing values! That\u2019s because aggregation functions obey the\nusual rule of missing values: if there\u2019s any missing value in the input, the\noutput will be a missing value. Fortunately, all aggregation functions have an\n`na.rm` argument which removes the missing values prior to computation:\n\n    \n    \n    flights %>% \n      group_by(year, month, day) %>% \n      summarise(mean = mean(dep_delay, na.rm = TRUE))\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 4\n    #> # Groups:   year, month [12]\n    #>    year month   day  mean\n    #>   <int> <int> <int> <dbl>\n    #> 1  2013     1     1 11.5 \n    #> 2  2013     1     2 13.9 \n    #> 3  2013     1     3 11.0 \n    #> 4  2013     1     4  8.95\n    #> 5  2013     1     5  5.73\n    #> 6  2013     1     6  7.15\n    #> # \u2139 359 more rows\n\n __\n\nIn this case, where missing values represent cancelled flights, we could also\ntackle the problem by first removing the cancelled flights. We\u2019ll save this\ndataset so we can reuse it in the next few examples.\n\n    \n    \n    not_cancelled <- flights %>% \n      filter(!is.na(dep_delay), !is.na(arr_delay))\n    \n    not_cancelled %>% \n      group_by(year, month, day) %>% \n      summarise(mean = mean(dep_delay))\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 4\n    #> # Groups:   year, month [12]\n    #>    year month   day  mean\n    #>   <int> <int> <int> <dbl>\n    #> 1  2013     1     1 11.4 \n    #> 2  2013     1     2 13.7 \n    #> 3  2013     1     3 10.9 \n    #> 4  2013     1     4  8.97\n    #> 5  2013     1     5  5.73\n    #> 6  2013     1     6  7.15\n    #> # \u2139 359 more rows\n\n __\n\n###  5.6.3 Counts __\n\nWhenever you do any aggregation, it\u2019s always a good idea to include either a\ncount (`n()`), or a count of non-missing values (`sum(!is.na(x))`). That way\nyou can check that you\u2019re not drawing conclusions based on very small amounts\nof data. For example, let\u2019s look at the planes (identified by their tail\nnumber) that have the highest average delays:\n\n    \n    \n    delays <- not_cancelled %>% \n      group_by(tailnum) %>% \n      summarise(\n        delay = mean(arr_delay)\n      )\n    \n    ggplot(data = delays, mapping = aes(x = delay)) + \n      geom_freqpoly(binwidth = 10)\n\n __\n\nWow, there are some planes that have an _average_ delay of 5 hours (300\nminutes)!\n\nThe story is actually a little more nuanced. We can get more insight if we\ndraw a scatterplot of number of flights vs. average delay:\n\n    \n    \n    delays <- not_cancelled %>% \n      group_by(tailnum) %>% \n      summarise(\n        delay = mean(arr_delay, na.rm = TRUE),\n        n = n()\n      )\n    \n    ggplot(data = delays, mapping = aes(x = n, y = delay)) + \n      geom_point(alpha = 1/10)\n\n __\n\nNot surprisingly, there is much greater variation in the average delay when\nthere are few flights. The shape of this plot is very characteristic: whenever\nyou plot a mean (or other summary) vs. group size, you\u2019ll see that the\nvariation decreases as the sample size increases.\n\nWhen looking at this sort of plot, it\u2019s often useful to filter out the groups\nwith the smallest numbers of observations, so you can see more of the pattern\nand less of the extreme variation in the smallest groups. This is what the\nfollowing code does, as well as showing you a handy pattern for integrating\nggplot2 into dplyr flows. It\u2019s a bit painful that you have to switch from\n`%>%` to `+`, but once you get the hang of it, it\u2019s quite convenient.\n\n    \n    \n    delays %>% \n      filter(n > 25) %>% \n      ggplot(mapping = aes(x = n, y = delay)) + \n        geom_point(alpha = 1/10)\n\n __\n\n* * *\n\nRStudio tip: a useful keyboard shortcut is Cmd/Ctrl + Shift + P. This resends\nthe previously sent chunk from the editor to the console. This is very\nconvenient when you\u2019re (e.g.) exploring the value of `n` in the example above.\nYou send the whole block once with Cmd/Ctrl + Enter, then you modify the value\nof `n` and press Cmd/Ctrl + Shift + P to resend the complete block.\n\n* * *\n\nThere\u2019s another common variation of this type of pattern. Let\u2019s look at how\nthe average performance of batters in baseball is related to the number of\ntimes they\u2019re at bat. Here I use data from the **Lahman** package to compute\nthe batting average (number of hits / number of attempts) of every major\nleague baseball player.\n\nWhen I plot the skill of the batter (measured by the batting average, `ba`)\nagainst the number of opportunities to hit the ball (measured by at bat,\n`ab`), you see two patterns:\n\n  1. As above, the variation in our aggregate decreases as we get more data points.\n\n  2. There\u2019s a positive correlation between skill (`ba`) and opportunities to hit the ball (`ab`). This is because teams control who gets to play, and obviously they\u2019ll pick their best players.\n\n    \n    \n    # Convert to a tibble so it prints nicely\n    batting <- as_tibble(Lahman::Batting)\n    \n    batters <- batting %>% \n      group_by(playerID) %>% \n      summarise(\n        ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),\n        ab = sum(AB, na.rm = TRUE)\n      )\n    \n    batters %>% \n      filter(ab > 100) %>% \n      ggplot(mapping = aes(x = ab, y = ba)) +\n        geom_point() + \n        geom_smooth(se = FALSE)\n    #> `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n __\n\nThis also has important implications for ranking. If you naively sort on\n`desc(ba)`, the people with the best batting averages are clearly lucky, not\nskilled:\n\n    \n    \n    batters %>% \n      arrange(desc(ba))\n    #> # A tibble: 20,469 \u00d7 3\n    #>   playerID     ba    ab\n    #>   <chr>     <dbl> <int>\n    #> 1 abramge01     1     1\n    #> 2 alberan01     1     1\n    #> 3 banisje01     1     1\n    #> 4 bartocl01     1     1\n    #> 5 bassdo01      1     1\n    #> 6 birasst01     1     2\n    #> # \u2139 20,463 more rows\n\n __\n\nYou can find a good explanation of this problem at\nhttp://varianceexplained.org/r/empirical_bayes_baseball/ and\nhttp://www.evanmiller.org/how-not-to-sort-by-average-rating.html.\n\n###  5.6.4 Useful summary functions __\n\nJust using means, counts, and sum can get you a long way, but R provides many\nother useful summary functions:\n\n  * Measures of location: we\u2019ve used `mean(x)`, but `median(x)` is also useful. The mean is the sum divided by the length; the median is a value where 50% of `x` is above it, and 50% is below it.\n\nIt\u2019s sometimes useful to combine aggregation with logical subsetting. We\nhaven\u2019t talked about this sort of subsetting yet, but you\u2019ll learn more about\nit in subsetting.\n\n    \n        not_cancelled %>% \n      group_by(year, month, day) %>% \n      summarise(\n        avg_delay1 = mean(arr_delay),\n        avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay\n      )\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 5\n    #> # Groups:   year, month [12]\n    #>    year month   day avg_delay1 avg_delay2\n    #>   <int> <int> <int>      <dbl>      <dbl>\n    #> 1  2013     1     1      12.7        32.5\n    #> 2  2013     1     2      12.7        32.0\n    #> 3  2013     1     3       5.73       27.7\n    #> 4  2013     1     4      -1.93       28.3\n    #> 5  2013     1     5      -1.53       22.6\n    #> 6  2013     1     6       4.24       24.4\n    #> # \u2139 359 more rows\n\n __\n\n  * Measures of spread: `sd(x)`, `IQR(x)`, `mad(x)`. The root mean squared deviation, or standard deviation `sd(x)`, is the standard measure of spread. The interquartile range `IQR(x)` and median absolute deviation `mad(x)` are robust equivalents that may be more useful if you have outliers.\n    \n        # Why is distance to some destinations more variable than to others?\n    not_cancelled %>% \n      group_by(dest) %>% \n      summarise(distance_sd = sd(distance)) %>% \n      arrange(desc(distance_sd))\n    #> # A tibble: 104 \u00d7 2\n    #>   dest  distance_sd\n    #>   <chr>       <dbl>\n    #> 1 EGE         10.5 \n    #> 2 SAN         10.4 \n    #> 3 SFO         10.2 \n    #> 4 HNL         10.0 \n    #> 5 SEA          9.98\n    #> 6 LAS          9.91\n    #> # \u2139 98 more rows\n\n __\n\n  * Measures of rank: `min(x)`, `quantile(x, 0.25)`, `max(x)`. Quantiles are a generalisation of the median. For example, `quantile(x, 0.25)` will find a value of `x` that is greater than 25% of the values, and less than the remaining 75%.\n    \n        # When do the first and last flights leave each day?\n    not_cancelled %>% \n      group_by(year, month, day) %>% \n      summarise(\n        first = min(dep_time),\n        last = max(dep_time)\n      )\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 5\n    #> # Groups:   year, month [12]\n    #>    year month   day first  last\n    #>   <int> <int> <int> <int> <int>\n    #> 1  2013     1     1   517  2356\n    #> 2  2013     1     2    42  2354\n    #> 3  2013     1     3    32  2349\n    #> 4  2013     1     4    25  2358\n    #> 5  2013     1     5    14  2357\n    #> 6  2013     1     6    16  2355\n    #> # \u2139 359 more rows\n\n __\n\n  * Measures of position: `first(x)`, `nth(x, 2)`, `last(x)`. These work similarly to `x[1]`, `x[2]`, and `x[length(x)]` but let you set a default value if that position does not exist (i.e. you\u2019re trying to get the 3rd element from a group that only has two elements). For example, we can find the first and last departure for each day:\n    \n        not_cancelled %>% \n      group_by(year, month, day) %>% \n      summarise(\n        first_dep = first(dep_time), \n        last_dep = last(dep_time)\n      )\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 5\n    #> # Groups:   year, month [12]\n    #>    year month   day first_dep last_dep\n    #>   <int> <int> <int>     <int>    <int>\n    #> 1  2013     1     1       517     2356\n    #> 2  2013     1     2        42     2354\n    #> 3  2013     1     3        32     2349\n    #> 4  2013     1     4        25     2358\n    #> 5  2013     1     5        14     2357\n    #> 6  2013     1     6        16     2355\n    #> # \u2139 359 more rows\n\n __\n\nThese functions are complementary to filtering on ranks. Filtering gives you\nall variables, with each observation in a separate row:\n\n    \n        not_cancelled %>% \n      group_by(year, month, day) %>% \n      mutate(r = min_rank(desc(dep_time))) %>% \n      filter(r %in% range(r))\n    #> # A tibble: 770 \u00d7 20\n    #> # Groups:   year, month, day [365]\n    #>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    #>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n    #> 1  2013     1     1      517            515         2      830            819\n    #> 2  2013     1     1     2356           2359        -3      425            437\n    #> 3  2013     1     2       42           2359        43      518            442\n    #> 4  2013     1     2     2354           2359        -5      413            437\n    #> 5  2013     1     3       32           2359        33      504            442\n    #> 6  2013     1     3     2349           2359       -10      434            445\n    #> # \u2139 764 more rows\n    #> # \u2139 12 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n    #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n    #> #   hour <dbl>, minute <dbl>, time_hour <dttm>, r <int>\n\n __\n\n  * Counts: You\u2019ve seen `n()`, which takes no arguments, and returns the size of the current group. To count the number of non-missing values, use `sum(!is.na(x))`. To count the number of distinct (unique) values, use `n_distinct(x)`.\n    \n        # Which destinations have the most carriers?\n    not_cancelled %>% \n      group_by(dest) %>% \n      summarise(carriers = n_distinct(carrier)) %>% \n      arrange(desc(carriers))\n    #> # A tibble: 104 \u00d7 2\n    #>   dest  carriers\n    #>   <chr>    <int>\n    #> 1 ATL          7\n    #> 2 BOS          7\n    #> 3 CLT          7\n    #> 4 ORD          7\n    #> 5 TPA          7\n    #> 6 AUS          6\n    #> # \u2139 98 more rows\n\n __\n\nCounts are so useful that dplyr provides a simple helper if all you want is a\ncount:\n\n    \n        not_cancelled %>% \n      count(dest)\n    #> # A tibble: 104 \u00d7 2\n    #>   dest      n\n    #>   <chr> <int>\n    #> 1 ABQ     254\n    #> 2 ACK     264\n    #> 3 ALB     418\n    #> 4 ANC       8\n    #> 5 ATL   16837\n    #> 6 AUS    2411\n    #> # \u2139 98 more rows\n\n __\n\nYou can optionally provide a weight variable. For example, you could use this\nto \u201ccount\u201d (sum) the total number of miles a plane flew:\n\n    \n        not_cancelled %>% \n      count(tailnum, wt = distance)\n    #> # A tibble: 4,037 \u00d7 2\n    #>   tailnum      n\n    #>   <chr>    <dbl>\n    #> 1 D942DN    3418\n    #> 2 N0EGMQ  239143\n    #> 3 N10156  109664\n    #> 4 N102UW   25722\n    #> 5 N103US   24619\n    #> 6 N104UW   24616\n    #> # \u2139 4,031 more rows\n\n __\n\n  * Counts and proportions of logical values: `sum(x > 10)`, `mean(y == 0)`. When used with numeric functions, `TRUE` is converted to 1 and `FALSE` to 0. This makes `sum()` and `mean()` very useful: `sum(x)` gives the number of `TRUE`s in `x`, and `mean(x)` gives the proportion.\n    \n        # How many flights left before 5am? (these usually indicate delayed\n    # flights from the previous day)\n    not_cancelled %>% \n      group_by(year, month, day) %>% \n      summarise(n_early = sum(dep_time < 500))\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 4\n    #> # Groups:   year, month [12]\n    #>    year month   day n_early\n    #>   <int> <int> <int>   <int>\n    #> 1  2013     1     1       0\n    #> 2  2013     1     2       3\n    #> 3  2013     1     3       4\n    #> 4  2013     1     4       3\n    #> 5  2013     1     5       3\n    #> 6  2013     1     6       2\n    #> # \u2139 359 more rows\n    \n    # What proportion of flights are delayed by more than an hour?\n    not_cancelled %>% \n      group_by(year, month, day) %>% \n      summarise(hour_prop = mean(arr_delay > 60))\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 4\n    #> # Groups:   year, month [12]\n    #>    year month   day hour_prop\n    #>   <int> <int> <int>     <dbl>\n    #> 1  2013     1     1    0.0722\n    #> 2  2013     1     2    0.0851\n    #> 3  2013     1     3    0.0567\n    #> 4  2013     1     4    0.0396\n    #> 5  2013     1     5    0.0349\n    #> 6  2013     1     6    0.0470\n    #> # \u2139 359 more rows\n\n __\n\n###  5.6.5 Grouping by multiple variables __\n\nWhen you group by multiple variables, each summary peels off one level of the\ngrouping. That makes it easy to progressively roll up a dataset:\n\n    \n    \n    daily <- group_by(flights, year, month, day)\n    (per_day   <- summarise(daily, flights = n()))\n    #> `summarise()` has grouped output by 'year', 'month'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 365 \u00d7 4\n    #> # Groups:   year, month [12]\n    #>    year month   day flights\n    #>   <int> <int> <int>   <int>\n    #> 1  2013     1     1     842\n    #> 2  2013     1     2     943\n    #> 3  2013     1     3     914\n    #> 4  2013     1     4     915\n    #> 5  2013     1     5     720\n    #> 6  2013     1     6     832\n    #> # \u2139 359 more rows\n    (per_month <- summarise(per_day, flights = sum(flights)))\n    #> `summarise()` has grouped output by 'year'. You can override using the\n    #> `.groups` argument.\n    #> # A tibble: 12 \u00d7 3\n    #> # Groups:   year [1]\n    #>    year month flights\n    #>   <int> <int>   <int>\n    #> 1  2013     1   27004\n    #> 2  2013     2   24951\n    #> 3  2013     3   28834\n    #> 4  2013     4   28330\n    #> 5  2013     5   28796\n    #> 6  2013     6   28243\n    #> # \u2139 6 more rows\n    (per_year  <- summarise(per_month, flights = sum(flights)))\n    #> # A tibble: 1 \u00d7 2\n    #>    year flights\n    #>   <int>   <int>\n    #> 1  2013  336776\n\n __\n\nBe careful when progressively rolling up summaries: it\u2019s OK for sums and\ncounts, but you need to think about weighting means and variances, and it\u2019s\nnot possible to do it exactly for rank-based statistics like the median. In\nother words, the sum of groupwise sums is the overall sum, but the median of\ngroupwise medians is not the overall median.\n\n###  5.6.6 Ungrouping __\n\nIf you need to remove grouping, and return to operations on ungrouped data,\nuse `ungroup()`.\n\n    \n    \n    daily %>% \n      ungroup() %>%             # no longer grouped by date\n      summarise(flights = n())  # all flights\n    #> # A tibble: 1 \u00d7 1\n    #>   flights\n    #>     <int>\n    #> 1  336776\n\n __\n\n###  5.6.7 Exercises __\n\n  1. Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios:\n\n    * A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.\n\n    * A flight is always 10 minutes late.\n\n    * A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.\n\n    * 99% of the time a flight is on time. 1% of the time it\u2019s 2 hours late.\n\nWhich is more important: arrival delay or departure delay?\n\n  2. Come up with another approach that will give you the same output as `not_cancelled %>% count(dest)` and `not_cancelled %>% count(tailnum, wt = distance)` (without using `count()`).\n\n  3. Our definition of cancelled flights (`is.na(dep_delay) | is.na(arr_delay)` ) is slightly suboptimal. Why? Which is the most important column?\n\n  4. Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?\n\n  5. Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about `flights %>% group_by(carrier, dest) %>% summarise(n())`)\n\n  6. What does the `sort` argument to `count()` do. When might you use it?\n\n##  5.7 Grouped mutates (and filters) __\n\nGrouping is most useful in conjunction with `summarise()`, but you can also do\nconvenient operations with `mutate()` and `filter()`:\n\n  * Find the worst members of each group:\n    \n        flights_sml %>% \n      group_by(year, month, day) %>%\n      filter(rank(desc(arr_delay)) < 10)\n    #> # A tibble: 3,306 \u00d7 7\n    #> # Groups:   year, month, day [365]\n    #>    year month   day dep_delay arr_delay distance air_time\n    #>   <int> <int> <int>     <dbl>     <dbl>    <dbl>    <dbl>\n    #> 1  2013     1     1       853       851      184       41\n    #> 2  2013     1     1       290       338     1134      213\n    #> 3  2013     1     1       260       263      266       46\n    #> 4  2013     1     1       157       174      213       60\n    #> 5  2013     1     1       216       222      708      121\n    #> 6  2013     1     1       255       250      589      115\n    #> # \u2139 3,300 more rows\n\n __\n\n  * Find all groups bigger than a threshold:\n    \n        popular_dests <- flights %>% \n      group_by(dest) %>% \n      filter(n() > 365)\n    popular_dests\n    #> # A tibble: 332,577 \u00d7 19\n    #> # Groups:   dest [77]\n    #>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n    #>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n    #> 1  2013     1     1      517            515         2      830            819\n    #> 2  2013     1     1      533            529         4      850            830\n    #> 3  2013     1     1      542            540         2      923            850\n    #> 4  2013     1     1      544            545        -1     1004           1022\n    #> 5  2013     1     1      554            600        -6      812            837\n    #> 6  2013     1     1      554            558        -4      740            728\n    #> # \u2139 332,571 more rows\n    #> # \u2139 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n    #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n    #> #   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n __\n\n  * Standardise to compute per group metrics:\n    \n        popular_dests %>% \n      filter(arr_delay > 0) %>% \n      mutate(prop_delay = arr_delay / sum(arr_delay)) %>% \n      select(year:day, dest, arr_delay, prop_delay)\n    #> # A tibble: 131,106 \u00d7 6\n    #> # Groups:   dest [77]\n    #>    year month   day dest  arr_delay prop_delay\n    #>   <int> <int> <int> <chr>     <dbl>      <dbl>\n    #> 1  2013     1     1 IAH          11  0.000111 \n    #> 2  2013     1     1 IAH          20  0.000201 \n    #> 3  2013     1     1 MIA          33  0.000235 \n    #> 4  2013     1     1 ORD          12  0.0000424\n    #> 5  2013     1     1 FLL          19  0.0000938\n    #> 6  2013     1     1 ORD           8  0.0000283\n    #> # \u2139 131,100 more rows\n\n __\n\nA grouped filter is a grouped mutate followed by an ungrouped filter. I\ngenerally avoid them except for quick and dirty manipulations: otherwise it\u2019s\nhard to check that you\u2019ve done the manipulation correctly.\n\nFunctions that work most naturally in grouped mutates and filters are known as\nwindow functions (vs. the summary functions used for summaries). You can learn\nmore about useful window functions in the corresponding vignette:\n`vignette(\"window-functions\")`.\n\n###  5.7.1 Exercises __\n\n  1. Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping.\n\n  2. Which plane (`tailnum`) has the worst on-time record?\n\n  3. What time of day should you fly if you want to avoid delays as much as possible?\n\n  4. For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination.\n\n  5. Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using `lag()`, explore how the delay of a flight is related to the delay of the immediately preceding flight.\n\n  6. Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?\n\n  7. Find all destinations that are flown by at least two carriers. Use that information to rank the carriers.\n\n  8. For each plane, count the number of flights before the first delay of greater than 1 hour.\n\n4 Workflow: basics\n\n6 Workflow: scripts\n\n## On this page\n\n  * 5 Data transformation\n  * 5.1 Introduction\n    * 5.1.1 Prerequisites\n    * 5.1.2 nycflights13\n    * 5.1.3 dplyr basics\n  * 5.2 Filter rows with filter()\n    * 5.2.1 Comparisons\n    * 5.2.2 Logical operators\n    * 5.2.3 Missing values\n    * 5.2.4 Exercises\n  * 5.3 Arrange rows with arrange()\n    * 5.3.1 Exercises\n  * 5.4 Select columns with select()\n    * 5.4.1 Exercises\n  * 5.5 Add new variables with mutate()\n    * 5.5.1 Useful creation functions\n    * 5.5.2 Exercises\n  * 5.6 Grouped summaries with summarise()\n    * 5.6.1 Combining multiple operations with the pipe\n    * 5.6.2 Missing values\n    * 5.6.3 Counts\n    * 5.6.4 Useful summary functions\n    * 5.6.5 Grouping by multiple variables\n    * 5.6.6 Ungrouping\n    * 5.6.7 Exercises\n  * 5.7 Grouped mutates (and filters)\n    * 5.7.1 Exercises\n\n\" **R for Data Science** \" was written by Hadley Wickham and Garrett\nGrolemund.\n\nThis book was built by the bookdown R package.\n\n",
    "links": "[]",
    "priceAndPlans": "Error: Timeout 30000ms exceeded. =========================== logs\n=========================== navigating to\n\"http://web.archive.org/web/20240113060122/https://r4ds.had.co.nz/\", waiting\nuntil \"load\" ============================================================\n\n"
}