{
    "summary": "__ Data Management __ Search the TechTarget Network __\n\nLogin Register\n\nExplore the Network\n\n  * TechTarget Network\n  * Business Analytics\n  * AWS\n  * Content Management\n  * Oracle\n  * SAP\n\n  * Data Management\n\n  *     * Data Governance\n    * Data Integration\n    * Data Management Strategies\n    * Data Warehousing\n    * Database Management\n\nOther Content\n\n    * News\n    * Features\n    * Tips\n    * Webinars\n    * 2023 IT Salary Survey Results\n    * More __\n\n      * Answers\n      * Conference Guides\n      * Definitions\n      * Opinions\n      * Podcasts\n      * Quizzes\n      * Tech Accelerators\n      * Tutorials\n      * Videos\n      * Sponsored Communities\n\n  * Follow:\n  * __\n  * __\n  * __\n  * __\n  * __\n\n  * Home\n  * Data management strategies\n\n__ Tech Accelerator What is data preparation? An in-depth guide to data prep\n\nPrev Next __data validation __data profiling\n\n__Download this guide 1\n\nDefinition\n\n# data transformation\n\n  * Share this item with your network:\n  * __\n  * __\n  * __\n  * __\n  * __\n\n  * __\n  * __\n  * __\n    * __\n    * __\n    * __\n    * __\n\nBy\n\n  * Mary K. Pratt\n  * Corinne Bernstein\n\n### What is data transformation?\n\nData transformation is the process of converting data from one format, such as\na database file, XML document or Excel spreadsheet, into another.\n\nTransformations typically involve converting a raw data source into a\ncleansed, validated and ready-to-use format. Data transformation is crucial to\ndata management processes that include data integration, data migration, data\nwarehousing and data preparation.\n\nThe process of data transformation can also be referred to as\nextract/transform/load (ETL). The extraction phase involves identifying and\npulling data from the various source systems that create data and then moving\nthe data to a single repository. Next, the raw data is cleansed, if needed.\nIt's then transformed into a target format that can be fed into operational\nsystems or into a data warehouse, a date lake or another repository for use in\nbusiness intelligence and analytics applications. The transformation may\ninvolve converting data types, removing duplicate data and enriching the\nsource data.\n\nData transformation is crucial to processes that include data integration,\ndata management, data migration, data warehousing and data wrangling.\n\nIt is also a critical component for any organization seeking to leverage its\ndata to generate timely business insights. As the volume of data has\nproliferated, organizations must have an efficient way to harness data to\neffectively put it to business use. Data transformation is one element of\nharnessing this data, because -- when done properly -- it ensures data is easy\nto access, consistent, secure and ultimately trusted by the intended business\nusers.\n\n### What are the key steps in data transformation?\n\nThe process of data transformation, as noted, involves identifying data\nsources and types; determining the structure of transformations that need to\noccur; and defining how fields will be changed or aggregated. It includes\nextracting data from its original source, transforming it and sending it to\nthe target destination, such as a database or data warehouse. Extractions can\ncome from many locations, including structured sources, streaming sources or\nlog files from web applications.\n\nThis article is part of\n\n### __What is data preparation? An in-depth guide to data prep\n\n  * Which also includes:\n  * 6 data preparation best practices for analytics applications\n  * Top data preparation challenges and how to overcome them\n  * Data preparation in machine learning: 6 key steps\n\n__Download 1\n\nDownload this entire guide for FREE now!\n\nData analysts, data engineers and data scientists are typically in charge of\ndata transformation within an organization. They identify the source data,\ndetermine the required data formats and perform data mapping, as well as\nexecute the actual transformation process before moving the data into\nappropriate databases for storage and use.\n\nTheir work involves five main steps:\n\n  1. **data discovery,** in which data professionals use data profiling tools or profiling scripts to understand the structure and characteristics of the data and also to determine how it should be transformed;\n  2. **data mapping,** during which data professionals connect, or match, data fields from one source to data fields in another;\n  3. **code generation,** a part of the process where the software code required to transform the data is created (either by data transformation tools or the data professionals themselves writing script);\n  4. **execution of the code,** where the data undergoes the transformation; and\n  5. **review,** during which data professionals or the business/end users confirm that the output data meets the established transformation requirements and, if not, address and correct any anomalies and errors.\n\nThese steps fall in the middle of the ETL process for organizations that use\non-premises warehouses. However, scalable cloud-based data warehouses have\ngiven rise to a slightly different process called _ELT_ for extract, load,\ntransform; in this process, organizations can load raw data into data\nwarehouses and then transform data at the time of use.\n\n### What are the benefits and challenges of data transformation?\n\nOrganizations across the board need to analyze their data for a host of\nbusiness operations, from customer service to supply chain management. They\nalso need data to feed the increasing number of automated and intelligent\nsystems within their enterprise.\n\nTo gain insight into and improve these operations, organizations need high-\nquality data in formats compatible with the systems consuming the data.\n\nThus, data transformation is a critical component of an enterprise data\nprogram because it delivers the following benefits:\n\n  * higher data quality;\n  * reduced number of mistakes, such as missing values;\n  * faster queries and retrieval times;\n  * less resources needed to manipulate data;\n  * better data organization and management; and\n  * more usable data, especially for advanced business intelligence or analytics.\n\nThe data transformation process, however, can be complex and complicated. The\nchallenges organizations face include the following:\n\n  * high cost of transformation tools and professional expertise;\n  * significant compute resources, with the intensity of some on-premises transformation processes having the potential to slow down other operations;\n  * difficulty recruiting and retaining the skilled data professionals required for this work, with data professionals some of the most in-demand workers today; and\n  * difficulty of properly aligning data transformation activities to the business's data-related priorities and requirements.\n\n__\n\n### Reasons to do data transformation\n\nOrganizations must be able to mine their data for insights in order to\nsuccessfully compete in the digital marketplace, optimize operations, cut\ncosts and boost productivity. They also require data to feed systems that use\nartificial intelligence, machine learning, natural language processing and\nother advanced technologies.\n\nTo gain accurate insights and to ensure accurate operations of intelligent\nsystems, organizations must collect data and merge it from multiple sources\nand ensure that integrated data is high quality.\n\nThis is where data transformation plays the star role, by ensuring that data\ncollected from one system is compatible with data from other systems and that\nthe combined data is ultimately compatible for use in the systems that require\nit. For example, databases might need to be combined following a corporate\nacquisition, transferred to a cloud data warehouse or merged for analysis.\n\n### Examples of data transformation\n\nThere are various data transformation methods, including the following:\n\n  * **aggregation,** in which data is collected from multiple sources and stored in a single format;\n  * **attribute construction,** in which new attributes are added or created from existing attributes;\n  * **discretization,** which involves converting continuous data values into sets of data intervals with specific values to make the data more manageable for analysis;\n  * **generalization,** where low-level data attributes are converted into high-level data attributes (for example, converting data from multiple brackets broken up by ages into the more general \"young\" and \"old\" attributes) to gain a more comprehensive view of the data;\n  * **integration,** a step that involves combining data from different sources into a single view;\n  * **manipulation,** where the data is changed or altered to make it more readable and organized;\n  * **normalization,** a process that converts source data into another format to limit the occurrence of duplicated data; and\n  * **smoothing,** which uses algorithms to reduce \"noise\" in data sets, thereby helping to more efficiently and effectively identify trends in the data.\n\n### Data transformation tools\n\nData professionals have a number of tools at their disposal to support the ETL\nprocess. These technologies automate many of the steps within data\ntransformation, replacing much, if not all, of the manual scripting and hand\ncoding that had been a major part of the data transformation process.\n\nBoth commercial and open source data transformation tools are available, with\nsome options designed for on-premises transformation processes and others\ncatering to cloud-based transformation activities.\n\nMoreover, some data transformation tools are focused on the data\ntransformation process itself, handling the string of actions required to\ntransform data. However, other ETL tools on the market are part of platforms\nthat offer a broad range of capabilities for managing enterprise data.\n\nOptions include IBM InfoSphere, DataStage, Matillion, SAP Data Services and\nTalend.\n\nThis was last updated in February 2022\n\n####  __Continue Reading About data transformation\n\n  * Top data preparation challenges and how to overcome them\n\n  * Top 7 Best Practices for Data Transformation\n\n  * Data integration platforms take users beyond ETL software\n\n  * How data staging helped Walgreens transform its supply chain\n\n  * 6 data preparation best practices for analytics applications\n\n####  Related Terms\n\nbig data engineer\n\n    A big data engineer is an information technology (IT) professional who is responsible for designing, building, testing and ... See complete definition __\ndata feed\n\n    A data feed is an ongoing stream of structured data that provides users with updates of current information from one or more ... See complete definition __\ndata protection management (DPM)\n\n    Data protection management (DPM) is the administration, monitoring and management of backup processes to ensure backup tasks run ... See complete definition __\n\n####  __Dig Deeper on Data management strategies\n\n  * ##### data lakehouse\n\nBy: Craig Stedman\n\n  * ##### Modernizing a data warehouse for real-time decisions\n\nBy: Stephen Catanzano\n\n  * ##### Data lake vs. data warehouse: Key differences explained\n\nBy: Bridget Botelho\n\n  * ##### An Azure Data Factory tutorial for beginners\n\nBy: Joydip Kanjilal\n\nLatest TechTarget resources\n\n  * Business Analytics ____\n  * AWS ____\n  * Content Management ____\n  * Oracle ____\n  * SAP ____\n\nBusiness Analytics\n\n  * __Microsoft unveils new GenAI, data tools for retail industry\n\nThe tech giant is adding industry-specific features in Data Fabric along with\nGenAI Copilots designed to better personalize ...\n\n  * __Generative AI a key tech for analytics, but within limits\n\nDespite its potential benefits, including increased productivity, users need\nto be wary of overreliance on generative AI given ...\n\n  * __Dresner: Analytics trends include prioritization of BI\n\nWhile generative AI is the BI craze of the moment, increased investments in\nBI, attempts to expand BI use to business users and ...\n\nSearchAWS\n\n  * __AWS Control Tower aims to simplify multi-account management\n\nMany organizations struggle to manage their vast collection of AWS accounts,\nbut Control Tower can help. The service automates ...\n\n  * __Break down the Amazon EKS pricing model\n\nThere are several important variables within the Amazon EKS pricing model. Dig\ninto the numbers to ensure you deploy the service ...\n\n  * __Compare EKS vs. self-managed Kubernetes on AWS\n\nAWS users face a choice when deploying Kubernetes: run it themselves on EC2 or\nlet Amazon do the heavy lifting with EKS. See ...\n\nContent Management\n\n  * __Best practices to create accessible documents\n\nAnyone who creates content can make documents accessible for people who use\nassistive technologies. These best practices lay out ...\n\n  * __DXP vendors: More generative AI tools for websites to come\n\nGenerative AI has given designers, marketers and digital experience leaders\nnew tools to more quickly create better, tightly ...\n\n  * __Best enterprise content management software of 2024\n\nWhen it comes to ECM, there are myriad vendors to consider. Delve into 10\nplatforms to understand their capabilities and ...\n\nSearchOracle\n\n  * __Oracle sets lofty national EHR goal with Cerner acquisition\n\nWith its Cerner acquisition, Oracle sets its sights on creating a national,\nanonymized patient database -- a road filled with ...\n\n  * __With Cerner, Oracle Cloud Infrastructure gets a boost\n\nOracle plans to acquire Cerner in a deal valued at about $30B. The second-\nlargest EHR vendor in the U.S. could inject new life ...\n\n  * __Supreme Court sides with Google in Oracle API copyright suit\n\nThe Supreme Court ruled 6-2 that Java APIs used in Android phones are not\nsubject to American copyright law, ending a ...\n\nSearchSAP\n\n  * __SAP's stance on cloud-only innovation needs clarity in 2024\n\nSAP must focus on delivering technical and business value for all customers in\n2024 rather than alienating some by offering ...\n\n  * __Accenture, SAP partner on supply chain visibility\n\nA partnership between Accenture and SAP builds supply chain capabilities on\nSAP IBP that enables organizations to identify and ...\n\n  * __SAP unveils AI-focused developer tools at TechEd\n\nSAP debuted AI-infused products for improved developer productivity: SAP Build\nCode for pro developers, a HANA Cloud vector ...\n\n  * About Us\n  * Editorial Ethics Policy\n  * Meet The Editors\n  * Contact Us\n  * Advertisers\n  * Partner with Us\n  * Media Kit\n  * Corporate Site\n\n  * Contributors\n  * Reprints\n  * Answers\n  * Definitions\n  * E-Products\n  * Events\n  * Features\n\n  * Guides\n  * Opinions\n  * Photo Stories\n  * Quizzes\n  * Tips\n  * Tutorials\n  * Videos\n\nAll Rights Reserved,  Copyright 2005 - 2024, TechTarget  \n  \nPrivacy Policy  \nCookie Preferences  \nCookie Preferences  \nDo Not Sell or Share My Personal Information\n\nClose\n\n",
    "links": "[]",
    "priceAndPlans": "Error: Timeout 30000ms exceeded. =========================== logs\n=========================== navigating to\n\"http://web.archive.org/web/20240113141314/https://www.techtarget.com/\",\nwaiting until \"load\"\n============================================================\n\n"
}