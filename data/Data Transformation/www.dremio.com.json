{
    "summary": "  *   * Products\n    *       *         * Unified AnalyticsGoverned self-service access across all your data\n        * SQL Query EngineBest price-performance for BI and interactive analytics\n        * Lakehouse ManagementIceberg data catalog with Git\u2011inspired versioning\n      *         * Why Dremio\n        * Pricing\n        * Reflections Query Acceleration\n        * Generative AI\n        * Security\n        * Open Source Innovation\n      *         * Request Demo Free Lakehouse\n\n  * Why Dremio\n  * Solutions\n    * Hadoop Migration\n    * Data Mesh\n    * Data Lakehouse\n  * Customers\n  * Partners\n  * Learn\n    *       *         * Save the date for 2024 and watch the sessions on-demand from 2023 that include topics such as Data Mesh and Iceberg.\n\nGet Notified\n\n      *         * SubsurfaceJoin the open lakehouse community.\n        * BlogStay up-to-date with product announcements and thoughts from our leadership team.\n        * Gnarly Data WavesA series featuring the latest trends and best practices for open data lakehouses.\n      *         * Events\n        * Resources\n        * Data Lakehouse\n        * Iceberg\n        * Wiki\n        * Docs\n        * University\n  * Company\n    * About Us\n    * Newsroom\n    * Press Releases\n    * Awards\n    * Careers\n  * Free Lakehouse\n  * Request Demo\n  *  \n  *  \n  * Login\n  * Contact Us\n\n# Data Transformation\n\n  1. Home\n  2. Wikis\n  3. Data Transformation\n\n  *   *   *   * \n\n## What Is Data Transformation?\n\nData transformation is a crucial process that involves converting data from\none format, structure, or type to another. This is necessary when data\nobtained from different sources is not in a standardized or compatible format,\nor when the target system or application requires a different data format or\nstructure. Data transformation is typically performed as part of the ETL\n(extract, transform, and load) process, which involves extracting data from\nsource systems, applying predefined rules and mappings to transform it, and\nloading it into target systems or data warehouses.\n\nData transformation involves a series of operations such as parsing,\nfiltering, sorting, aggregating, joining, splitting, and mapping. These\noperations manipulate the original data to produce a desired output that is\nconsistent, accurate, and usable for analytical or operational purposes. Data\ntransformation can be performed manually using scripting or automated using\nETL tools. They offer a visual interface and a library of connectors and\ncomponents that simplify the process of designing, executing, and monitoring\ndata transformation workflows.\n\n## How Is Data Transformation Used?\n\n**Data integration -** Data transformation integrates data from different\nsources into a single, unified format. For example, a retail company may need\nto integrate data from different point-of-sale systems in order to gain a\ncomprehensive view of its sales performance.\n\n**Data migration -** Data transformation is used to migrate data from one\nsystem to another, especially when moving to a new platform or database. For\nexample, a company may need to migrate data from an on-premises system to a\ncloud-based system.\n\n**Data cleansing -** Data transformation is used to clean and scrub data,\nremoving inconsistencies and errors affecting the analysis. For example, a\nfinancial institution may need to cleanse customer data to ensure compliance\nwith regulations.\n\n**Data warehousing -** Data transformation is used to prepare data for storage\nin a data warehouse, ensuring it is structured and formatted correctly. For\nexample, a healthcare organization may need to transform patient data from\ndifferent sources into a common format for storage in a data warehouse.\n\n**Data analytics -** Data transformation is used to prepare data for analysis,\nensuring it is in a format that can be easily queried and manipulated. For\nexample, a marketing team may need to transform customer data to create\ntargeted marketing campaigns based on demographics or behavior.\n\n## Challenges and Benefits of Data Transformation\n\n### Challenges\n\nOne of the main challenges of data transformation is ensuring data accuracy\nand consistency. As data is transformed from one format or structure to\nanother, there is a risk of data loss or corruption if the transformation is\nnot performed correctly.\n\nAnother challenge of data transformation is dealing with large volumes of\ndata. Transforming large datasets can be time-consuming and resource-\nintensive, and can require specialized tools and techniques. Data\ntransformation can also be complex and difficult to manage. Organizations need\nto have a clear understanding of their data and the goals of their\ntransformation process in order to ensure that the process is effective and\nefficient.\n\n### Benefits\n\nData transformation can help organizations to integrate and unify an\norganization\u2019s data from various sources and formats. This can lead to a more\ncomplete and accurate view of their data, which can drive better decision-\nmaking and insights. By transforming data into a more usable format,\norganizations can make their data more accessible to users and stakeholders.\nThis can enable faster and more informed decision-making across the\norganization.\n\nData transformation can also help organizations to optimize their data for\nanalytics and business intelligence. By transforming data into a format that\nis optimized for analysis, they can gain insights that drive business success\nand competitive advantage.\n\nOverall, data transformation is a critical process for organizations that want\nto unlock the full potential of their data. While it can present challenges,\nsuch as ensuring data accuracy and dealing with large volumes of data, the\nbenefits of data transformation, such as improved data integration,\naccessibility, and analytics, make it a worthwhile investment for\norganizations looking to drive growth and innovation.\n\n## Dremio and Data Transformation\n\nDremio's data transformation capabilities are made possible by its SQL-based\nquery engine, which allows users to manipulate data in real time. Users can\nperform a wide range of transformations on their data, such as filtering,\naggregating, joining, and pivoting, among others. These transformations can be\nperformed on data from various sources, including relational databases, NoSQL\ndatabases, cloud storage, and Hadoop-based data lakes.\n\nIn addition to these basic transformations, Dremio includes more advanced data\ntransformation capabilities, such as machine learning-based data profiling,\ndata cataloging, and automatic schema detection. These capabilities help to\nsimplify the process of data transformation and ensure that data is\ntransformed accurately and efficiently.\n\nOverall, data transformation is a crucial part of Dremio's data lake engine.\nBy providing powerful and flexible data transformation capabilities, Dremio\nallows users to extract maximum value from their data and gain insights that\ndrive business success.\n\n## Data Transformation Resources\n\n  * https://www.dremio.com/announcing-dremios-partnership-with-dbt-labs/\n  * https://docs.dremio.com/software/managing-data/data-curation/#transforming-data \n\n## Ready to Get Started?\n\nBring your users closer to the data with organization-wide self-service\nanalytics and lakehouse flexibility, scalability, and performance at a\nfraction of the cost. Run Dremio anywhere with self-managed software or Dremio\nCloud.\n\nBook a Meeting Get Started\n\n### Here are some resources to get started\n\nDocs\n\nDemo\n\nCommunity\n\n### Get Started Free\n\nNo time limit - totally free - just the way you like it.\n\nSign Up Now\n\n### See Dremio in Action\n\nNot ready to get started today? See the platform in action.\n\nWatch Demo\n\n### Talk to an Expert\n\nNot sure where to start? Get your questions answered fast.\n\nContact Us\n\n  * Products\n  * Unified Analytics\n  * Dremio Arctic\n  * Why Dremio?\n  * Data Lakehouse\n  * Pricing\n  * Security\n  * Open Source Innovation\n\n  * Support\n  * Dremio Community\n  * Dremio Hub\n  * Drivers\n  * Support Portal\n\n  * Customers\n  * Customer Stories\n  * Partners\n  * Dremio Partners\n\n  * Learn\n  * University\n  * Subsurface\n  * Subsurface Live\n  * Resources\n  * Blog\n  * Events\n  * Docs\n\n  * Company\n  * About Us\n  * Newsroom\n  * Press Releases\n  * Awards\n  * Careers\n  * Contact Us\n  * Legal\n  * Privacy Policy\n\nFree Lakehouse Request Demo\n\nDremio Community Edition Contact Us\n\n  * __\n  * __\n  * __\n  * __\n\n\u00a9 2024 Dremio All Rights Reserved\n\n  * |\n\n  * Privacy Policy\n\n  * |\n\n  * Legal\n\n\u00a9 2024 Dremio All Rights Reserved\n\n  * Privacy Policy\n\n  * Legal\n\n",
    "links": "[{\"link\": \"https://www.dremio.com/platform/unified-analytics/\", \"text\": \"\"}, {\"link\": \"https://www.dremio.com/platform/sql-query-engine/\", \"text\": \"\"}, {\"link\": \"https://www.dremio.com/platform/arctic/\", \"text\": \"\"}, {\"link\": \"https://www.dremio.com/whydremio/\", \"text\": \"Why Dremio\"}, {\"link\": \"https://www.dremio.com/reflections/\", \"text\": \"Reflections Query Acceleration\"}, {\"link\": \"https://www.dremio.com/generative-ai/\", \"text\": \"Generative AI\"}, {\"link\": \"https://www.dremio.com/on-demand-demo\", \"text\": \"Request Demo\"}, {\"link\": \"https://www.dremio.com/get-started/\", \"text\": \"Free Lakehouse\"}, {\"link\": \"https://www.dremio.com/solutions/data-lakehouse/\", \"text\": \"Data Lakehouse\"}, {\"link\": \"https://www.dremio.com/subsurface/\", \"text\": \"Get Notified\"}, {\"link\": \"https://www.dremio.com/subsurface/\", \"text\": \"\"}, {\"link\": \"https://www.dremio.com/events/\", \"text\": \"Events\"}, {\"link\": \"https://www.dremio.com/resources\", \"text\": \"Resources\"}, {\"link\": \"https://www.dremio.com/resources/topic/apache-iceberg/\", \"text\": \"Iceberg\"}, {\"link\": \"https://www.dremio.com/wiki/\", \"text\": \"Wiki\"}, {\"link\": \"https://www.dremio.com/get-started/\", \"text\": \"Free Lakehouse\"}, {\"link\": \"https://www.dremio.com/on-demand-demo\", \"text\": \"Request Demo\"}, {\"link\": \"https://www.dremio.com/\", \"text\": \"Home\"}, {\"link\": \"https://www.dremio.com/wiki\", \"text\": \"Wikis\"}, {\"link\": \"https://www.dremio.com/wiki/filtering/\", \"text\": \"filtering\"}, {\"link\": \"https://www.dremio.com/wiki/etl/\", \"text\": \"ETL\"}, {\"link\": \"https://www.dremio.com/wiki/data-migration/\", \"text\": \"Data migration\"}, {\"link\": \"https://www.dremio.com/wiki/data-cleansing/\", \"text\": \"Data cleansing\"}, {\"link\": \"https://www.dremio.com/wiki/data-warehouse/\", \"text\": \"data warehouse\"}, {\"link\": \"https://www.dremio.com/wiki/business-intelligence-bi/\", \"text\": \"business intelligence\"}, {\"link\": \"https://www.dremio.com/wiki/data-integration/\", \"text\": \"data integration\"}, {\"link\": \"https://www.dremio.com/wiki/nosql-databases/\", \"text\": \"NoSQL databases\"}, {\"link\": \"https://www.dremio.com/wiki/data-catalog/\", \"text\": \"data cataloging\"}, {\"link\": \"https://www.dremio.com/wiki/data-lake/\", \"text\": \"data lake\"}, {\"link\": \"https://www.dremio.com/contact/\", \"text\": \"Book a Meeting\"}, {\"link\": \"https://www.dremio.com/get-started/\", \"text\": \"Get Started\"}, {\"link\": \"https://www.dremio.com/on-demand-demo/\", \"text\": \"\"}, {\"link\": \"https://www.dremio.com/platform/unified-analytics/\", \"text\": \"Unified Analytics\"}, {\"link\": \"https://www.dremio.com/why-dremio\", \"text\": \"Why Dremio?\"}, {\"link\": \"https://www.dremio.com/pricing\", \"text\": \"Pricing\"}, {\"link\": \"https://www.dremio.com/subsurface/live/winter2023/\", \"text\": \"Subsurface\"}, {\"link\": \"https://www.dremio.com/subsurface/live/winter2023/\", \"text\": \"Subsurface Live\"}, {\"link\": \"https://www.dremio.com/events/\", \"text\": \"Events\"}, {\"link\": \"https://www.dremio.com/legal\", \"text\": \"Legal\"}, {\"link\": \"https://www.dremio.com/legal/privacy-policy\", \"text\": \"Privacy Policy\"}, {\"link\": \"https://www.dremio.com/get-started/\", \"text\": \"Free Lakehouse\"}, {\"link\": \"https://www.dremio.com/on-demand-demo/\", \"text\": \"Request Demo\"}, {\"link\": \"https://www.dremio.com/get-started-dremio-software\", \"text\": \"Dremio Community Edition\"}, {\"link\": \"https://www.dremio.com/contact\", \"text\": \"Contact Us\"}, {\"link\": \"https://www.dremio.com/\", \"text\": \"\"}, {\"link\": \"https://www.dremio.com/legal/privacy-policy/\", \"text\": \"Privacy Policy\"}, {\"link\": \"https://www.dremio.com/legal/\", \"text\": \"Legal\"}, {\"link\": \"https://www.dremio.com/legal/privacy-policy/\", \"text\": \"Privacy Policy\"}, {\"link\": \"https://www.dremio.com/legal/\", \"text\": \"Legal\"}]",
    "priceAndPlans": "X\n\nEarly Release\n\nUnlock the full potential of your data with Our O\u2019Reilly Book \"Apache Iceberg:\nThe Definitive Guide\"  \n  \n---  \n  \n  *   * Products\n    *       *         * Unified AnalyticsGoverned self-service access across all your data\n        * SQL Query EngineBest price-performance for BI and interactive analytics\n        * Lakehouse ManagementIceberg data catalog with Git\u2011inspired versioning\n      *         * Why Dremio\n        * Pricing\n        * Reflections Query Acceleration\n        * Generative AI\n        * Security\n        * Open Source Innovation\n      *         * Request Demo Free Lakehouse\n\n  * Why Dremio\n  * Solutions\n    * Hadoop Migration\n    * Data Mesh\n    * Data Lakehouse\n  * Customers\n  * Partners\n  * Learn\n    *       *         * Save the date for 2024 and watch the sessions on-demand from 2023 that include topics such as Data Mesh and Iceberg.\n\nGet Notified\n\n      *         * SubsurfaceJoin the open lakehouse community.\n        * BlogStay up-to-date with product announcements and thoughts from our leadership team.\n        * Gnarly Data WavesA series featuring the latest trends and best practices for open data lakehouses.\n      *         * Events\n        * Resources\n        * Data Lakehouse\n        * Iceberg\n        * Wiki\n        * Docs\n        * University\n  * Company\n    * About Us\n    * Newsroom\n    * Press Releases\n    * Awards\n    * Careers\n  * Free Lakehouse\n  * Request Demo\n  *  \n  *  \n  * Login\n  * Contact Us\n\n#  Dremio Pricing\n\n##  Dremio Cloud\n\nOur Standard Edition is everything you need to successfully build, automate,\nand query your lakehouse in production. Or check out our Enterprise Edition\nfor security and support for large-scale lakehouse environments.\n\nStandard\n\nFree forever!\n\n  * Fully-managed lakehouse platform \n  * Global control plane \n  * Infinite scale and concurrency \n  * Self-service data curation and sharing \n  * Built-in governance and lineage \n  * Transparent query acceleration \n  * SQL DML on the lakehouse \n  * Analyze data in external sources \n  * Best-in-class BI tool integration \n  * Data encrypted in motion \n  * Audit logs \n  * Social identity provider integration \n  * SOC 2 Type 2 \n  * ISO 27001 \n  * HIPAA Compliant \n  * Community Support \n\nGet Started\n\nEnterprise\n\n$0.39/DCU\n\n  * Everything in Standard, plus\u2026 \n  * Enterprise identity provider integration \n  * Data masking \n  * SCIM synchronization \n  * Support Options Available \n\nGet Started\n\nA Dremio Consumption Unit (DCU) is the unit used to measure consumption on the\nDremio platform. The number of DCUs consumed is based on compute engine size\nand processing time, with processing time measured on a per-second basis.The\nprice listed represents on-demand pricing for the Dremio Cloud platform only.\nIt does not include the cost of any required cloud infrastructure, e.g. Amazon\nEC2 instances. Please contact Dremio for additional pricing options.\n\n##  Dremio Software\n\nRun Dremio Enterprise anywhere on your own infrastructure\n\nContact us for Dremio Software pricing\n\nGet Started\n\nCapabilities Overview\n\nPlatform | Dremio Cloud | Dremio Software  \n---|---|---  \nEdition | Standard (Free) | Enterprise | Community | Enterprise  \n| Everything needed to build, automate, and query your lakehouse in production\n| Enterprise security and support for large-scale lakehouse environments |\nFreedom to run Dremio Community Edition on your own infrastructure | Freedom\nto run Dremio Enterprise anywhere on your own infrastructure  \nCloud Service  \nFully-managed service |  |  |  |  \nInfinite scale |  |  |  |  \nGlobal control plane for multi-cloud |  |  |  |  \nFull ANSI SQL |  |  |  |  \nDremio Community Support |  |  |  |  \nDremio Support (8x5) |  |  |  |  \nGoverned, Self-Service Experience  \nSemantic layer |  |  |  |  \nData curation |  |  |  |  \nData sharing |  |  |  |  \nData lineage |  |  |  |  \nSecurity  \nData encrypted in motion |  |  |  |  \nAudit logs |  |  |  |  \nPrivileges |  |  |  |  \nRBAC with built-in roles |  |  |  |  \nCustom roles |  |  |  |  \nTable & column level policies |  |  |  |  \nData masking policies |  |  |  |  \nIP whitelisting |  |  |  |  \nIdentity Management & Authentication  \nLocal Identities |  |  |  |  \nSocial IdP Integration (e.g., GSuite, Microsoft, GitHub) |  |  |  |  \nEnterprise IdP Integration (e.g., Azure AD, Okta) |  |  |  |  \nSCIM synchronization |  |  |  |  \nIntegration with external policy providers (e.g., Privacera) |  |  |  |  \nPersonal Access Tokens |  |  |  |  \nExternal token providers |  |  |  |  \nRegulatory Compliance  \nSOC 2 Type 2 |  |  |  |  \nISO 27001 |  |  |  |  \nGDPR & CCPA |  |  |  |  \nHIPAA Compliant |  |  |  |  \n  \n### Query engine features\n\nData Sources  \n---  \nAnalyze data stored in cloud data lake storage (e.g., S3, ADLS, GCS) |  |  |\n|  \nNative support for structured and unstructured file formats (e.g., Parquet,\nCSV, JSON) |  |  |  |  \nNative support for table formats (e.g., Apache Iceberg/Delta Lake) |  |  |  |  \nAnalyze data stored in RDBMS/NoSQL sources |  |  |  |  \nSQL Support, Performance, and Scalability  \nFull ANSI SQL |  |  |  |  \nTransparent query acceleration |  |  |  |  \nReflection management |  |  |  |  \nCost-based optimizer |  |  |  |  \nWorkload management |  |  |  |  \nMulti-engine architecture |  |  |  |  \nEngine replicas (scale-out for concurrency) |  |  |  |  \nAutomatically scale up/down and pause engines |  |  |  |  \nInterfaces and Client Connectivity  \nNative integrations with Tableau and Power BI |  |  |  |  \nREST API |  |  |  |  \nJDBC/ODBC |  |  |  |  \nArrow Flight |  |  |  |  \n  \n### Get Started Free\n\nNo time limit - totally free - just the way you like it.\n\nSign Up Now\n\n### See Dremio in Action\n\nNot ready to get started today? See the platform in action.\n\nWatch Demo\n\n### Talk to an Expert\n\nNot sure where to start? Get your questions answered fast.\n\nContact Us\n\n  * Products\n  * Unified Analytics\n  * Dremio Arctic\n  * Why Dremio?\n  * Data Lakehouse\n  * Pricing\n  * Security\n  * Open Source Innovation\n\n  * Support\n  * Dremio Community\n  * Dremio Hub\n  * Drivers\n  * Support Portal\n\n  * Customers\n  * Customer Stories\n  * Partners\n  * Dremio Partners\n\n  * Learn\n  * University\n  * Subsurface\n  * Subsurface Live\n  * Resources\n  * Blog\n  * Events\n  * Docs\n\n  * Company\n  * About Us\n  * Newsroom\n  * Press Releases\n  * Awards\n  * Careers\n  * Contact Us\n  * Legal\n  * Privacy Policy\n\nFree Lakehouse Request Demo\n\nDremio Community Edition Contact Us\n\n  * __\n  * __\n  * __\n  * __\n\n\u00a9 2024 Dremio All Rights Reserved\n\n  * |\n\n  * Privacy Policy\n\n  * |\n\n  * Legal\n\n\u00a9 2024 Dremio All Rights Reserved\n\n  * Privacy Policy\n\n  * Legal\n\n"
}