{
    "summary": "Skip Navigation\n\nStitch - A Talend Product\n\nMain Navigation\n\n  * Platform\n    * Extensibility\n    * Orchestration\n    * Security & Compliance\n    * Performance & Reliability\n    * Embedding\n    * Transformation & Quality\n    * For Enterprise\n  * Solutions\n    * Sales\n    * Marketing\n    * Product Intelligence\n  * Integrations\n    * Sources\n    * Destination and Warehouses\n    * Analysis Tools\n  * Pricing\n  * Customers\n  * Documentation\n  * Sign in\n  * Try it free\n  * Contact Sales\n\n# Data transformation: A comprehensive guide to benefits, challenges, and\ntools\n\n## What is data transformation?\n\nAnalyzing information requires structured and accessible data for best\nresults. Data transformation enables organizations to alter the structure and\nformat of raw data as needed. Learn how your enterprise can transform its data\nto perform analytics efficiently.\n\n### Defining data transformation and its role in data management\n\nBusinesses run on data that is used to inform decision making in every realm\nof the organization. But for data to be useful, it has to be changed from its\nraw data source form into a format that is easy for applications and systems\nto use \u2014 and for people to interpret and understand. To achieve this in the\ndata management process, companies use data transformation to convert the data\ninto the needed format.\n\n### The importance of transforming raw data for analysis and visualization\n\nOne of the major purposes of data transformation is to make data usable for\nanalysis and visualization, key components of business intelligence and data-\ndriven decision making. Businesses generate and collect vast amounts of data,\nbut until it is transformed, its value cannot be leveraged. Raw data is often\nstored in data warehouses or data lakes, where it waits to be selected and\nused for analysis.\n\n### How data transformation fits into the ETL/ELT process\n\nTo obtain the data from its repository, businesses use related data\ntransformation processes called extract/transform/load (ETL) and\nextract/load/transform (ELT).\n\nFor data stored in on-premises data warehouses, ETL extracts the data from the\nrepository, transforms it into the required format, then loads it into an\napplication or system. There it can be used for business intelligence, data\nanalysis, and other purposes.\n\nFor cloud-based data warehouses, the ELT process is used. The scalability of\nthe cloud platform lets organizations skip preload transformations and load\nraw data into the data warehouse, then transform it at query time.\n\nProcesses such as data integration, data migration, data warehousing, and data\nwrangling all may involve data transformation.\n\nData transformation may be constructive (adding, copying, and replicating\ndata), destructive (deleting fields and records), aesthetic (standardizing\nsalutations or street names), or structural (renaming, moving, and combining\ncolumns in a database).\n\nAn enterprise can choose among a variety of ETL tools that automate the\nprocess of data transformation. Data analysts, data engineers, and data\nscientists also transform data using scripting languages such as Python or\ndomain-specific languages like SQL. They may also use tools such as Stitch to\nget to insights faster using fully automated cloud data pipelines that do not\nrequire any coding. This can greatly speed up the process of making data\nusable and useful.\n\n## The benefits and challenges of data transformation\n\nTransforming data yields several benefits:\n\n  * Data is transformed to make it better organized. Transformed data may be easier for both humans and computers to use.\n  * Properly formatted and validated data improves data quality and protects applications from potential landmines such as null values, unexpected duplicates, incorrect indexing, and incompatible formats.\n  * Data transformation facilitates compatibility between applications, systems, and types of data. Data used for multiple purposes may need to be transformed in different ways.\n\nHowever, there are challenges to transforming data effectively:\n\n  * Data transformation can be expensive. The cost is dependent on the specific infrastructure, software, and tools used to process data. Expenses may include software licensing, computing resources, and the time spent on task by the needed personnel.\n  * Data transformation processes can be resource-intensive. Performing transformations before loading into a data warehouse, or transforming data before feeding it into applications can create a computational burden that slows down other operations. If you use a cloud-based data warehouse, you can do the transformations after loading because the platform can scale up to meet demand.\n  * Lack of expertise and carelessness can introduce problems during transformation. Data analysts without appropriate subject matter expertise are less likely to notice typos or incorrect data because they are less familiar with the range of accurate and permissible values. For example, someone working on medical data who is unfamiliar with relevant terms might fail to flag different names for a disease that should be mapped to a singular value or notice and correct misspellings.\n  * Enterprises can perform transformations that don't suit their needs. A business might change information to a specific format for one application only to then need to revert the information back to its prior format for a different application.\n\n## Techniques for data transformation\n\nData transformation can increase the efficiency of analytic and business\nprocesses and enable better data-driven decision-making. The first phase of\ndata transformations should include things like data type conversion and\nflattening of hierarchical data. These operations shape data to increase\ncompatibility with analytics systems. Data analysts and data scientists can\nimplement further transformations additively as necessary as individual layers\nof processing. Each layer of processing should be designed to perform a\nspecific set of tasks that meet a known business or technical requirement. The\nfollowing are techniques for data transformation.\n\n### Extraction and parsing: Accessing data from different sources\n\nIn the modern ELT process, data ingestion begins with extracting information\nfrom a data source, followed by copying the data to its destination. Initial\ntransformations are focused on shaping the format and structure of data to\nensure its compatibility with both the destination system and the data already\nthere. Parsing fields out of comma-delimited log data for loading to a\nrelational database is an example of this type of data transformation.\n\nBefore your enterprise can run analytics, and even before you transform the\ndata, you must replicate it to a data warehouse architected for analytics.\nMost organizations today choose a cloud data warehouse, allowing them to take\nfull advantage of ELT. Stitch can load all of your data to your preferred data\nwarehouse in a raw state, ready for transformation.\n\n### Translation and mapping: Converting data formats and structures\n\nSome of the most basic data transformations involve the mapping and\ntranslation of data. For example, a column containing integers representing\nerror codes can be mapped to the relevant error descriptions, making that\ncolumn easier to understand and more useful for display in a customer-facing\napplication.\n\nTranslation converts data from formats used in one system to formats\nappropriate for a different system. Even after parsing, web data might arrive\nin the form of hierarchical JSON or XML files, but need to be translated into\nrow and column data for inclusion in a relational database.\n\n### Filtering, aggregation, and summarization: Reducing and generalizing data\n\nData transformation is often concerned with whittling data down and making it\nmore manageable. Data may be consolidated by filtering out unnecessary fields,\ncolumns, and records. Omitted data might include numerical indexes in data\nintended for graphs and dashboards or records from business regions that\naren\u2019t of interest in a particular study.\n\nData might also be aggregated or summarized by, for instance, transforming a\ntime series of customer transactions to hourly or daily sales counts.\n\nBI tools can do this filtering and aggregation, but it can be more efficient\nto do the transformations before a reporting tool accesses the data.\n\n### Enrichment and imputation: Handling missing values and enhancing the\ndataset\n\nData from different sources can be merged to create denormalized, enriched\ninformation. A customer\u2019s transactions can be rolled up into a grand total and\nadded into a customer information table for quicker reference or for use by\ncustomer analytics systems. Long or freeform fields may be split into multiple\ncolumns, and missing values can be imputed or corrupted data replaced as a\nresult of these kinds of transformations.\n\n### Indexing and ordering: Organizing data for optimal retrieval\n\nData can be transformed so that it's ordered logically or to suit a data\nstorage schema. In relational database management systems, for example,\ncreating indexes can improve performance or improve the management of\nrelationships between different tables.\n\n### Anonymization and encryption: Protecting sensitive data\n\nData containing personally identifiable information, or other information that\ncould compromise privacy or security, should be anonymized before propagation.\nEncryption of private data is a requirement in many industries, and systems\ncan perform encryption at multiple levels, from individual database cells to\nentire records or fields.\n\n### Modeling, typecasting, formatting, and renaming: Preparing data for\nanalysis\n\nFinally, a whole set of transformations can reshape data without changing\ncontent. This includes casting and converting data types for compatibility,\nadjusting dates and times with offsets and format localization, and renaming\nschemas, tables, and columns for clarity.\n\n## Data transformation tools and technologies\n\nBusinesses have multiple options for data transformation tools and\ntechnologies, depending on size of organization, budget, and a company\u2019s data\nmanagement strategy.\n\n### ETL tools for data transformation\n\nThere are numerous ETL tools available for data transformation. They are\ntypically categorized into four groups:\n\n  * **Enterprise-grade.** These tools are sold by commercial organizations and often deliver the most mature solutions. They are geared for businesses that do not have the time or resources to devote to staffing an in-house team to build their own solutions. Enterprise-grade solutions come with pre-defined pipelines, easy to use interfaces, and are built with the IT and line of business user in mind. Stitch provides an enterprise-grade solution. \n  * **Open-source.** Teams that can develop, build, and maintain their own ETL process often use open-source ETL tools to do so. Many are free and allow businesses to access the tool\u2019s source code to study its technical infrastructure and extensibility. \n  * **Cloud-based platform tools.** Integration platform-as-a-service providers often bake ETL tools into their offerings. Platform-based tools offer high latency, availability, and elasticity, enabling organizations to scale their data transformation to the volume and speed the business needs. \n  * **Custom ETL tools.** Some businesses prefer to develop their own custom ETL tools so they can tailor a solution to their organization\u2019s unique infrastructure or priorities. ETL tools are often built with SQL, Python, and Java programming languages. This approach requires intensive internal resources to build, test, maintain, and update the tool. It also requires in-house documentation and training to enable new users. \n\n### Getting started with ETL tools for data transformation\n\nMost organizations are already doing data transformation as part of their data\nmanagement strategy. However, choosing the right ETL tools is often\nchallenging. To help determine the type of ETL tool that is best for your\norganization, consider the following:\n\n  * **Determine your use case.** How much data do you need to transform and how will it be used? \n  * **Align with your budget.** Consider the cost of each option, including the \u201chidden\u201d costs of open-source and custom ETL, when evaluating options. \n  * **Consider who will use it.** Will you need your ETL tools to be available to various teams? If so, how easy it to make a tool available to others and to train new users? \n  * **Be mindful of data quality.** Automated features in ETL tools can help enforce data quality. \n  * **Be sure it can access data wherever it lives.** ETL tools need to be able connect to data sources in all different formats. \n  * **Know what level of technical skills are required.** Will you have only developers working with the tool, or do you want to make it available to business users who can then build their own data pipelines and use the tool to inform business processes and analytics? \n\nStitch offers an enterprise-grade cloud ETL platform to help power actionable\ninsights for any analytics environment.\n\nLearn more about Stitch.\n\n## Give Stitch a try, on us\n\nStitch streams all of your data directly to your analytics warehouse.\n\nSign up for free \u2192Contact Sales \u2192\n\nSet up in minutesUnlimited data volume during trial\n\n  *   *   *   * \n\n  * Products\n  * Extensibility\n  * Orchestration\n  * Security\n  * Performance\n  * Embedding\n  * Pricing\n  * For Enterprise\n  * Compare ETL Tools\n\n  * Solutions\n  * Sales\n  * Marketing\n  * Product Intelligence\n\n  * Integrations\n  * Sources\n  * Destinations\n  * Analysis tools\n\n  * Learn\n  * Documentation\n  * Community\n  * Blog\n  * Changelog\n  * Resources\n  * Github\n  * Status\n\n  * Company\n  * About\n  * Careers\n  * Contact\n  * Customers\n  * Partners\n\n  * \u00a9 2005-2023 Talend, Inc., All Rights Reserved\n  * Terms of use\n  * Privacy Information\n  * Cookie Policy\n\n",
    "links": "[{\"link\": \"https://www.stitchdata.com/\", \"text\": \"\"}, {\"link\": \"https://www.stitchdata.com/platform/extensibility/\", \"text\": \"Extensibility\"}, {\"link\": \"https://www.stitchdata.com/platform/orchestration/\", \"text\": \"Orchestration\"}, {\"link\": \"https://www.stitchdata.com/platform/security/\", \"text\": \"Security & Compliance\"}, {\"link\": \"https://www.stitchdata.com/platform/performance/\", \"text\": \"Performance & Reliability\"}, {\"link\": \"https://www.stitchdata.com/platform/embedding/\", \"text\": \"Embedding\"}, {\"link\": \"https://www.stitchdata.com/platform/datatransformation/\", \"text\": \"Transformation & Quality\"}, {\"link\": \"https://www.stitchdata.com/platform/enterprise/\", \"text\": \"For Enterprise\"}, {\"link\": \"https://www.stitchdata.com/solutions/sales/\", \"text\": \"Sales\"}, {\"link\": \"https://www.stitchdata.com/solutions/marketing/\", \"text\": \"Marketing\"}, {\"link\": \"https://www.stitchdata.com/solutions/product/\", \"text\": \"Product Intelligence\"}, {\"link\": \"https://www.stitchdata.com/integrations/sources/\", \"text\": \"Sources\"}, {\"link\": \"https://www.stitchdata.com/integrations/destinations/\", \"text\": \"Destination and Warehouses\"}, {\"link\": \"https://www.stitchdata.com/integrations/analysis-tools/\", \"text\": \"Analysis Tools\"}, {\"link\": \"https://www.stitchdata.com/pricing/\", \"text\": \"Pricing\"}, {\"link\": \"https://www.stitchdata.com/customers/\", \"text\": \"Customers\"}, {\"link\": \"https://www.stitchdata.com/docs/\", \"text\": \"Documentation\"}, {\"link\": \"https://www.stitchdata.com/contact/\", \"text\": \"Contact Sales\"}, {\"link\": \"https://www.stitchdata.com/contact/\", \"text\": \"Contact Sales \u2192\"}, {\"link\": \"https://www.stitchdata.com/platform/extensibility/\", \"text\": \"Extensibility\"}, {\"link\": \"https://www.stitchdata.com/platform/orchestration/\", \"text\": \"Orchestration\"}, {\"link\": \"https://www.stitchdata.com/platform/security/\", \"text\": \"Security\"}, {\"link\": \"https://www.stitchdata.com/platform/performance/\", \"text\": \"Performance\"}, {\"link\": \"https://www.stitchdata.com/platform/embedding/\", \"text\": \"Embedding\"}, {\"link\": \"https://www.stitchdata.com/pricing/\", \"text\": \"Pricing\"}, {\"link\": \"https://www.stitchdata.com/platform/enterprise/\", \"text\": \"For Enterprise\"}, {\"link\": \"https://www.stitchdata.com/vs/\", \"text\": \"Compare ETL Tools\"}, {\"link\": \"https://www.stitchdata.com/solutions/sales/\", \"text\": \"Sales\"}, {\"link\": \"https://www.stitchdata.com/solutions/marketing/\", \"text\": \"Marketing\"}, {\"link\": \"https://www.stitchdata.com/solutions/product/\", \"text\": \"Product Intelligence\"}, {\"link\": \"https://www.stitchdata.com/integrations/sources/\", \"text\": \"Sources\"}, {\"link\": \"https://www.stitchdata.com/integrations/destinations/\", \"text\": \"Destinations\"}, {\"link\": \"https://www.stitchdata.com/integrations/analysis-tools/\", \"text\": \"Analysis tools\"}, {\"link\": \"https://www.stitchdata.com/docs/\", \"text\": \"Documentation\"}, {\"link\": \"https://www.stitchdata.com/docs/changelog/\", \"text\": \"Changelog\"}, {\"link\": \"https://www.stitchdata.com/resources/\", \"text\": \"Resources\"}, {\"link\": \"https://www.stitchdata.com/company/\", \"text\": \"About\"}, {\"link\": \"https://www.stitchdata.com/jobs/\", \"text\": \"Careers\"}, {\"link\": \"https://www.stitchdata.com/contact/\", \"text\": \"Contact\"}, {\"link\": \"https://www.stitchdata.com/customers/\", \"text\": \"Customers\"}, {\"link\": \"https://www.stitchdata.com/partners/\", \"text\": \"Partners\"}, {\"link\": \"https://www.stitchdata.com/cookies/\", \"text\": \"Cookie Policy\"}]"
}