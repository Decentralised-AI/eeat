{
    "summary": "Open in app\n\nSign up\n\nSign in\n\nWrite\n\nSign up\n\nSign in\n\n# ChatGPT Clone With Streamlit And LangChain\n\nPrince Krampah\n\n\u00b7\n\nFollow\n\nPublished in\n\n\ud835\udc00\ud835\udc08 \ud835\udc26\ud835\udc28\ud835\udc27\ud835\udc24\ud835\udc2c.\ud835\udc22\ud835\udc28\n\n\u00b7\n\n7 min read\n\n\u00b7\n\nSep 5, 2023\n\n\\--\n\nListen\n\nShare\n\nI have recently been working with streamlit and got this idea, \u201cWhat If I\nbuild a streamlit application with LangChain to make a clone of ChatGPT?\u201d. I\ntook on the challenge and did it! In this article, I\u2019ll go ahead and explain\nto you how I was able to do just that.\n\nIn previous articles, I went ahead and showed how to use LLMs that are hosted\nin the cloud. You can find the video of this here. In this post, we\u2019ll be\nusing OpenAI\u2019s GPT-3.5 turbo for this.\n\n# Getting OpenAI API Key\n\nThe thing we need to do is get our own OpenAI API key ready. You can do this\nby visiting the official documentation of OpenAI and creating an account, once\ndone, head to the API tab and get an API key. It\u2019s all for free for a given\namount of tokens, just enough to write this app.\n\nOnce you have the API key, create a project folder with two main files. The\nfirst file is **app.py** and **.env**\n\n\u2192 **Project directory should look like**\n\n    \n    \n     |-- root_directory  \n    |-----> app.py  \n    |----->.env\n\nInside of the .env file, add the following:\n\n    \n    \n    OPENAI_API_KEY=add_your_openai_api_key_here\n\n# Library Installations\n\nWe\u2019ll use three main libraries in this project, all are Python3 libraries.\nI\u2019ll create a python virtual environment to house all these libraries to keep\nour global Python environment clean from clutter.\n\nFor Linux and Macbook users, you can use the command below to setup a virtual\nenvironment.\n\n    \n    \n    $ python3 -m venv venv\n\nThis will create a folder in the root directory of your project called\n**venv.** Now we need to activate this virtual environment, to make it active,\nuse the command below. Again this is for Linux and MacBook users.\n\n    \n    \n    $ source venv/bin/activate\n\nFor Windows users, kindly refer to this post on how to create a virtual\nenvironment and have it activated.\n\nNow, I am assuming you have the virtual environment created and activated.\nLet\u2019s move on to installing the libraries we need.\n\n    \n    \n    $ pip install langchain streamlit openai python-decouple\n\nGreat! now we are ready to go and lead on coding!!!\n\n# Writing Streamlit ChatGPT Clone\n\n## Importing the necessary libraries\n\nImport streamlit, LangChain and decouple libraries to get started.\n\n    \n    \n    import streamlit as st  \n    from langchain.chat_models import ChatOpenAI  \n    from langchain.chains import LLMChain  \n    from langchain.prompts import PromptTemplate  \n    from decouple import config  \n    from langchain.memory import ConversationBufferWindowMemory\n\n## Streamlit page configuration and title setup\n\nWrite the following to setup your streamlit page configurations and title. The\n**_page_title_** is what appears as the name of the tap in your browser,\n**_page_icon_** is that is the icon of the tap in the browser,\n**_st.title()_** is the title of the page itself in the site(web app).\n\nIf you wondering where I got the icons (emoji) from, checkout here\n\n    \n    \n    st.set_page_config(  \n        page_title=\"ChatGPT Clone\",  \n        page_icon=\"\ud83e\udd16\",  \n        layout=\"wide\"  \n    )  \n      \n      \n    st.title(\"ChatGPT Clone\")\n\nOnce you have done this first two steps, your code should now look something\nlike this:\n\n    \n    \n    import streamlit as st  \n    from langchain.chat_models import ChatOpenAI  \n    from langchain.chains import LLMChain  \n    from langchain.prompts import PromptTemplate  \n    from decouple import config  \n    from langchain.memory import ConversationBufferWindowMemory  \n      \n      \n    st.set_page_config(  \n        page_title=\"ChatGPT Clone\",  \n        page_icon=\"\ud83e\udd16\",  \n        layout=\"wide\"  \n    )  \n      \n    st.title(\"ChatGPT Clone\")\n\nWe can run this to see the results, to run this use the command below\n\n    \n    \n    $ streamlit run app.py\n\nIf you use a different name for your Python file, make sure to replace\n`app.py` with that file name.\n\nStreamlit Initial UI\n\n## Session and messages store\n\nNow, let\u2019s handle the application session for streamlit and how to store user\nand bot responses in the session. We\u2019ll first check if `messages` exists in\nthe session of the streamlit application, if it does not exist, we create one\nand we\u2019ll use it to store messages.\n\n    \n    \n    # check for messages in session and create if not exists  \n    if \"messages\" not in st.session_state.keys():  \n        st.session_state.messages = [  \n            {\"role\": \"assistant\", \"content\": \"Hello there, am ChatGPT clone\"}  \n        ]  \n      \n      \n    # Display all messages  \n    for message in st.session_state.messages:  \n        with st.chat_message(message[\"role\"]):  \n            st.write(message[\"content\"])\n\n## User input and storing in session\n\nLet\u2019s create an input field to get the user input and have it stored in the\nsession of the streamlit application. This user input is what will act as user\ninput to the LLM(GPT-3).\n\n    \n    \n    user_prompt = st.chat_input()  \n      \n    if user_prompt is not None:  \n        st.session_state.messages.append({\"role\": \"user\", \"content\": user_prompt})  \n        with st.chat_message(\"user\"):  \n            st.write(user_prompt)\n\nUser Input and Initial Message\n\nPutting everything we have done so far together. The code should look like:\n\n    \n    \n    import streamlit as st  \n    from langchain.chat_models import ChatOpenAI  \n    from langchain.chains import LLMChain  \n    from langchain.prompts import PromptTemplate  \n    from decouple import config  \n    from langchain.memory import ConversationBufferWindowMemory  \n      \n    st.set_page_config(  \n        page_title=\"ChatGPT Clone\",  \n        page_icon=\"\ud83e\udd16\",  \n        layout=\"wide\"  \n    )  \n      \n    st.title(\"ChatGPT Clone\")  \n      \n    # check for messages in session and create if not exists  \n    if \"messages\" not in st.session_state.keys():  \n        st.session_state.messages = [  \n            {\"role\": \"assistant\", \"content\": \"Hello there, am ChatGPT clone\"}  \n        ]  \n      \n    # Display all messages  \n    for message in st.session_state.messages:  \n        with st.chat_message(message[\"role\"]):  \n            st.write(message[\"content\"])  \n      \n    user_prompt = st.chat_input()  \n      \n    if user_prompt is not None:  \n        st.session_state.messages.append({\"role\": \"user\", \"content\": user_prompt})  \n        with st.chat_message(\"user\"):  \n            st.write(user_prompt)\n\n## Creating LLM and Prompt Templates\n\nNow we can move on to creating the prompt using LangChains\u2019s `PromptTemplate`\nclass as well with the memory and LLM chain.\n\n    \n    \n    prompt = PromptTemplate(  \n        input_variables=[\"chat_history\", \"question\"],  \n        template=\"\"\"You are a very kindl and friendly AI assistant. You are  \n        currently having a conversation with a human. Answer the questions  \n        in a kind and friendly tone with some sense of humor.  \n          \n        chat_history: {chat_history},  \n        Human: {question}  \n        AI:\"\"\"  \n    )  \n      \n      \n    llm = ChatOpenAI(openai_api_key=config(\"OPENAI_API_KEY\"))  \n    memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=4)  \n    llm_chain = LLMChain(  \n        llm=llm,  \n        memory=memory,  \n        prompt=prompt  \n    )\n\nMake sure that `chat_history` is the same as`memory_key` of the memory class.\nThis needs to be the same, by default it\u2019s called `history` since we modified\nit then we need to keep track of it.\n\nYour code should now look something like:\n\n    \n    \n    import streamlit as st  \n    from langchain.chat_models import ChatOpenAI  \n    from langchain.chains import LLMChain  \n    from langchain.prompts import PromptTemplate  \n    from decouple import config  \n    from langchain.memory import ConversationBufferWindowMemory  \n      \n    prompt = PromptTemplate(  \n        input_variables=[\"chat_history\", \"question\"],  \n        template=\"\"\"You are a very kindl and friendly AI assistant. You are  \n        currently having a conversation with a human. Answer the questions  \n        in a kind and friendly tone with some sense of humor.  \n          \n        chat_history: {chat_history},  \n        Human: {question}  \n        AI:\"\"\"  \n    )  \n      \n    llm = ChatOpenAI(openai_api_key=config(\"OPENAI_API_KEY\"))  \n    memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=4)  \n    llm_chain = LLMChain(  \n        llm=llm,  \n        memory=memory,  \n        prompt=prompt  \n    )  \n      \n    st.set_page_config(  \n        page_title=\"ChatGPT Clone\",  \n        page_icon=\"\ud83e\udd16\",  \n        layout=\"wide\"  \n    )  \n      \n    st.title(\"ChatGPT Clone\")  \n      \n    # check for messages in session and create if not exists  \n    if \"messages\" not in st.session_state.keys():  \n        st.session_state.messages = [  \n            {\"role\": \"assistant\", \"content\": \"Hello there, am ChatGPT clone\"}  \n        ]  \n      \n    # Display all messages  \n    for message in st.session_state.messages:  \n        with st.chat_message(message[\"role\"]):  \n            st.write(message[\"content\"])  \n      \n    user_prompt = st.chat_input()  \n      \n    if user_prompt is not None:  \n        st.session_state.messages.append({\"role\": \"user\", \"content\": user_prompt})  \n        with st.chat_message(\"user\"):  \n            st.write(user_prompt)\n\n## Passing User Input To Prompt\n\nNow that we are able to get the user input, we\u2019ll have to pass it into the\nprompt to get back an output. Here\u2019s how we can do this.\n\n    \n    \n    if st.session_state.messages[-1][\"role\"] != \"assistant\":  \n        with st.chat_message(\"assistant\"):  \n            with st.spinner(\"Loading...\"):  \n                ai_response = llm_chain.predict(question=user_prompt)  \n                st.write(ai_response)  \n        new_ai_message = {\"role\": \"assistant\", \"content\": ai_response}  \n        st.session_state.messages.append(new_ai_message)\n\nThis will return the model\u2019s output and we are going to output it on the\nstreamlit application then store the message in the session state of the\napplication.\n\nOnce you do this, we have the application done and ready to run. You final\ncode should look like so:\n\n    \n    \n    import streamlit as st  \n    from langchain.chat_models import ChatOpenAI  \n    from langchain.chains import LLMChain  \n    from langchain.prompts import PromptTemplate  \n    from decouple import config  \n    from langchain.memory import ConversationBufferWindowMemory  \n      \n    prompt = PromptTemplate(  \n        input_variables=[\"chat_history\", \"question\"],  \n        template=\"\"\"You are a very kindl and friendly AI assistant. You are  \n        currently having a conversation with a human. Answer the questions  \n        in a kind and friendly tone with some sense of humor.  \n          \n        chat_history: {chat_history},  \n        Human: {question}  \n        AI:\"\"\"  \n    )  \n      \n      \n    llm = ChatOpenAI(openai_api_key=config(\"OPENAI_API_KEY\"))  \n    memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=4)  \n    llm_chain = LLMChain(  \n        llm=llm,  \n        memory=memory,  \n        prompt=prompt  \n    )  \n      \n      \n    st.set_page_config(  \n        page_title=\"ChatGPT Clone\",  \n        page_icon=\"\ud83e\udd16\",  \n        layout=\"wide\"  \n    )  \n      \n      \n    st.title(\"ChatGPT Clone\")  \n      \n      \n    # check for messages in session and create if not exists  \n    if \"messages\" not in st.session_state.keys():  \n        st.session_state.messages = [  \n            {\"role\": \"assistant\", \"content\": \"Hello there, am ChatGPT clone\"}  \n        ]  \n      \n      \n    # Display all messages  \n    for message in st.session_state.messages:  \n        with st.chat_message(message[\"role\"]):  \n            st.write(message[\"content\"])  \n      \n      \n    user_prompt = st.chat_input()  \n      \n    if user_prompt is not None:  \n        st.session_state.messages.append({\"role\": \"user\", \"content\": user_prompt})  \n        with st.chat_message(\"user\"):  \n            st.write(user_prompt)  \n      \n      \n    if st.session_state.messages[-1][\"role\"] != \"assistant\":  \n        with st.chat_message(\"assistant\"):  \n            with st.spinner(\"Loading...\"):  \n                ai_response = llm_chain.predict(question=user_prompt)  \n                st.write(ai_response)  \n        new_ai_message = {\"role\": \"assistant\", \"content\": ai_response}  \n        st.session_state.messages.append(new_ai_message)\n\nCongratulations, let\u2019s run the app again to see how it looks and works.\n\n    \n    \n    $ streamlit run app.py\n\nFinal UI Appearance\n\n# Conclusion\n\nCongratulations! for making it to the end, I hope this project has really\ntaught you something about working with streamlit and LangChain. If you are\ninterested in LangChain and how it works. I have a whole series on it on page\nhere on medium, be sure to check it out.\n\nI also have a video series on the same, as well as a video version of this\narticle on my YouTube channel.\n\nHappy coding and see you soon\n\n## Sign up to discover human stories that deepen your understanding of the\nworld.\n\n## Free\n\nDistraction-free reading. No ads.\n\nOrganize your knowledge with lists and highlights.\n\nTell your story. Find your audience.\n\nSign up for free\n\n## Membership\n\nAccess the best member-only stories.\n\nSupport independent authors.\n\nListen to audio narrations.\n\nRead offline.\n\nJoin the Partner Program and earn for your writing.\n\nTry for $5/month\n\nLangchain\n\nStreamlit\n\nChatgpt Clone\n\nPython\n\nAI\n\n\\--\n\n\\--\n\nFollow\n\n## Written by Prince Krampah\n\n362 Followers\n\n\u00b7Writer for\n\n\ud835\udc00\ud835\udc08 \ud835\udc26\ud835\udc28\ud835\udc27\ud835\udc24\ud835\udc2c.\ud835\udc22\ud835\udc28\n\nHello there , am Prince a full-stack web developer, data science enthusiast,\nlover of Python Programming with a deep interest in deep learning, computer\nvision\n\nFollow\n\nHelp\n\nStatus\n\nAbout\n\nCareers\n\nBlog\n\nPrivacy\n\nTerms\n\nText to speech\n\nTeams\n\n",
    "links": "[{\"link\": \"https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&source=post_page---two_column_layout_nav-----------------------global_nav-----------\", \"text\": \"Sign in\"}, {\"link\": \"https://medium.com/?source=---two_column_layout_nav----------------------------------\", \"text\": \"\"}, {\"link\": \"https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_topnav-----------\", \"text\": \"\"}, {\"link\": \"https://medium.com/search?source=---two_column_layout_nav----------------------------------\", \"text\": \"\"}, {\"link\": \"https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&source=post_page---two_column_layout_nav-----------------------global_nav-----------\", \"text\": \"Sign in\"}, {\"link\": \"https://medium.com/@princekrampah?source=post_page-----e0d4fa78e33d--------------------------------\", \"text\": \"\"}, {\"link\": \"https://medium.com/@princekrampah?source=post_page-----e0d4fa78e33d--------------------------------\", \"text\": \"Prince Krampah\"}, {\"link\": \"https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F43f5ed8aa6e0&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&user=Prince+Krampah&userId=43f5ed8aa6e0&source=post_page-43f5ed8aa6e0----e0d4fa78e33d---------------------post_header-----------\", \"text\": \"Follow\"}, {\"link\": \"https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Faimonks%2Fe0d4fa78e33d&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&user=Prince+Krampah&userId=43f5ed8aa6e0&source=-----e0d4fa78e33d---------------------clap_footer-----------\", \"text\": \"\"}, {\"link\": \"https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe0d4fa78e33d&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&source=-----e0d4fa78e33d---------------------bookmark_footer-----------\", \"text\": \"\"}, {\"link\": \"https://medium.com/tag/langchain?source=post_page-----e0d4fa78e33d---------------langchain-----------------\", \"text\": \"Langchain\"}, {\"link\": \"https://medium.com/tag/streamlit?source=post_page-----e0d4fa78e33d---------------streamlit-----------------\", \"text\": \"Streamlit\"}, {\"link\": \"https://medium.com/tag/chatgpt-clone?source=post_page-----e0d4fa78e33d---------------chatgpt_clone-----------------\", \"text\": \"Chatgpt Clone\"}, {\"link\": \"https://medium.com/tag/python?source=post_page-----e0d4fa78e33d---------------python-----------------\", \"text\": \"Python\"}, {\"link\": \"https://medium.com/tag/ai?source=post_page-----e0d4fa78e33d---------------ai-----------------\", \"text\": \"AI\"}, {\"link\": \"https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Faimonks%2Fe0d4fa78e33d&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&user=Prince+Krampah&userId=43f5ed8aa6e0&source=-----e0d4fa78e33d---------------------clap_footer-----------\", \"text\": \"\"}, {\"link\": \"https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Faimonks%2Fe0d4fa78e33d&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&user=Prince+Krampah&userId=43f5ed8aa6e0&source=-----e0d4fa78e33d---------------------clap_footer-----------\", \"text\": \"\"}, {\"link\": \"https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe0d4fa78e33d&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&source=--------------------------bookmark_footer-----------\", \"text\": \"\"}, {\"link\": \"https://medium.com/@princekrampah?source=post_page-----e0d4fa78e33d--------------------------------\", \"text\": \"\"}, {\"link\": \"https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb8af9fae2f0f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&newsletterV3=43f5ed8aa6e0&newsletterV3Id=b8af9fae2f0f&user=Prince+Krampah&userId=43f5ed8aa6e0&source=-----e0d4fa78e33d---------------------subscribe_user-----------\", \"text\": \"\"}, {\"link\": \"https://medium.com/@princekrampah?source=post_page-----e0d4fa78e33d--------------------------------\", \"text\": \"Written by Prince Krampah\"}, {\"link\": \"https://medium.com/@princekrampah/followers?source=post_page-----e0d4fa78e33d--------------------------------\", \"text\": \"362 Followers\"}, {\"link\": \"https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb8af9fae2f0f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faimonks%2Fchatgpt-clone-with-streamlit-and-langchain-e0d4fa78e33d&newsletterV3=43f5ed8aa6e0&newsletterV3Id=b8af9fae2f0f&user=Prince+Krampah&userId=43f5ed8aa6e0&source=-----e0d4fa78e33d---------------------subscribe_user-----------\", \"text\": \"\"}, {\"link\": \"https://medium.com/about?autoplay=1&source=post_page-----e0d4fa78e33d--------------------------------\", \"text\": \"About\"}, {\"link\": \"https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----e0d4fa78e33d--------------------------------\", \"text\": \"Careers\"}, {\"link\": \"https://medium.com/business?source=post_page-----e0d4fa78e33d--------------------------------\", \"text\": \"Teams\"}]"
}