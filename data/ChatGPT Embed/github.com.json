{
    "summary": "Skip to content\n\nToggle navigation\n\nSign in\n\n  * Product \n\n    * Actions\n\nAutomate any workflow\n\n    * Packages\n\nHost and manage packages\n\n    * Security\n\nFind and fix vulnerabilities\n\n    * Codespaces\n\nInstant dev environments\n\n    * Copilot\n\nWrite better code with AI\n\n    * Code review\n\nManage code changes\n\n    * Issues\n\nPlan and track work\n\n    * Discussions\n\nCollaborate outside of code\n\nExplore\n\n    * All features \n    * Documentation \n    * GitHub Skills \n    * Blog \n\n  * Solutions \n\nFor\n\n    * Enterprise \n    * Teams \n    * Startups \n    * Education \n\nBy Solution\n\n    * CI/CD & Automation \n    * DevOps \n    * DevSecOps \n\nResources\n\n    * Learning Pathways \n    * White papers, Ebooks, Webinars \n    * Customer Stories \n    * Partners \n\n  * Open Source \n\n    * GitHub Sponsors\n\nFund open source developers\n\n    * The ReadME Project\n\nGitHub community articles\n\nRepositories\n\n    * Topics \n    * Trending \n    * Collections \n\n  * Pricing\n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\nSearch syntax tips\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our documentation.\n\nCancel  Create saved search\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\n{{ message }}\n\nAppointat  / **Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding **\nPublic\n\n  * Notifications \n  * Fork 24\n  * Star  122\n\n  * \n\nA Chatbot of Data Science Expert- Chat with Document(s) using ChatGPT API and\nText Embedding\n\n### License\n\nMIT license\n\n122 stars  24 forks  Branches Tags Activity\n\nStar\n\nNotifications\n\n  * Code\n  * Issues 1\n  * Pull requests 0\n  * Actions\n  * Projects 0\n  * Security\n  * Insights\n\nAdditional navigation options\n\n  * Code \n  * Issues \n  * Pull requests \n  * Actions \n  * Projects \n  * Security \n  * Insights \n\n# Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n main\n\n **6** Branches\n\n**0** Tags\n\nGo to file\n\nCode\n\n## Folders and files\n\nName| Name|\n\nLast commit message\n\n|\n\nLast commit date  \n  \n---|---|---|---  \n  \n## Latest commit\n\nAppointat\n\nFix bug in login functionality\n\n81780ba \u00b7\n\n## History\n\n237 Commits  \n  \n###\n\nOpenAI Example using Chroma\n\n|\n\n###\n\nOpenAI Example using Chroma\n\n|\n\nProject normalization\n\n|  \n  \n###\n\nOpenAI Example using Qdrant\n\n|\n\n###\n\nOpenAI Example using Qdrant\n\n|\n\nAdd an instance about the usage of vectorDB Qdrant (#3)\n\n|  \n  \n###\n\nTraceTalk-with-multi-agent-v2.0\n\n|\n\n###\n\nTraceTalk-with-multi-agent-v2.0\n\n|\n\nFix bug in login functionality\n\n|  \n  \n###\n\nTraceTalk\n\n|\n\n###\n\nTraceTalk\n\n|\n\nFix bug in login functionality\n\n|  \n  \n###\n\nchatbot-ui @ d5da93d\n\n|\n\n###\n\nchatbot-ui @ d5da93d\n\n|\n\nModify the chatbot-ui\n\n|  \n  \n###\n\nchatbot\n\n|\n\n###\n\nchatbot\n\n|\n\nUpdate OpenAI_API_key.txt\n\n|  \n  \n###\n\n.gitignore\n\n|\n\n###\n\n.gitignore\n\n|\n\nUpdate gitignore\n\n|  \n  \n###\n\n.gitmodules\n\n|\n\n###\n\n.gitmodules\n\n|\n\nAdd submodule\n\n|  \n  \n###\n\nLICENSE\n\n|\n\n###\n\nLICENSE\n\n|\n\nInitial commit\n\n|  \n  \n###\n\nREADME.md\n\n|\n\n###\n\nREADME.md\n\n|\n\nUpdate\n\n|  \n  \nView all files  \n  \n## Repository files navigation\n\n  * README\n  * MIT license\n\n# Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\n\n## Main idea\n\nThe short answer is that they convert documents that are over 100 or even\n1,000 pages long into a numeric representation of data and related context (\n**vector embedding** ) and store them in a vector search engine. When a user\nchats with the document (i.e., asks questions), the system searches and\nreturns similar text to a question (i.e., chat) using an algorithm called\n**Approximate Nearest Neighbor search (ANN)**. It looks something like this.\n\nFig.1 **What is vector search?**\n\n  * Resources (images, documents, audio)\n  * vector representation\n  * Nearest neighbor\n  * Output/results\n\nThe program then includes the returned text that is similar to a question\n(i.e., chat) in a prompt and asks the same question again to the OpenAI GPT-3\nAPI. This returns a nice response that you are used to with ChatGPT. The\nbenefits of this approach are that the prompt is much smaller, not 1,000 pages\nof documents, and the user gets the answer they are looking for.\n\nOn a side note, if you are worried about something like ChatGPT providing\nincorrect answers to a question, then you can point it to your organization\u2019s\nknowledge base and provide answers from there. The accuracy of the answers\nwill be as good as your knowledge base.\n\n# Product introduction to _TraceTalk_ \ud83d\udcac\n\nStepping into the future of conversational AI, we are thrilled to introduce\nTraceTalk, a cutting-edge solution that blends state-of-the-art artificial\nintelligence with interactive learning. By reshaping the traditional approach\nto knowledge acquisition, we are making learning as dynamic, engaging, and\npersonable as conversing with a close friend. \ud83d\ude80\n\n**Roadmap of TraceTalk** :\n\n## The Novelty of TraceTalk \ud83d\udcda\n\nDitching the stereotype of conventional chatbots, TraceTalk is conceived as an\nAI-fueled conversational companion with a primary aim to facilitate learning\nin an exciting and immersive manner. Deriving insights from New Bing\u2019s\ninnovative interactive solutions, TraceTalk is engineered to be more than a\nmere provider of information. It morphs into your personal and interactive\nlearning assistant, designed to transform the way we learn and interact with\ninformation, which seamlessly **integrates relevant references by providing\ncorrect links, illustrations, video jump links, code blocks, and other\ncomponents**. This integration provides a rich, context-driven learning\nexperience that extends beyond the usual confines of traditional learning\nmechanisms.\n\nThe core of our AI taps into the prodigious **knowledge repository available**\non Ocademy, an open-source educational initiative. As a result, TraceTalk is\nempowered to pull data from an incessantly evolving and expanding base of\nknowledge, ensuring your interactions are always current, informative, and\nenriching.\n\n## A Comprehensive Technological Framework \ud83c\udfd7\ufe0f\n\nAt the heart of TraceTalk is an intricate and scalable architecture that is\nbuilt on the harmonious blending of modern technologies. Our product is\nfocused on leveraging the strengths of Large Language Models (LLMs), allowing\nus to cater to specific domain expertise and not stifling innovation. It\nepitomizes the potential of **cloud-centric** , **microservices-based** , and\n**data-driven** systems. It stores library-like knowledge in databases and\npresents it to the user when needed in an understandable and efficient way.\nThis advanced structure amplifies the product's flexibility, scalability, and\nhigh availability, assuring a smooth and uninterrupted user experience\nregardless of the volume of interactions.\n\nOur frontend is bolstered by the efficient **Next.js** framework which excels\nat server-side rendering. The backend, driven by Python, harnesses the\nlanguage's power to manage complex data processing tasks and administer\nsophisticated business logic. These components are interconnected via a\n**RESTful API** , facilitating communication with our high-performance\n**Qdrant database** hosted on the cloud. \u2601\ufe0f\n\n## A Technological Marvel \ud83e\udd16\n\nThe uniqueness of TraceTalk is deeply rooted in its technological\ninfrastructure. Powering this conversational AI marvel is OpenAI's **GPT-3.5\nTurbo API** , positioning it amongst the most sophisticated conversational AIs\ncurrently available. In addition, our engineering team has innovatively\nutilized Python's multithreading capabilities and queue systems to handle\nsubstantial traffic, thereby ensuring seamless interactions irrespective of\nthe scale.\n\nIn the realm of database management, TraceTalk leverages the substantial\nbenefits of cloud technology. By opting to train our models and store our data\non the cloud, we have geared TraceTalk to handle massive volumes of data and\ndeliver the optimal conversational experience.\n\n## The Dawn of Conversational Evolution \ud83d\udcac\n\nTraceTalk transcends the boundaries of a standard chatbot - it signifies the\ndawn of a new era in conversational interaction. As we continue to expand and\nevolve, we eagerly look forward to integrating more features and refining the\nuser experience. For now, we are proud to present an AI conversational\nassistant that is not just technologically advanced, but also committed to\ndelivering a smooth, intuitive, and engaging user experience. Welcome to the\nfuture of conversation, and welcome to TraceTalk! \ud83c\udf89\n\n## Our Vision: The Future of Learning \ud83c\udfaf\n\nAt TraceTalk, we firmly believe that the potential of AI and machine learning\nextends beyond technological advancement - it holds the power to revolutionize\nthe way we learn, interact, and communicate. Our vision is to harness this\nvast potential and shape a world where information is not just readily\naccessible but interactive, where learning transforms from a monotonous task\nto a fascinating conversation. We invite you to join us on this thrilling\njourney as we collectively shape the future of learning. Welcome aboard\nTraceTalk! \ud83c\udf1f\n\nIn addition, TraceTalk supports what we call 'selfish data.' Our database\ncurrently hosts over 400 documents in private domains \ud83d\udd10, and yet we're just\nscratching the surface of the model's capacity.\n\nWe also acknowledge that interactions may occasionally veer off-topic or\ninclude inappropriate content \ud83d\ude45. To manage such situations, we've built in\nmechanisms to filter out these interactions and guide the conversation back to\nits intended course.\n\nIn essence, TraceTalk is more than a chatbot\u2014it's the next step in interactive\nlearning. Our commitment to comprehensive implementation and meticulous\nproject management ensures not only accurate and relevant responses but a\nseamless, informative, and engaging user experience. Welcome to the future of\nconversation, and welcome to TraceTalk \ud83d\ude80.\n\nAn answer from _TraceTalk_ :\n\n# Installation Guide for _TraceTalk_\n\nThis guide will walk you through the steps necessary to install and run the\n\"Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\" application.\n\n## Prerequisites\n\n  * Git\n  * Python 3.8 or above\n  * Node.js v14 or above\n  * npm v6.14 or above\n\n## Installation Steps\n\n### 1\\. Clone the GitHub repository\n\nClone the repository from GitHub using the following command, remember to\ninclude the \"--recursive\" option to clone the submodules as well:\n\n    \n    \n    git clone --recursive https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding.git\n    \n\n### 2\\. Create a \".env\" file\n\nNavigate into the cloned repository and create a new file named \".env\". This\nfile will contain your configuration variables. At the moment, you need to\nfill in the following two:\n\n    \n    \n    OPENAI_API_KEY=<Your OpenAI API Key>\n    QDRANT_URL=<Qdrant URL>\n    QDRANT_API_KEY=<Qdrant API Key>\n    \n\nFor `QDRANT_URL` and `QDRANT_API_KEY`, you need to contact the project\nadministrator to obtain them.\n\n### 3\\. Install and run the backend\n\nNavigate to the `TraceTalk` directory :\n\n    \n    \n    cd TraceTalk\n    \n\nInstall the required Python packages:\n\n    \n    \n    pip install -r requirements.txt\n    \n\nStart the backend service:\n\n    \n    \n    python app.py\n    \n\n### 4\\. Install and run the frontend\n\nNavigate to the `chatbot-ui` directory:\n\n    \n    \n    cd chatbot-ui\n    \n\nInstall the required Node.js packages:\n\n    \n    \n    npm install\n    \n\nStart the frontend service:\n\n    \n    \n    npm run dev\n    \n\n### 5\\. Access the application\n\nFinally, open your web browser and navigate to `http://localhost:3000` .\n\nYou should now be able to see and interact with the \"Chat-with-Document-s-\nusing-ChatGPT-API-and-Text-Embedding\" application. Enjoy exploring!\n\n## Troubleshooting\n\nIf you run into any issues during the installation process, please feel free\nto contact the project administrator or raise an issue on the GitHub\nrepository.\n\n## Tutorial\n\n### Tools\n\nWe will be using three tools in this tutorial:\n\n  * OpenAI GPT-3, specifically the new ChatGPT API (gpt-3.5-turbo). Not because this model is any better than other models, but because it is cheaper ($0.002 / 1K tokens) and good enough for this use case.\n  * **Chroma**, the AI-native open-source embedding database (i.e., vector search engine). Chroma is an easy-to-use vector database when used in conjunction with LangChain; otherwise, it\u2019s kind of unusable. If you want to deploy these types of applications in production, I recommend using Elasticsearch because it has wide adoption and has been around for years. Not because Elasticsearch is better than competitors, but because not many organizations like to add a new technology stack*.*\n  * **LangChain**, is a library that aims to assist developers in building applications that use Large Language Models (LLMs) by allowing them to integrate these models with other sources of computation or knowledge.\n\n### Data\n\nWe will be using the data from Project Gutenberg\u2019s \u201cRomeo and Juliet by\nWilliam Shakespeare\u201d, which consists of 55,985 tokens. This makes it a nicely\nsized dataset.\n\n### Python code\n\n**Installation of packages:**\n\n    \n    \n    $ writefile requirements.txt\n    openai\n    chromadb\n    langchain\n    tiktoken\n    \n    \n    $ pip install -r requirements.txt\n\nNote: administrator privileges may be required to install these packages.\n\n**Import Python Packages**\n\n    \n    \n    import os\n    import platform\n    \n    import openai\n    import chromadb\n    import langchain\n    \n    from langchain.embeddings.openai import OpenAIEmbeddings\n    from langchain.vectorstores import Chroma\n    from langchain.text_splitter import TokenTextSplitter\n    from langchain.llms import OpenAI\n    from langchain.chains import ChatVectorDBChain\n    from langchain.document_loaders import GutenbergLoader\n    \n    print('Python: ', platform.python_version())\n\n**Mount Google Drive on Colab**\n\n    \n    \n    from google.colab import drive\n    drive.mount('/content/drive')\n\n**OpenAI API Key**\n\n    \n    \n    os.environ[\"OPENAI_API_KEY\"] = 'your openai api key'\n\n**Configure Chroma**\n\nChroma uses both of my favorite technologies for their backend \u2014 DuckDB and\nApache Parquet \u2014 but by default, it uses an **in-memory database**. This is\nfine for this tutorial, but I want to give you the option of storing the\ndatabase file on a disk so you can reuse the database without paying for\nembedding it every single time.\n\n    \n    \n    persist_directory=\"/content/drive/My Drive/Colab Notebooks/chroma/romeo\"\n\n**Convert Document to Embedding**\n\nConvert the document, i.e., the book, to vector embedding and store it in a\nvector search engine, i.e., a vector database.\n\n    \n    \n    def get_gutenberg(url):\n        loader = GutenbergLoader(url)\n        data = loader.load()\n        return data\n    \n    \n    romeoandjuliet_data = get_gutenberg('https://www.gutenberg.org/cache/epub/1513/pg1513.txt')\n    \n    text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=0)\n    romeoandjuliet_doc = text_splitter.split_documents(romeoandjuliet_data)\n    \n    embeddings = OpenAIEmbeddings()\n    vectordb = Chroma.from_documents(romeoandjuliet_doc, embeddings, persist_directory=persist_directory)\n    vectordb.persist()\n\n  * The first step is a bit self-explanatory, but it involves using  _\u2018from langchain.document_loaders import GutenbergLoader\u2019_  to load a book from Project Gutenberg.\n  * The second step is more involved. To obtain an embedding, we need to send the text string, i.e., the book, to OpenAI\u2019s embeddings API endpoint along with a choice of embedding model ID, e.g.,  _text-embedding-ada-002_. The response will contain an embedding. However, since the book consists of 55,985 tokens and the token limit for the  _text-embedding-ada-002_  model is 2,048 tokens, we use the  _\u2018text_splitter\u2019_  utility (from  _\u2018langchain.text_splitter import TokenTextSplitter\u2019_ ) to split the book into manageable 1,000-token chunks. The following is an illustration of a sample embedding response from OpenAI. If you\u2019re wondering, the pricing for the embedding model is $0.0004 / 1K tokens.\n  * The third step is pretty straightforward: we store the embedding in Chroma, our vector search engine, and persist it on a file system.\n\n**Configure LangChain QA**\n\nTo configure LangChain QA with Chroma, use the OpenAI GPT-3 model (\n_`model_name='gpt-3.5-turbo'`_ ) and ensure that the response includes the\nintermediary step of a result from a vector search engine, i.e., Chroma (set\n_`return_source_documents=True`_ ).\n\n    \n    \n    romeoandjuliet_qa = ChatVectorDBChain.from_llm(OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"), vectordb, return_source_documents=True)\n\n**Questions & Answers with \u201cRomeo and Juliet\u201d Book**\n\nGenerating questions and answers from the book is a straightforward process.\nTo assess the accuracy of the results, I will be comparing the answers with\nthose from SparkNotes.\n\n> _SparkNotes editors._ \u201cRomeo and Juliet\u201d SparkNotes.com, _SparkNotes LLC,\n> 2005_\n\n**I hope you have enjoyed this simple tutorial. If you have any questions or\ncomments, please provide them here.**\n\n# **Resources**\n\n  * ChatPDF\n  * ArvixGPT\n  * GPT for Sheets and Docs\n  * What is vector search?\n  * Chroma\n  * Elasticsearch\n  * LangChain\n  * Romeo and Juliet by William Shakespeare\n  * DuckDB\n  * Apache Parquet\n  * What are embeddings?\n  * Sparknotes\u2019 Romeo and Juliet: Questions & Answers\n\n# **Modules of LangChain**\n\nThere are several main modules that LangChain provides support for. For each\nmodule we provide some examples to get started, how-to guides, reference docs,\nand conceptual guides. These modules are, in increasing order of complexity:\n\n  * Models: LLMs, Chat models, Text embedding models\n  * Prompts: LLM prompts templates, Chat prompt templates, Example selectors, Output Parers\n  * Indexes: The primary index and retrieval types supported by LangChain are currently centered around vector databases, and therefore a lot of the functionality we dive deep on those topics.\n  * Memory: LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.\n  * Chains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\n  * Agents: Tools, Agents, Toolkits, Agent exucutor\n\n## About\n\nA Chatbot of Data Science Expert- Chat with Document(s) using ChatGPT API and\nText Embedding\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\n### Stars\n\n**122** stars\n\n### Watchers\n\n**3** watching\n\n### Forks\n\n**24** forks\n\nReport repository\n\n##  Releases\n\nNo releases published\n\n##  Packages 0\n\nNo packages published  \n\n## Languages\n\n  * Python 65.7%\n  * Jupyter Notebook 34.3%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\n### Footer navigation\n\n  * Terms\n  * Privacy\n  * Security\n  * Status\n  * Docs\n  * Contact\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n",
    "links": "[{\"link\": \"https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FAppointat%2FChat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\\n          Sign in\\n        \"}, {\"link\": \"https://github.com/features/actions\", \"text\": \"\"}, {\"link\": \"https://github.com/features/packages\", \"text\": \"\"}, {\"link\": \"https://github.com/features/security\", \"text\": \"\"}, {\"link\": \"https://github.com/features/codespaces\", \"text\": \"\"}, {\"link\": \"https://github.com/features/copilot\", \"text\": \"\"}, {\"link\": \"https://github.com/features/code-review\", \"text\": \"\"}, {\"link\": \"https://github.com/features/issues\", \"text\": \"\"}, {\"link\": \"https://github.com/features/discussions\", \"text\": \"\"}, {\"link\": \"https://github.com/features\", \"text\": \"\\n      All features\\n\\n    \\n\"}, {\"link\": \"https://github.com/enterprise\", \"text\": \"\\n      Enterprise\\n\\n    \\n\"}, {\"link\": \"https://github.com/team\", \"text\": \"\\n      Teams\\n\\n    \\n\"}, {\"link\": \"https://github.com/enterprise/startups\", \"text\": \"\\n      Startups\\n\\n    \\n\"}, {\"link\": \"https://github.com/solutions/ci-cd/\", \"text\": \"\\n      CI/CD & Automation\\n\\n    \\n\"}, {\"link\": \"https://github.com/customer-stories\", \"text\": \"\\n      Customer Stories\\n\\n    \\n\"}, {\"link\": \"https://github.com/sponsors\", \"text\": \"\"}, {\"link\": \"https://github.com/readme\", \"text\": \"\"}, {\"link\": \"https://github.com/topics\", \"text\": \"\\n      Topics\\n\\n    \\n\"}, {\"link\": \"https://github.com/trending\", \"text\": \"\\n      Trending\\n\\n    \\n\"}, {\"link\": \"https://github.com/collections\", \"text\": \"\\n      Collections\\n\\n    \\n\"}, {\"link\": \"https://github.com/pricing\", \"text\": \"Pricing\"}, {\"link\": \"https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FAppointat%2FChat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\\n              Sign in\\n            \"}, {\"link\": \"https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=Appointat%2FChat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\\n              Sign up\\n            \"}, {\"link\": \"https://github.com/Appointat\", \"text\": \"\\n        Appointat\\n\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\"}, {\"link\": \"https://github.com/login?return_to=%2FAppointat%2FChat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\"}, {\"link\": \"https://github.com/login?return_to=%2FAppointat%2FChat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\"}, {\"link\": \"https://github.com/login?return_to=%2FAppointat%2FChat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/blob/main/LICENSE\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/stargazers\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/forks\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/branches\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tags\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/activity\", \"text\": \"\"}, {\"link\": \"https://github.com/login?return_to=%2FAppointat%2FChat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\"}, {\"link\": \"https://github.com/login?return_to=%2FAppointat%2FChat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/issues\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/pulls\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/actions\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/projects\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/security\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/pulse\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/issues\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/pulls\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/actions\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/projects\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/security\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/pulse\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/branches\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tags\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/branches\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tags\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commits?author=Appointat\", \"text\": \"Appointat\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/81780ba34751ce3a9e9a4bee6fc97376283e5ae7\", \"text\": \"Fix bug in login functionality\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/81780ba34751ce3a9e9a4bee6fc97376283e5ae7\", \"text\": \"81780ba\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commits/main/\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commits/main/\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/OpenAI%20Example%20using%20Chroma\", \"text\": \"OpenAI Example using Chroma\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/OpenAI%20Example%20using%20Chroma\", \"text\": \"OpenAI Example using Chroma\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/5adf4166738a9f50502b626f41826ed29193f7f3\", \"text\": \" Project normalization\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/OpenAI%20Example%20using%20Qdrant\", \"text\": \"OpenAI Example using Qdrant\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/OpenAI%20Example%20using%20Qdrant\", \"text\": \"OpenAI Example using Qdrant\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/98e74662c70a9409d8ded3091ad09d36d8aea034\", \"text\": \"Add an instance about the usage of vectorDB Qdrant (\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/pull/3\", \"text\": \"#3\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/98e74662c70a9409d8ded3091ad09d36d8aea034\", \"text\": \")\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/TraceTalk-with-multi-agent-v2.0\", \"text\": \"TraceTalk-with-multi-agent-v2.0\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/TraceTalk-with-multi-agent-v2.0\", \"text\": \"TraceTalk-with-multi-agent-v2.0\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/81780ba34751ce3a9e9a4bee6fc97376283e5ae7\", \"text\": \"Fix bug in login functionality\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/TraceTalk\", \"text\": \"TraceTalk\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/TraceTalk\", \"text\": \"TraceTalk\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/cafe56d5961be72c2f3987fca2c12f2747500198\", \"text\": \"Fix bug in login functionality\"}, {\"link\": \"https://github.com/Appointat/chatbot-ui/tree/d5da93d10aed6efe068e7ca9bad15e92b5fa8053\", \"text\": \"chatbot-ui @ d5da93d\"}, {\"link\": \"https://github.com/Appointat/chatbot-ui/tree/d5da93d10aed6efe068e7ca9bad15e92b5fa8053\", \"text\": \"chatbot-ui @ d5da93d\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/9b80d50ab67a08d7f92763e478a6cffa4b068eb7\", \"text\": \"Modify the chatbot-ui\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/chatbot\", \"text\": \"chatbot\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/tree/main/chatbot\", \"text\": \"chatbot\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/c0eb369d93627c92f35ad86cbc1c87e2a49b4af5\", \"text\": \"Update OpenAI_API_key.txt\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/blob/main/.gitignore\", \"text\": \".gitignore\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/blob/main/.gitignore\", \"text\": \".gitignore\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/19892b6a4895907fe73a25c0229e5a760b8c0762\", \"text\": \"Update gitignore\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/blob/main/.gitmodules\", \"text\": \".gitmodules\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/blob/main/.gitmodules\", \"text\": \".gitmodules\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/1b7b6a9bda89c4262974787a7043c5e8f5f2fe82\", \"text\": \"Add submodule\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/blob/main/LICENSE\", \"text\": \"LICENSE\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/blob/main/LICENSE\", \"text\": \"LICENSE\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/1f9ad66f96bca323bb4f1e913c135a778f431efa\", \"text\": \"Initial commit\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/blob/main/README.md\", \"text\": \"README.md\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/blob/main/README.md\", \"text\": \"README.md\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/commit/0226afb72aadcf1f1cc27ee9ab66c6029b05d98c\", \"text\": \"Update\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/activity\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/stargazers\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/watchers\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/forks\", \"text\": \"\"}, {\"link\": \"https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FAppointat%2FChat-with-Document-s-using-ChatGPT-API-and-Text-Embedding&report=Appointat+%28user%29\", \"text\": \"\\n          Report repository\\n\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/releases\", \"text\": \"\\n    Releases\\n\"}, {\"link\": \"https://github.com/users/Appointat/packages?repo_name=Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/search?l=python\", \"text\": \"\"}, {\"link\": \"https://github.com/Appointat/Chat-with-Document-s-using-ChatGPT-API-and-Text-Embedding/search?l=jupyter-notebook\", \"text\": \"\"}, {\"link\": \"https://github.com/security\", \"text\": \"Security\"}]"
}