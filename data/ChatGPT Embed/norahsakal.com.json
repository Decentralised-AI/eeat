{
    "summary": "Norah Sakal\n\nNorah Sakal\n\nConsulting Services\n\nNew\n\nCourses Blog\n\n# How to use ChatGPT API to build a chatbot for product recommendations with\nembeddings\n\n**Are you looking to build a chatbot that can recommend products to your\ncustomers based on their unique profiles?**  \nHere's a step-by-step guide that shows you how to build a chatbot using\nembeddings to match a user's profile with relevant products from a company's\ndatabase.\n\nYou'll get the tools you need to create a customer-facing chatbot that can\nboost engagement and drive sales.\n\nIn this walkthrough, we'll use a beauty e-commerce company as an example, but\nthe principles can be applied to any industry.\n\n> **Need tailored AI solutions?**  \n>  I provide one-on-one collaboration and custom AI services for businesses.\n>\n> Let's find the perfect solution for your challenges: consulting services\n\n* * *\n\nHere's what we'll use:\n\n### 1\\. OpenAI API \ud83e\udd16\n\n### 2\\. Python \ud83d\udc0d\n\n* * *\n\nHere are the steps:\n\n### 1\\. Introduction to embeddings\n\n### 2\\. Get OpenAI API keys\n\n### 3\\. Create a product dataset\n\n### 4\\. Create embeddings for product dataset\n\n### 5\\. Create a customer profile dataset\n\n### 6\\. Create embeddings for customer profile dataset\n\n### 7\\. Create embeddings for customer chat message\n\n### 8\\. Get previous purchase data similarities\n\n### 9\\. Get product database similarities\n\n### 10\\. Create ChatGPT API prompt\n\n### 11\\. Create ChatGPT product recommendations\n\n* * *\n\n## 1\\. Introduction to embeddings\n\n**What are embeddings?**  \n\nIn natural language processing (NLP), an embedding represents words, phrases,\nor even entire documents as dense vectors of numerical values. These vectors\nare typically high-dimensional, with hundreds or even thousands of dimensions,\nand are designed to capture the semantic and syntactic relationships between\ndifferent pieces of text data.\n\nEmbeddings are often created using neural networks trained on large amounts of\ntext data. During training, the neural network learns to map each word to a\ndense vector so that words with similar meanings or are used in similar\ncontexts are mapped to similar vectors.\n\nFor example, the words **\"car\"** and **\"vehicle\"** might be mapped to vectors\nthat are very close together, while the word **\"banana\"** might be mapped to a\nvector that is further away.\n\nIn our case, we generate embeddings for each **user profile** and each\n**product** in the database, which we will then use to calculate their\n**similarity** and find the best product matches for each user.\n\n  \n**OpenAI endpoints for embeddings**  \n\nThe OpenAI API has two different endpoints for working with embeddings:\n\n\u2013 search  \n\u2013 similarity\n\nThe choice of which endpoint to use depends on your use case and the task\nyou're trying to accomplish.\n\nUse the `search` endpoint if you're trying to find documents or snippets that\nare similar to your input text. This endpoint returns a list of search\nresults, where each result includes the following:\n\n\u2013 document id  \n\u2013 score  \n\u2013 text of the matched document  \n\nThe score measures the similarity between your input text and the matched\ndocument. A higher score means greater similarity.\n\nThe other endpoint for embeddings is `similarity`. Use this endpoint when\nyou're trying to measure the similarity between two snippets of text or\ndocuments. This endpoint returns a single score between 0 and 1, which\nindicates the similarity between the two input texts.\n\nA score of 0 indicates that the texts are completely dissimilar, while 1 means\nthat the texts are identical.\n\nIn summary, use the `search` endpoint when you want to find similar documents\nto a given input text, and use the `similarity` endpoint when you want to\nmeasure the similarity between two snippets of text or document.\n\nFor this guide, I'll go with `similarity` since we're looking for products\nthat would fit a customer based on their customer profile.\n\nNow that we know the difference between the endpoints, let's get our OpenAI\nAPI keys.\n\n* * *\n\n## 2\\. Get OpenAI API keys\n\nBefore we go ahead and start coding, let's get the OpenAI credentials needed\nfor the API calls.\n\nGo to https://beta.openai.com/, log in and click on your avatar and **View API\nkeys** :\n\nThen create a **new secret key** and save it for the request:\n\nNow we have all the credentials needed to make an API request.\n\n* * *\n\n## 3\\. Create a product dataset\n\nThe next step is to create a product dataset. Start by importing **openai** ,\n**pandas** , and **openai embeddings**. We'll be using Pandas when we're\nworking with the data in DataFrames:\n\n    \n    \n    import openai\n    from openai.embeddings_utils import get_embedding, cosine_similarity\n    import pandas as pd\n\nThen go ahead and add your API key and then initialize the OpenAI API using\nyour API key. This will allow you to authenticate and access the OpenAI API\nusing the API key we got in the previous step:\n\n    \n    \n    api_key =\"YOUR_API_KEY\"\n    openai.api_key = api_key\n\nHere's the made-up data I'm using:\n\n    \n    \n    product_data = [{\n        \"prod_id\": 1,\n        \"prod\": \"moisturizer\",\n        \"brand\":\"Aveeno\",\n        \"description\": \"for dry skin\"\n    },\n    {\n        \"prod_id\": 2,\n        \"prod\": \"foundation\",\n        \"brand\":\"Maybelline\",\n        \"description\": \"medium coverage\"\n    },\n    {\n        \"prod_id\": 3,\n        \"prod\": \"moisturizer\",\n        \"brand\":\"CeraVe\",\n        \"description\": \"for dry skin\"\n    },\n    {\n        \"prod_id\": 4,\n        \"prod\": \"nail polish\",\n        \"brand\":\"OPI\",\n        \"description\": \"raspberry red\"\n    },\n    {\n        \"prod_id\": 5,\n        \"prod\": \"concealer\",\n        \"brand\":\"Chanel\",\n        \"description\": \"medium coverage\"\n    },\n    {\n        \"prod_id\": 6,\n        \"prod\": \"moisturizer\",\n        \"brand\":\"Ole Henkrisen\",\n        \"description\": \"for oily skin\"\n    },\n    {\n        \"prod_id\": 7,\n        \"prod\": \"moisturizer\",\n        \"brand\":\"CeraVe\",\n        \"description\": \"for normal to dry skin\"\n    },\n    {\n        \"prod_id\": 8,\n        \"prod\": \"moisturizer\",\n        \"brand\":\"First Aid Beauty\",\n        \"description\": \"for dry skin\"\n    },{\n        \"prod_id\": 9,\n        \"prod\": \"makeup sponge\",\n        \"brand\":\"Sephora\",\n        \"description\": \"super-soft, exclusive, latex-free foam\"\n    }]\n\nThe brands are real, but the data is all made-up.\n\nLet's add this product data to a **Pandas DataFrame** :\n\n    \n    \n    product_data_df = pd.DataFrame(product_data)\n    product_data_df\n\nThe product DataFrame should look something like this:\n\nLet's also create a new column called **combined** for the embeddings later,\nconcatenate the **brand** , **product** , and **description** into the new\ncolumn **combined** :\n\n    \n    \n    product_data_df['combined'] = product_data_df.apply(lambda row: f\"{row['brand']}, {row['prod']}, {row['description']}\", axis=1)\n    product_data_df\n\nThe `product data DataFrame` should now have a new column with the combined\ndata:\n\nWe have the product data ready, let's create embeddings for the new column in\nthe next section.\n\n* * *\n\n## 4\\. Create embeddings for the product dataset\n\nThe next step is to create embeddings for the **combined** column we just\ncreated. We'll use `get_embedding` from OpenAI:\n\n> **get_embedding** is a text embedding service provided by OpenAI that\n> generates high-quality vector representations of input text.\n>\n> The embeddings are generated using a neural network trained on a large\n> corpus of text data and are designed to capture the semantic meaning of the\n> input text.\n\nIn our case, we will use `get_embedding` to generate embeddings for each user\nprofile and each product in the database. Which we'll then use to calculate\ntheir similarity and find the best product matches as suggestions for the\nuser.\n\nThis will allow us to represent the product data in the database as **vectors\nin a high-dimensional space** , making it easier to calculate their similarity\nwith the user input in the chat later and find the best matches:\n\n    \n    \n    product_data_df['text_embedding'] = product_data_df.combined.apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n    product_data_df\n\n> We'll be using the embedding model **text-embedding-ada-002** , which is\n> OpenAI's second-generation embedding model: https://openai.com/blog/new-and-\n> improved-embedding-model\n\n> \u26a0\ufe0f This step can take several minutes depending on the data amount\n\nThis step can take several minutes depending on the data amount, once\nfinished, you'll have a new column with the **numerical representation** of\nthe **combined** column:\n\nThe product data embeddings are all set, let's start with the customer user\ndata in the next section.\n\n* * *\n\n## 5\\. Create a customer profile dataset\n\nNow that we have the product data embeddings let's create the customer profile\ndata.\n\nIdeally, this dataset would be past orders or products the customer has\npreviously shown interest in. Or any other customer-specific data you have\navailable.\n\nFor this guide, we'll create a made-up order history for a customer. Start by\ncreating a list of the 5 latest beauty products the customer purchased:\n\n    \n    \n    customer_order_data = [\n    {\n        \"prod_id\": 1,\n        \"prod\": \"moisturizer\",\n        \"brand\":\"Aveeno\",\n        \"description\": \"for dry skin\"\n    },{\n        \"prod_id\": 2,\n        \"prod\": \"foundation\",\n        \"brand\":\"Maybelline\",\n        \"description\": \"medium coverage\"\n    },{\n        \"prod_id\": 4,\n        \"prod\": \"nail polish\",\n        \"brand\":\"OPI\",\n        \"description\": \"raspberry red\"\n    },{\n        \"prod_id\": 5,\n        \"prod\": \"concealer\",\n        \"brand\":\"Chanel\",\n        \"description\": \"medium coverage\"\n    },{\n        \"prod_id\": 9,\n        \"prod\": \"makeup sponge\",\n        \"brand\":\"Sephora\",\n        \"description\": \"super-soft, exclusive, latex-free foam\"\n    }]\n\nThen add this customer order data to a Pandas DataFrame:\n\n    \n    \n    customer_order_df = pd.DataFrame(customer_order_data)\n    customer_order_df\n\nYou should now have this DataFrame:\n\nNext, let's create a new column for **combined** purchased product data, just\nlike we did for the product DataFrame:\n\n    \n    \n    customer_order_df['combined'] = customer_order_df.apply(lambda row: f\"{row['brand']}, {row['prod']}, {row['description']}\", axis=1)\n    customer_order_df\n\nYour DataFrame with previous purchases data should now look like this:\n\nLet's head over to the next section, where we'll create embeddings for the\ncustomer profile data.\n\n* * *\n\n## 6\\. Create embeddings for customer profile dataset\n\nLet's also create embedding for the previous purchases the customer has made.\nWe'll use `get_embedding` the same way as before:\n\n    \n    \n    customer_order_df['text_embedding'] = customer_order_df.combined.apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n    customer_order_df\n\nYour DataFrame should now have a column for the text embeddings of column\n**Combined** :\n\nWe have one last text that needs embeddings; the customer input chat message.\nLet's do that in the next section.\n\n* * *\n\n## 7\\. Create embeddings for customer chat message\n\nWe have all the data prepared and ready to work with a user question input.\n\nLet's pretend that the customer starts a conversation with your chatbot and\nasks, **\"Hi! Can you recommend a good moisturizer for me?\"**\n\nStart by adding the message as a new `customer_input`:\n\n    \n    \n    customer_input = \"Hi! Can you recommend a good moisturizer for me?\"\n\nWe need to create embeddings for the customer input just like we did for the\nproduct data.\n\nUse `openai.Embedding.create` and make sure to use the same model as for the\nproducts:\n\n    \n    \n    response = openai.Embedding.create(\n        input=customer_input,\n        model=\"text-embedding-ada-002\"\n    )\n    embeddings_customer_question = response['data'][0]['embedding']\n\nYou now have a numerical representation of the user input, and we can go ahead\nand find product recommendations for the customer in the next step.\n\n* * *\n\n## 8\\. Get previous purchase data similarities\n\nIn this next step, we'll compare the user chat input embeddings with the\nprevious product purchases database embeddings we created earlier.\n\nWe'll use the endpoint `search` since we want to find similarities between the\nuser input question: `Hi! Can you recommend a good moisturizer for me?` with\nall their previous purchases.\n\nCreate a new column in the previous purchase product data DataFrame for the\nsearch score and call `cosine_similarity` for each embedding.\n\nNext, sort the DataFrame in descending order based on the highest score.\n\n    \n    \n    customer_order_df['search_purchase_history'] = customer_order_df.text_embedding.apply(lambda x: cosine_similarity(x, embeddings_customer_question))\n    customer_order_df = customer_order_df.sort_values('search_purchase_history', ascending=False)\n    customer_order_df\n\nThe previous purchases DataFrame will now have a new column\n**search_purchase_history** which is the **similarity score** between the user\nquestion `Hi! Can you recommend a good moisturizer for me?` and each of the\npreviously purchased products:\n\nWe can see that the highest score, indicating high similarity, is between the\nuser input question and the **Aveeno moisturizer**.\n\nGreat, we have the similarity scores for the previously purchased products.\nLet's make the same comparison but for all the products in our database in the\nnext section.\n\n* * *\n\n## 9\\. Get product database similarities\n\nLet's make the same comparison between the user input question and all the\nproducts in our product database, and sort the results in descending order\nbased on the highest score:\n\n    \n    \n    product_data_df['search_products'] = product_data_df.text_embedding.apply(lambda x: cosine_similarity(x, embeddings_customer_question))\n    product_data_df = product_data_df.sort_values('search_products', ascending=False)\n    product_data_df\n\nYour products DataFrame should now have a new column `search_products`, which\nis the similarity score between the user input question and each product in\nyour database:\n\nThe highest similarity scores are for the moisturizers from **CeraVe** and\n**Aveeno**. The Aveeno moisturizer happens to be one of the products the\ncustomer also previously bought.\n\nBefore constructing the ChatGPT API prompt in the next step, let's create two\nnew DataFrames with only the top 3 similarity scores.\n\nOne new DataFrame for the previously bought products with the highest\nsimilarity scores:\n\n    \n    \n    top_3_purchases_df = customer_order_df.head(3)\n    top_3_purchases_df\n\nLet's also create a new DataFrame for the top 3 similarity scores of all the\nproducts on our database:\n\n    \n    \n    top_3_products_df = product_data_df.head(3)\n    top_3_products_df\n\n* * *\n\n## 10\\. Create ChatGPT API prompt\n\nThe next step is to create the message objects needed as input for the ChatGPT\ncompletion function.\n\nThe ChatGPT prompts in this guide are just suggestions. You can construct the\nprompt in any way you want, as long as you follow the temple and have a dict\nwith a **role** and **message content**.\n\n> **From the Chat completion documentation:**\n>\n> \"The main input is the messages parameter. Messages must be an array of\n> message objects, where each object has a role (either \u201csystem\u201d, \u201cuser\u201d, or\n> \u201cassistant\u201d) and content (the content of the message). Conversations can be\n> as short as 1 message or fill many pages.\"\n> https://platform.openai.com/docs/guides/chat/introduction\n\nStart with an empty list:\n\n    \n    \n    message_objects = []\n\nThen append the first message, which is the system message. The system message\nhelps set the behavior of the assistant:\n\n    \n    \n    message_objects.append({\"role\":\"system\", \"content\":\"You're a chatbot helping customers with beauty-related questions and helping them with product recommendations\"})\n\nHere's an important note in the OpenAI API docs:\n\n> From OpenAI API docs:\n> https://platform.openai.com/docs/guides/chat/introduction\n>\n> \"gpt-3.5-turbo-0301 does not always pay strong attention to system messages.\n> Future models will be trained to pay stronger attention to system messages.\"\n\nAfter appending the system message, let's add the input message from the\ncustomer:\n\n    \n    \n    message_objects.append({\"role\":\"user\", \"content\": customer_input})\n\nThen, let's go ahead and create a string of the previous purchases from our\ntop 3 purchases DataFrame:\n\n    \n    \n    prev_purchases = \". \".join([f\"{row['combined']}\" for index, row in top_3_purchases_df.iterrows()])\n    prev_purchases\n\nAdd those purchases to a **user message** and append it to the array of\nmessage objects:\n\n    \n    \n    message_objects.append({\"role\":\"user\", \"content\": f\"Here're my latest product orders: {prev_purchases}\"})\n\nLet's also add some additional instructions to help set the assistant's\nbehavior.\n\nI'm using these instructions to get a friendly reply from the model:\n\n    \n    \n    message_objects.append({\"role\":\"user\", \"content\": f\"Please give me a detailed explanation of your recommendations\"})\n    message_objects.append({\"role\":\"user\", \"content\": \"Please be friendly and talk to me like a person, don't just give me a list of recommendations\"})\n\n> Tip \ud83d\udca1\n>\n> Tinker with the instructions in the prompt until you find the desired voice\n> of your chatbot.\n\nAfter this set of user instructions, I'm adding this **assistant content** to\nhelp give the model an example of desired behavior:\n\n    \n    \n    message_objects.append({\"role\": \"assistant\", \"content\": f\"I found these 3 products I would recommend\"})\n\nI'll also go ahead and create a list of the top 3 products we have in our\nproduct DataFrame:\n\n    \n    \n    products_list = []\n    \n    for index, row in top_3_products_df.iterrows():\n        brand_dict = {'role': \"assistant\", \"content\": f\"{row['combined']}\"}\n        products_list.append(brand_dict)\n    products_list\n\nAnd then add those to our list of message objects with `extend`:\n\n    \n    \n    message_objects.extend(products_list)\n\nFinally, I'll end the prompt with a last instruction:\n\n    \n    \n    message_objects.append({\"role\": \"assistant\", \"content\":\"Here's my summarized recommendation of products, and why it would suit you:\"})\n\nHere's what the list of **message objects** looks like:\n\nWe have the final prompt. Let's call the ChatGPT API in the next step and see\nwhat message our customer will receive.\n\n* * *\n\n## 11\\. Create ChatGPT product recommendations\n\nThe final step is to call the `openai.ChatCompletion.create` function with our\nfinalized list of message objects:\n\n    \n    \n    completion = openai.ChatCompletion.create(\n      model=\"gpt-3.5-turbo\",\n      messages=message_objects\n    )\n    \n    print(completion.choices[0].message['content'])\n\nThe model's reply can be extracted with\n`response['choices'][0]['message']['content']` and should look something like\nthis:\n\nThis will give us the AI-generated response to our customer input question\nbased on the previous beauty product purchase history and the product database\nwe provided.\n\nWe're all set; this is how easy it is to leverage the power of ChatGPT to\ncreate conversational AI applications.\n\nWith just a few lines of code, we can build a simple chatbot service that can\nunderstand natural language and provide product recommendations from user\nquestions.\n\n* * *\n\n## Here's a summary of what we did\n\n### 1\\. Introduction to embeddings\n\n### 2\\. Obtained OpenAI API keys\n\n### 3\\. Created a product dataset\n\n### 4\\. Created embeddings for the product dataset using get_embedding\n\n### 5\\. Created a customer profile dataset\n\n### 6\\. Created embeddings for the customer profile dataset using\nget_embedding\n\n### 7\\. Created embeddings for the customer chat message using get_embedding\n\n### 8\\. Calculated similarities between the customer's previous purchases and\nthe customer's chat input question using cosine similarity\n\n### 9\\. Calculated similarities between the customer's chat input question and\nthe products in the database using cosine similarity\n\n### 10\\. Created a ChatGPT API prompt to initiate the chatbot conversation\n\n### 11\\. Generated product recommendations using the ChatGPT API\n\n* * *\n\n## Improvements\n\nWhile this guide provides a solid foundation for building a chatbot that\nrecommends products based on a user's profile and available product data,\nseveral areas can be improved for more accurate and relevant recommendations.  \n  \n\n**Product data**  \nIn this guide, we used minimal data set with basic product and customer\ninformation, so the generated product information in the ChatGPT API response\nis made-up. It's recommended to use an extensive dataset with detailed product\ninformation.  \n  \n\n**Increase the number of previously purchased products**  \nThis walkthrough only uses the top three previously purchased products to make\nrecommendations. To broaden the scope of product suggestions, it would be\nbeneficial to use a larger set of previously purchased products.  \n  \n\n**Extract the product type from the user input**  \nExtracting the product type from the user input question can help the model\nmake more accurate recommendations by including the relevant product types in\nthe suggestions.\n\n* * *\n\n## Troubleshooting\n\n### attributeError: module 'openai' has no attribute 'ChatCompletion'\n\nThis probably means that the version of your **Python client library for the\nOpenAI API** is lower than `0.27.0`.\n\nRun `pip install openai --upgrade` in your terminal for the latest version and\nmake sure it is at least `0.27.0`:\n\n* * *\n\n### InvalidRequestError: This model's maximum context length is 4096 tokens\n\nThis indicates that the input `message_object` sent to the ChatGPT API has\nexceeded the maximum allowed length of 4096 tokens.\n\nYou will need to shorten the length of your messages to resolve the issue:\n\n* * *\n\n## Next steps\n\n**1\\. Repo with source code**  \nHere is the repo with a Jupyter notebook with all the source code if you'd\nlike to implement this on your own \u2b07\ufe0f  \nhttps://github.com/norahsakal/chatgpt-product-recommendation-embeddings\n\n**2\\. Do you need help with getting started with the ChatGPT API? Or do you\nhave other questions?**  \nI'm happy to help, don't hesitate to reach out \u27a1\ufe0f norah@quoter.se\n\nOr shoot me a DM on Twitter @norahsakal  \n  \n\n###### **Need tailored AI solutions?**\n\nI provide one-on-one collaboration and custom AI services for businesses.\n\nLet's find the perfect solution for your challenges: Consulting Services\n\n* * *\n\n###### Get notified about new posts\n\nEmail\n\nEmail\n\nSubscribe\n\n###### Connect with me\n\n###### Need a custom solution for your business or idea?\n\n###### Get a tailored blog post on ChatGPT, GPT-3 and GPT-4 to tackle your\nspecific problem.\n\nGet custom blog post\n\nCopyright \u00a9 Norah Sakal 2024\n\n  * Consulting Services \n\nNew\n\n  * Courses \n  * Blog \n\n",
    "links": "[{\"link\": \"https://norahsakal.com/\", \"text\": \"\"}, {\"link\": \"https://norahsakal.com/\", \"text\": \"\"}, {\"link\": \"https://norahsakal.com/\", \"text\": \"\"}, {\"link\": \"https://norahsakal.com/consulting\", \"text\": \"\"}, {\"link\": \"https://norahsakal.com/courses\", \"text\": \"\"}, {\"link\": \"https://norahsakal.com/blog\", \"text\": \"\"}, {\"link\": \"https://norahsakal.com/consulting\", \"text\": \"Consulting Services\"}, {\"link\": \"https://norahsakal.com/consulting\", \"text\": \"\"}, {\"link\": \"https://norahsakal.com/courses\", \"text\": \"\"}, {\"link\": \"https://norahsakal.com/blog\", \"text\": \"\"}]"
}