{
    "summary": "GPU Al/ML today! NVIDIA A100s & H100s for \u20ac 2.06/h\n\nTools\n\n  * Looking Glass\n  * Speed Test\n  * Developer Tools\n  * Status Page\n\nContent Hub\n\n  * Blog\n  * Learning\n  * News\n  * Case studies\n  * Downloads\n  * Press & Media\n  * Product Roadmap\n  * API Documentation\n  * Product Documentation\n  * Help Center\n\nUnder attack?Report abuseTalk to an expert EN  DE  ZH\n\nEN  DE  ZH\n\nProducts \u2192\n\nSolutions \u2192\n\nPricing \u2192\n\nPartnership \u2192\n\nCompany \u2192\n\nContent Hub \u2192\n\nTools \u2192\n\nTalk to an expert\n\nReport abuse\n\nUnder attack?\n\nSign in  Get started for free\n\n#  GPU-Powered Dedicated Servers\n\nServers that use powerful graphics cards for processing.\n\nChoose a server Test the connectivity\n\n##  GPU-Powered Servers Massively Speed Up Any Calculation\n\n#### Machine Learning\n\nTrain neural networks faster.\n\n#### Cloud Rendering\n\nSpeed up video processing, 3D modeling, and the development of graphics and\ndesign.\n\n#### Process Modelling\n\nCalculate models of physical processes, weather, and atmospheric events.\n\n#### Financial Analytics\n\nAnalyze financial risks and perform complex calculations.\n\n##  Dedicated servers\n\nEUR\n\nUSD\n\nShow more filters+\n\nReset filter settings\n\nData center |  CPU |  RAM |  Disk |  RAID |  GPU |  Price  \n---|---|---|---|---|---|---  \n  \nAll data centers\n\n\u2190\n\nAll data centers\n\n  * US\n  * Miami \n  * Santa Clara \n  * Ashburn, DC 2 \n  * Chicago \n\n  * South America\n  * S\u00e3o Paulo \n\n  * Europe\n  * Frankfurt \n  * Kyiv \n  * London \n  * Luxembourg \n  * Madrid \n  * Milan \n  * Amsterdam, DC 2 \n  * Warsaw \n\n  * Asia\n  * Seoul \n  * Singapore \n  * Mumbai \n  * Hong Kong \n  * Tokyo \n\n  * Australia\n  * Melbourne \n  * Sydney \n\n  * MENA\n  * Istanbul \n  * Tel Aviv \n\n  * Africa\n  * Johannesburg \n\n\u2190\n\nAll data centers\n\n  * US\n  * Miami \n  * Santa Clara \n  * Ashburn, DC 2 \n  * Chicago \n\n  * South America\n  * S\u00e3o Paulo \n\n  * Europe\n  * Frankfurt \n  * Kyiv \n  * London \n  * Luxembourg \n  * Madrid \n  * Milan \n  * Amsterdam, DC 2 \n  * Warsaw \n\n  * Asia\n  * Seoul \n  * Singapore \n  * Mumbai \n  * Hong Kong \n  * Tokyo \n\n  * Australia\n  * Melbourne \n  * Sydney \n\n  * MENA\n  * Istanbul \n  * Tel Aviv \n\n  * Africa\n  * Johannesburg \n\n|\n\n2xE5-2630v4\n\n2xE5-2660\n\n2xE5-2670\n\n2xE5-2690v4\n\n2xGold-6128\n\n2xGold-6132\n\n2xGold-6226R\n\n2xGold-6348\n\n|\n\n16Gb\n\n32Gb\n\n64Gb\n\n96Gb\n\n128Gb\n\n192Gb\n\n256Gb\n\n384Gb\n\n|\n\n2x1000SSD\n\n2x1200SAS\n\n2x2000SATA\n\n2x2000SSD\n\n2x2000SSD + 2x4000SATA\n\n2x240SSD\n\n2x4000SATA\n\n2x4000SSD + 2x8000SATA\n\n|\n\nHardware\n\nSoftware\n\n|\n\nGPU\n\n|\n\nOut of range\n\nOut of range\n\n93\n\n1482\n\n89\n\n1482  \n  \nScroll horizontally to view the configurator\n\n1 month\n\n  * 1 month \n  * 3 months \n  * 6 months \n  * 12 months \n\n\u20ac 249 x1 mo\n\n*without VAT\n\nTel Aviv\n\n  * CPU\n\nE-2288G\n\n  * RAM\n\n64Gb\n\n  * GPU\n\n\u2013\n\n  * Disk\n\n2x480SSD\n\n  * RAID\n\nHardware\n\n  * Bandwidth \n\n1 Gbps\n\n  * Included traffic\n\n5 TB\n\nBuy\n\n1 month\n\n  * 1 month \n  * 3 months \n  * 6 months \n  * 12 months \n\n\u20ac 206 x1 mo\n\n*without VAT\n\nTel Aviv\n\n  * CPU\n\nE-2236\n\n  * RAM\n\n64Gb\n\n  * GPU\n\n\u2013\n\n  * Disk\n\n2x480SSD\n\n  * RAID\n\nHardware\n\n  * Bandwidth \n\n1 Gbps\n\n  * Included traffic\n\n5 TB\n\nBuy\n\n1 month\n\n  * 1 month \n  * 3 months \n  * 6 months \n  * 12 months \n\n\u20ac 175 x1 mo\n\n*without VAT\n\nTel Aviv\n\n  * CPU\n\nE-2236\n\n  * RAM\n\n32Gb\n\n  * GPU\n\n\u2013\n\n  * Disk\n\n2x480SSD\n\n  * RAID\n\nHardware\n\n  * Bandwidth \n\n1 Gbps\n\n  * Included traffic\n\n5 TB\n\nBuy\n\nShow more dedicated servers\n\n##  Use our GPU-Powered dedicated servers if your projects require maximum\nperformance\n\nSend a request with your needs and we will select the proper server for your\ntasks\n\nTalk to an expert\n\nWe provide powerful solutions that will help your business grow globally. Try\nour superior performance for free.\n\nConvenient cloud services with low latency around the world proven by the\nlargest online businesses.\n\n####  Products\n\nCDNDNSHostingStreaming PlatformStorageDDoS ProtectionCloudIT Infrastructure\nManagement\n\n####  Company\n\nAboutAffiliate ProgramReferral ProgramCase\nStudiesCareersBlogLearningPressLegal Information#SupportUkraine\n\n####  Resources\n\nStatus PageAPI DocumentationProduct DocumentationLooking GlassDeveloper\nToolsProducts RoadmapHelp Center\n\n#### Contact\n\nsupport@gcore.cominfo@gcore.comReport abuse\n\n####  Sales\n\n\\+ 352 208 80 507sales@gcore.com\n\n#### Follow us on social media\n\n#### Subscribe and discover the latest updates, news, and features\n\nWe value your inbox and are committed to preventing spam\n\nEmail*\n\nInsert your email address\n\nUTM Campaign\n\nUTM Content\n\nUTM Medium\n\nUTM Source\n\nUTM Term\n\nGA Client id\n\nBy clicking the button you give us an informed, specific and unambiguous\nconsent to process your personal data in accordance with our Privacy policy\n\nThis site is protected by reCAPTCHA and the Google Privacy Policy and Terms of\nService apply.\n\nG-Core Labs S.A. \u00a9 2015\u20132023 All rights reserved. Principal place of business\nand postal address: 2-4, Rue Edmond Reuter, L-5326 Contern, Luxembourg\n\n",
    "links": "[{\"link\": \"https://gcore.com/cloud/ai-gpu\", \"text\": \"\"}, {\"link\": \"https://gcore.com/\", \"text\": \"\"}, {\"link\": \"https://gcore.com/dev-tools\", \"text\": \"Developer Tools\"}, {\"link\": \"https://gcore.com/\", \"text\": \"\"}, {\"link\": \"https://gcore.com/blog/\", \"text\": \"Blog\"}, {\"link\": \"https://gcore.com/learning/\", \"text\": \"Learning\"}, {\"link\": \"https://gcore.com/news/\", \"text\": \"News\"}, {\"link\": \"https://gcore.com/case-studies/\", \"text\": \"Case studies\"}, {\"link\": \"https://gcore.com/library\", \"text\": \"Downloads\"}, {\"link\": \"https://gcore.com/press\", \"text\": \"Press & Media\"}, {\"link\": \"https://gcore.com/docs\", \"text\": \"Product Documentation\"}, {\"link\": \"https://gcore.com/emergency-ddos-protection\", \"text\": \"Under attack?\"}, {\"link\": \"https://gcore.com/report-abuse\", \"text\": \"Report abuse\"}, {\"link\": \"https://gcore.com/contact-us\", \"text\": \"Talk to an expert\"}, {\"link\": \"https://gcore.com/\", \"text\": \"\"}, {\"link\": \"https://gcore.com/pricing\", \"text\": \"\"}, {\"link\": \"https://gcore.com/contact-us\", \"text\": \"Talk to an expert\"}, {\"link\": \"https://gcore.com/report-abuse\", \"text\": \"Report abuse\"}, {\"link\": \"https://gcore.com/emergency-ddos-protection\", \"text\": \"Under attack?\"}, {\"link\": \"https://gcore.com/contact-us\", \"text\": \"Talk to an expert\"}, {\"link\": \"https://gcore.com/cdn\", \"text\": \"CDN\"}, {\"link\": \"https://gcore.com/dns\", \"text\": \"DNS\"}, {\"link\": \"https://gcore.com/hosting\", \"text\": \"Hosting\"}, {\"link\": \"https://gcore.com/streaming-platform\", \"text\": \"Streaming Platform\"}, {\"link\": \"https://gcore.com/storage\", \"text\": \"Storage\"}, {\"link\": \"https://gcore.com/ddos-protection\", \"text\": \"DDoS Protection\"}, {\"link\": \"https://gcore.com/cloud\", \"text\": \"Cloud\"}, {\"link\": \"https://gcore.com/it-infrastructure-management\", \"text\": \"IT Infrastructure Management\"}, {\"link\": \"https://gcore.com/about\", \"text\": \"About\"}, {\"link\": \"https://gcore.com/affiliate-program\", \"text\": \"Affiliate Program\"}, {\"link\": \"https://gcore.com/referral-program\", \"text\": \"Referral Program\"}, {\"link\": \"https://gcore.com/case-studies/\", \"text\": \"Case Studies\"}, {\"link\": \"https://gcore.com/careers\", \"text\": \"Careers\"}, {\"link\": \"https://gcore.com/blog/\", \"text\": \"Blog\"}, {\"link\": \"https://gcore.com/learning/\", \"text\": \"Learning\"}, {\"link\": \"https://gcore.com/press\", \"text\": \"Press\"}, {\"link\": \"https://gcore.com/legal\", \"text\": \"Legal Information\"}, {\"link\": \"https://gcore.com/business-support-for-ukraine\", \"text\": \"#SupportUkraine\"}, {\"link\": \"https://gcore.com/docs\", \"text\": \"Product Documentation\"}, {\"link\": \"https://gcore.com/dev-tools\", \"text\": \"Developer Tools\"}, {\"link\": \"https://gcore.com/report-abuse\", \"text\": \"Report abuse\"}, {\"link\": \"https://gcore.com/legal?tab=privacy_policy\", \"text\": \"Privacy policy\"}]",
    "priceAndPlans": "GPU Al/ML today! NVIDIA A100s & H100s for \u20ac 2.06/h\n\nTools\n\n  * Looking Glass\n  * Speed Test\n  * Developer Tools\n  * Status Page\n\nContent Hub\n\n  * Blog\n  * Learning\n  * News\n  * Case studies\n  * Downloads\n  * Press & Media\n  * Product Roadmap\n  * API Documentation\n  * Product Documentation\n  * Help Center\n\nUnder attack?Report abuseTalk to an expert EN  DE  ZH\n\nEN  DE  ZH\n\nProducts \u2192\n\nSolutions \u2192\n\nPricing \u2192\n\nPartnership \u2192\n\nCompany \u2192\n\nContent Hub \u2192\n\nTools \u2192\n\nTalk to an expert\n\nReport abuse\n\nUnder attack?\n\nSign in  Get started for free\n\n#  AI GPU Cloud Infrastructure\n\nGcore bare metal servers and virtual machines powered by NVIDIA A100 and H100\nGPUs. Boost the productivity of your AI tasks with breakthrough performance!\n\nBook an Instance See pricing\n\n##  For more information about AI GPU Cloud Infrastructure, please fill out\nthe form\n\nFirst name*\n\nInsert your first name\n\nLast name*\n\nInsert your last name\n\nEmail*\n\nInsert your email address\n\nJob title*\n\nInsert your job title\n\nGPU configuration*\n\n  * Virtual machine\n  * Bare metal \n\nPayment options\n\nChoose payment optionsHoury Monthly Yearly\n\nQuantity*\n\nChoose quantity\n\nMessage\n\nTell us any details about your order\n\nBy clicking the button you give us an informed, specific and unambiguous\nconsent to process your personal data in accordance with our Privacy policy\n\n##  Configurations and prices\n\nEUR\n\nUSD\n\nLuxembourg (Luxembourg-2 Region)\n\n#### Bare Metal\n\nFlavor ID |  Server config |  GPUs |  GPU Memory |  Infiniband Interconnect\n(Gbit/s) |  Quantity |  Price |  \n---|---|---|---|---|---|---|---  \nbm3-ai-large-a100-40-4| 2 Intel Xeon 8468 / 2 TB RAM / 4x3.84 TB NVMe / 4x\nNvidia A100 / 200Gbit/s Infiniband|  4xA100 |  40 GB |  200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 15.52 / 1 hour\n\n\u20ac 11,174.4 / 1 month\n\n\u20ac 127,388.16 / 1 year\n\n|  Book  \nbm3-ai-large-a100-80-8| 2 Intel Xeon 8468 / 2 TB RAM / 8x3.84 TB NVMe / 8x\nNvidia A100 / 800Gbit/s Infiniband|  8xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 16.48 / 1 hour\n\n\u20ac 11,865.6 / 1 month\n\n\u20ac 135,267.84 / 1 year\n\n|  Book  \nbm3-ai-large-h100-80-8| 2 Intel Xeon 8468 / 2TB RAM / 8x3.84 TB NVMe / 8x\nNvidia H100 / 3200Gbit/s Infiniband|  8xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 30.01 / 1 hour\n\n\u20ac 21,608.00 / 1 month\n\n\u20ac 246,331.2 / 1 year\n\n|  Book  \n  \n#### Virtual instances\n\nFlavor ID |  Server config |  GPUs |  GPU Memory |  Infiniband Interconnect\n(Gbit/s) |  Quantity |  Price |  \n---|---|---|---|---|---|---|---  \ng3-ai-24-232-1100-a100-80-1| 24 vCPU / 232 GB RAM / 1100 GB NVMe / A100-1GPU|\n1xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 2.06 / 1 hour\n\n\u20ac 1,483.2 / 1 month\n\n\u20ac 16,908.48 / 1 year\n\n|  Book  \ng3-ai-48-464-2200-a100-80-2| 48 vCPU / 464 GB RAM / 2200 GB NVMe / A100-2GPU|\n2xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 4.12 / 1 hour\n\n\u20ac 2,966.4 / 1 month\n\n\u20ac 33,816.96 / 1 year\n\n|  Book  \ng3-ai-96-1856-8800-a100-80-8| 96 vCPU / 1856 GB RAM / 8800 GB NVMe /\nA100-8GPU|  8xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 16.48 / 1 hour\n\n\u20ac 11,865.6 / 1 month\n\n\u20ac 135,267.84 / 1 year\n\n|  Book  \ng3-ai-24-232-1100-h100-80-1| 24 vCPU / 232 GB RAM / 1100 GB NVMe / H100-1GPU|\n1xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 3.75 / 1 hour\n\n\u20ac 2,701.0 / 1 month\n\n\u20ac 30,791.4 / 1 year\n\n|  Book  \ng3-ai-48-464-2200-h100-80-2| 48 vCPU / 464 GB RAM / 2200 GB NVMe / H100-2GPU|\n2xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 7.5 / 1 hour\n\n\u20ac 5,402.0 / 1 month\n\n\u20ac 61,582.8 / 1 year\n\n|  Book  \ng3-ai-96-1856-8800-h100-80-8| 96 vCPU / 1856 GB RAM / 8800 GB NVMe /\nH100-8GPU|  8xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 30.01 / 1 hour\n\n\u20ac 21,608.0 / 1 month\n\n\u20ac 246,331.2 / 1 year\n\n|  Book  \n  \nBare Metal\n\nVirtual instances\n\nFlavor ID |  Server config |  GPUs |  GPU Memory |  Infiniband Interconnect\n(Gbit/s) |  Quantity |  Price |  \n---|---|---|---|---|---|---|---  \nbm3-ai-large-a100-40-4| 2 Intel Xeon 8468 / 2 TB RAM / 4x3.84 TB NVMe / 4x\nNvidia A100 / 200Gbit/s Infiniband|  4xA100 |  40 GB |  200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 15.52 / 1 hour\n\n\u20ac 11,174.4 / 1 month\n\n\u20ac 127,388.16 / 1 year\n\n|  Book  \nbm3-ai-large-a100-80-8| 2 Intel Xeon 8468 / 2 TB RAM / 8x3.84 TB NVMe / 8x\nNvidia A100 / 800Gbit/s Infiniband|  8xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 16.48 / 1 hour\n\n\u20ac 11,865.6 / 1 month\n\n\u20ac 135,267.84 / 1 year\n\n|  Book  \nbm3-ai-large-h100-80-8| 2 Intel Xeon 8468 / 2TB RAM / 8x3.84 TB NVMe / 8x\nNvidia H100 / 3200Gbit/s Infiniband|  8xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 30.01 / 1 hour\n\n\u20ac 21,608.00 / 1 month\n\n\u20ac 246,331.2 / 1 year\n\n|  Book  \n  \nScroll horizontally to view the table\n\n*Prices do not include VAT. \n\n##  Designed for AI and compute-intensive workloads\n\n#### AI training\n\nWith thousands of processing cores, a graphics processing unit (GPU) can\nperform multiple matrix operations and calculations in parallel. As a result,\nGPUs complete AI training tasks much faster than traditional CPUs.\n\n#### Deep learning\n\nGPUs easily handle the high computational demands of deep neural networks and\n\u200b\u200brecurrent neural networks, which are fundamental to developing complex deep\nlearning models, including generative AI.\n\n\n\n#### High-performance computing\n\nSuperior GPU performance is well suited for compute-intensive workloads,\nincluding dynamic programming algorithms, video rendering, and scientific\nsimulations.\n\n#### Data analytics\n\nGPUs provide high memory bandwidth and efficient data transfer capabilities.\nThis improves the processing and manipulation of large data sets, enabling\nfaster analysis.\n\n##  GPU champs\n\nThe NVIDIA A100 and latest H100 GPUs are at the forefront of the enterprise\nGPU market. Both are powerful  \nand versatile accelerators for a wide range of AI and high-performance\ncomputing (HPC) workloads.\n\n#### A100 specs\n\n  * Up to 249x higher AI inference performance over CPUs \n  * Up to 20x higher performance than the previous generation of the NVIDIA GPU, V100 \n  * Tensor Core 3rd generation \n  * Up to 80GB of HBM2e memory \n\n#### H100 specs\n\n  * Up to 4x higher performance than the A100 GPU for AI training on GPT-3 \n  * \u200b\u200bUp to 7x higher performance than the A100 GPU for HPC applications \n  * Tensor Core 4th generation \n  * Up to 100GB of HBM3 memory \n\nBook an Instance\n\nPrior to the H100 release in 2022, A100 was a leading GPU platform in the\nMLPerf industry benchmarks.\n\nIn the latest MLPerf benchmark, H100 showed better performance than\ncompetitors.\n\n##  Ideal for AI frameworks\n\nNVIDIA GPUs are great for running AI frameworks and tools that help to build,\ntrain, and deploy AI models.\n\n##  Dedicated bare metal GPU servers or virtual GPU instances?\n\n\u0421hoose what works for you!\n\n###  Bare metal GPU servers\n\nBare metal servers provide direct access to the physical hardware, including\nthe GPU. This means that all GPU resources are dedicated to you. Bare metal\nGPU gives you optimal performance for AI and compute-intensive workloads.\n\n###  Virtual GPU instances\n\nFor the same configuration, GPUs on VMs may perform slightly slower than those\non bare metal servers. But VMs offer easier management, scalability, and lower\nprices than bare metal GPU servers.\n\n##  Managed Kubernetes with GPU worker nodes\n\nFeatures like autoscaling and autohealing make Kubernetes ideal for dynamic\nworkloads, including machine learning, video processing, and other compute-\nintensive tasks. With Gcore\u2019s Managed Kubernetes, you can use Bare Metal and\nVMs with GPU as worker nodes (A100 and H100.) Simply utilize GPUs in your\ncontainers by requesting the custom GPU resource, just like you would request\nCPU or memory.\n\nLearn more about Managed Kubernetes\n\n##  Take advantage of  \nGcore Cloud solutions\n\n#### AI IPU\n\nUse Gcore\u2019s AI cloud infrastructure powered by Graphcore IPUs to accelerate\nmachine learning.\n\nLearn more  \u2192\n\n#### Bare metal servers\n\nDeploy resource-intensive applications and services on high-performance\nphysical servers.\n\nLearn more  \u2192\n\n#### Virtual machines\n\nLeverage production-grade VMs designed for a wide range of workloads and\npredictable performance.\n\nLearn more  \u2192\n\n#### Managed Kubernetes\n\nProvision, manage, and scale Kubernetes clusters with 99.9% SLA and support\nfor bare metal nodes.\n\nLearn more  \u2192\n\n##  Frequently Asked Questions\n\n#### What is a graphics processing unit?\n\nA graphics processing unit (GPU) is a specialized electronic circuit designed\nto improve the rendering of computer graphics. GPUs are used in various\napplications, including video games, 3D modeling, and AI training.  \n  \nGPUs are designed for parallel processing, which means that they can execute\nmultiple instructions at the same time. This is the main difference between\nGPUs and central processing units (CPUs); the latter executes instructions one\nat a time.\n\n#### How will I be charged for GPU instances?\n\nYou will be charged for a specific configuration that you choose. If you\npurchase a separate GPU instance that is not part of a Kubernetes cluster, you\nwill be charged for the corresponding VM or bare metal configuration. See the\n_Configuration and pricing_ section above to learn more about our pricing.\n\n#### How can I change the configuration of a GPU instance?\n\nContact our sales team at sales@gcore.com with your desired new instance\nconfiguration. If you need help choosing a configuration, they\u2019ll get back to\nyou with the best solution for your request.\n\n#### Are your GPU instances fully dedicated or shared?\n\nIt depends on the type of instances you choose, bare metal or VMs. If you\nchoose a bare metal server, all of its resources are dedicated to you.  \n  \nIf you choose a VM, you get virtual computing resources, including those of a\nGPU. The physical resources of the instance (server) are shared, but the\nvirtual resources are not. You get access to the full amount of resources that\nyou purchased.\n\n#### When will the instance I purchased be available?\n\nAfter you purchase the GPU instance, it is up and running:  \n  \n\n  * Within 3\u20135 minutes if it is a virtual machine\n  * Within 15\u201320 minutes if it is a bare metal server\n\n#### Do you offer a free trial period to test a GPU instance?\n\nYes. Fill out this form, and our sales team will contact you to discuss this\noption. Please note that at the end of your trial period, you will be switched\nto the standard pay-as-you-go plan.\n\n#### Can I get custom pricing?\n\nYes. Fill out this form and our sales team will contact you to discuss this\noption.\n\n#### Do you have a waiting list for GPU instances?\n\nYes. Fill out this form and our sales team will contact you to discuss the\ndetails and add you to our waiting list.\n\n##  Contact us to get personalized offer\n\nTell us about the challenges of your business, and we\u2019ll help you grow in any\ncountry in the world.\n\nTalk to an expert\n\nWe provide powerful solutions that will help your business grow globally. Try\nour superior performance for free.\n\nConvenient cloud services with low latency around the world proven by the\nlargest online businesses.\n\n####  Products\n\nCDNDNSHostingStreaming PlatformStorageDDoS ProtectionCloudIT Infrastructure\nManagement\n\n####  Company\n\nAboutAffiliate ProgramReferral ProgramCase\nStudiesCareersBlogLearningPressLegal Information#SupportUkraine\n\n####  Resources\n\nStatus PageAPI DocumentationProduct DocumentationLooking GlassDeveloper\nToolsProducts RoadmapHelp Center\n\n#### Contact\n\nsupport@gcore.cominfo@gcore.comReport abuse\n\n####  Sales\n\n\\+ 352 208 80 507sales@gcore.com\n\n#### Follow us on social media\n\n#### Subscribe and discover the latest updates, news, and features\n\nWe value your inbox and are committed to preventing spam\n\nEmail*\n\nInsert your email address\n\nUTM Campaign\n\nUTM Content\n\nUTM Medium\n\nUTM Source\n\nUTM Term\n\nGA Client id\n\nBy clicking the button you give us an informed, specific and unambiguous\nconsent to process your personal data in accordance with our Privacy policy\n\nThis site is protected by reCAPTCHA and the Google Privacy Policy and Terms of\nService apply.\n\nG-Core Labs S.A. \u00a9 2015\u20132023 All rights reserved. Principal place of business\nand postal address: 2-4, Rue Edmond Reuter, L-5326 Contern, Luxembourg\n\nGPU Al/ML today! NVIDIA A100s & H100s for \u20ac 2.06/h\n\nTools\n\n  * Looking Glass\n  * Speed Test\n  * Developer Tools\n  * Status Page\n\nContent Hub\n\n  * Blog\n  * Learning\n  * News\n  * Case studies\n  * Downloads\n  * Press & Media\n  * Product Roadmap\n  * API Documentation\n  * Product Documentation\n  * Help Center\n\nUnder attack?Report abuseTalk to an expert EN  DE  ZH\n\nEN  DE  ZH\n\nProducts \u2192\n\nSolutions \u2192\n\nPricing \u2192\n\nPartnership \u2192\n\nCompany \u2192\n\nContent Hub \u2192\n\nTools \u2192\n\nTalk to an expert\n\nReport abuse\n\nUnder attack?\n\nSign in  Get started for free\n\n#  AI GPU Cloud Infrastructure\n\nGcore bare metal servers and virtual machines powered by NVIDIA A100 and H100\nGPUs. Boost the productivity of your AI tasks with breakthrough performance!\n\nBook an Instance See pricing\n\n##  For more information about AI GPU Cloud Infrastructure, please fill out\nthe form\n\nBy clicking the button you give us an informed, specific and unambiguous\nconsent to process your personal data in accordance with our Privacy policy\n\n##  Configurations and prices\n\nEUR\n\nUSD\n\nLuxembourg (Luxembourg-2 Region)\n\n#### Bare Metal\n\nFlavor ID |  Server config |  GPUs |  GPU Memory |  Infiniband Interconnect\n(Gbit/s) |  Quantity |  Price |  \n---|---|---|---|---|---|---|---  \nbm3-ai-large-a100-40-4| 2 Intel Xeon 8468 / 2 TB RAM / 4x3.84 TB NVMe / 4x\nNvidia A100 / 200Gbit/s Infiniband|  4xA100 |  40 GB |  200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 15.52 / 1 hour\n\n\u20ac 11,174.4 / 1 month\n\n\u20ac 127,388.16 / 1 year\n\n|  Book  \nbm3-ai-large-a100-80-8| 2 Intel Xeon 8468 / 2 TB RAM / 8x3.84 TB NVMe / 8x\nNvidia A100 / 800Gbit/s Infiniband|  8xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 16.48 / 1 hour\n\n\u20ac 11,865.6 / 1 month\n\n\u20ac 135,267.84 / 1 year\n\n|  Book  \nbm3-ai-large-h100-80-8| 2 Intel Xeon 8468 / 2TB RAM / 8x3.84 TB NVMe / 8x\nNvidia H100 / 3200Gbit/s Infiniband|  8xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 30.01 / 1 hour\n\n\u20ac 21,608.00 / 1 month\n\n\u20ac 246,331.2 / 1 year\n\n|  Book  \n  \n#### Virtual instances\n\nFlavor ID |  Server config |  GPUs |  GPU Memory |  Infiniband Interconnect\n(Gbit/s) |  Quantity |  Price |  \n---|---|---|---|---|---|---|---  \ng3-ai-24-232-1100-a100-80-1| 24 vCPU / 232 GB RAM / 1100 GB NVMe / A100-1GPU|\n1xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 2.06 / 1 hour\n\n\u20ac 1,483.2 / 1 month\n\n\u20ac 16,908.48 / 1 year\n\n|  Book  \ng3-ai-48-464-2200-a100-80-2| 48 vCPU / 464 GB RAM / 2200 GB NVMe / A100-2GPU|\n2xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 4.12 / 1 hour\n\n\u20ac 2,966.4 / 1 month\n\n\u20ac 33,816.96 / 1 year\n\n|  Book  \ng3-ai-96-1856-8800-a100-80-8| 96 vCPU / 1856 GB RAM / 8800 GB NVMe /\nA100-8GPU|  8xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 16.48 / 1 hour\n\n\u20ac 11,865.6 / 1 month\n\n\u20ac 135,267.84 / 1 year\n\n|  Book  \ng3-ai-24-232-1100-h100-80-1| 24 vCPU / 232 GB RAM / 1100 GB NVMe / H100-1GPU|\n1xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 3.75 / 1 hour\n\n\u20ac 2,701.0 / 1 month\n\n\u20ac 30,791.4 / 1 year\n\n|  Book  \ng3-ai-48-464-2200-h100-80-2| 48 vCPU / 464 GB RAM / 2200 GB NVMe / H100-2GPU|\n2xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 7.5 / 1 hour\n\n\u20ac 5,402.0 / 1 month\n\n\u20ac 61,582.8 / 1 year\n\n|  Book  \ng3-ai-96-1856-8800-h100-80-8| 96 vCPU / 1856 GB RAM / 8800 GB NVMe /\nH100-8GPU|  8xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 30.01 / 1 hour\n\n\u20ac 21,608.0 / 1 month\n\n\u20ac 246,331.2 / 1 year\n\n|  Book  \n  \nBare Metal\n\nVirtual instances\n\nFlavor ID |  Server config |  GPUs |  GPU Memory |  Infiniband Interconnect\n(Gbit/s) |  Quantity |  Price |  \n---|---|---|---|---|---|---|---  \nbm3-ai-large-a100-40-4| 2 Intel Xeon 8468 / 2 TB RAM / 4x3.84 TB NVMe / 4x\nNvidia A100 / 200Gbit/s Infiniband|  4xA100 |  40 GB |  200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 15.52 / 1 hour\n\n\u20ac 11,174.4 / 1 month\n\n\u20ac 127,388.16 / 1 year\n\n|  Book  \nbm3-ai-large-a100-80-8| 2 Intel Xeon 8468 / 2 TB RAM / 8x3.84 TB NVMe / 8x\nNvidia A100 / 800Gbit/s Infiniband|  8xA100 |  80 GB |  800 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 16.48 / 1 hour\n\n\u20ac 11,865.6 / 1 month\n\n\u20ac 135,267.84 / 1 year\n\n|  Book  \nbm3-ai-large-h100-80-8| 2 Intel Xeon 8468 / 2TB RAM / 8x3.84 TB NVMe / 8x\nNvidia H100 / 3200Gbit/s Infiniband|  8xH100 |  80 GB |  3200 |\n\n1\n\n  * 1\n\n|\n\n\u20ac 30.01 / 1 hour\n\n\u20ac 21,608.00 / 1 month\n\n\u20ac 246,331.2 / 1 year\n\n|  Book  \n  \nScroll horizontally to view the table\n\n*Prices do not include VAT. \n\n##  Designed for AI and compute-intensive workloads\n\n#### AI training\n\nWith thousands of processing cores, a graphics processing unit (GPU) can\nperform multiple matrix operations and calculations in parallel. As a result,\nGPUs complete AI training tasks much faster than traditional CPUs.\n\n#### Deep learning\n\nGPUs easily handle the high computational demands of deep neural networks and\n\u200b\u200brecurrent neural networks, which are fundamental to developing complex deep\nlearning models, including generative AI.\n\n\n\n#### High-performance computing\n\nSuperior GPU performance is well suited for compute-intensive workloads,\nincluding dynamic programming algorithms, video rendering, and scientific\nsimulations.\n\n#### Data analytics\n\nGPUs provide high memory bandwidth and efficient data transfer capabilities.\nThis improves the processing and manipulation of large data sets, enabling\nfaster analysis.\n\n##  GPU champs\n\nThe NVIDIA A100 and latest H100 GPUs are at the forefront of the enterprise\nGPU market. Both are powerful  \nand versatile accelerators for a wide range of AI and high-performance\ncomputing (HPC) workloads.\n\n#### A100 specs\n\n  * Up to 249x higher AI inference performance over CPUs \n  * Up to 20x higher performance than the previous generation of the NVIDIA GPU, V100 \n  * Tensor Core 3rd generation \n  * Up to 80GB of HBM2e memory \n\n#### H100 specs\n\n  * Up to 4x higher performance than the A100 GPU for AI training on GPT-3 \n  * \u200b\u200bUp to 7x higher performance than the A100 GPU for HPC applications \n  * Tensor Core 4th generation \n  * Up to 100GB of HBM3 memory \n\nBook an Instance\n\nPrior to the H100 release in 2022, A100 was a leading GPU platform in the\nMLPerf industry benchmarks.\n\nIn the latest MLPerf benchmark, H100 showed better performance than\ncompetitors.\n\n##  Ideal for AI frameworks\n\nNVIDIA GPUs are great for running AI frameworks and tools that help to build,\ntrain, and deploy AI models.\n\n##  Dedicated bare metal GPU servers or virtual GPU instances?\n\n\u0421hoose what works for you!\n\n###  Bare metal GPU servers\n\nBare metal servers provide direct access to the physical hardware, including\nthe GPU. This means that all GPU resources are dedicated to you. Bare metal\nGPU gives you optimal performance for AI and compute-intensive workloads.\n\n###  Virtual GPU instances\n\nFor the same configuration, GPUs on VMs may perform slightly slower than those\non bare metal servers. But VMs offer easier management, scalability, and lower\nprices than bare metal GPU servers.\n\n##  Managed Kubernetes with GPU worker nodes\n\nFeatures like autoscaling and autohealing make Kubernetes ideal for dynamic\nworkloads, including machine learning, video processing, and other compute-\nintensive tasks. With Gcore\u2019s Managed Kubernetes, you can use Bare Metal and\nVMs with GPU as worker nodes (A100 and H100.) Simply utilize GPUs in your\ncontainers by requesting the custom GPU resource, just like you would request\nCPU or memory.\n\nLearn more about Managed Kubernetes\n\n##  Take advantage of  \nGcore Cloud solutions\n\n#### AI IPU\n\nUse Gcore\u2019s AI cloud infrastructure powered by Graphcore IPUs to accelerate\nmachine learning.\n\nLearn more  \u2192\n\n#### Bare metal servers\n\nDeploy resource-intensive applications and services on high-performance\nphysical servers.\n\nLearn more  \u2192\n\n#### Virtual machines\n\nLeverage production-grade VMs designed for a wide range of workloads and\npredictable performance.\n\nLearn more  \u2192\n\n#### Managed Kubernetes\n\nProvision, manage, and scale Kubernetes clusters with 99.9% SLA and support\nfor bare metal nodes.\n\nLearn more  \u2192\n\n##  Frequently Asked Questions\n\n#### What is a graphics processing unit?\n\nA graphics processing unit (GPU) is a specialized electronic circuit designed\nto improve the rendering of computer graphics. GPUs are used in various\napplications, including video games, 3D modeling, and AI training.  \n  \nGPUs are designed for parallel processing, which means that they can execute\nmultiple instructions at the same time. This is the main difference between\nGPUs and central processing units (CPUs); the latter executes instructions one\nat a time.\n\n#### How will I be charged for GPU instances?\n\nYou will be charged for a specific configuration that you choose. If you\npurchase a separate GPU instance that is not part of a Kubernetes cluster, you\nwill be charged for the corresponding VM or bare metal configuration. See the\n_Configuration and pricing_ section above to learn more about our pricing.\n\n#### How can I change the configuration of a GPU instance?\n\nContact our sales team at sales@gcore.com with your desired new instance\nconfiguration. If you need help choosing a configuration, they\u2019ll get back to\nyou with the best solution for your request.\n\n#### Are your GPU instances fully dedicated or shared?\n\nIt depends on the type of instances you choose, bare metal or VMs. If you\nchoose a bare metal server, all of its resources are dedicated to you.  \n  \nIf you choose a VM, you get virtual computing resources, including those of a\nGPU. The physical resources of the instance (server) are shared, but the\nvirtual resources are not. You get access to the full amount of resources that\nyou purchased.\n\n#### When will the instance I purchased be available?\n\nAfter you purchase the GPU instance, it is up and running:  \n  \n\n  * Within 3\u20135 minutes if it is a virtual machine\n  * Within 15\u201320 minutes if it is a bare metal server\n\n#### Do you offer a free trial period to test a GPU instance?\n\nYes. Fill out this form, and our sales team will contact you to discuss this\noption. Please note that at the end of your trial period, you will be switched\nto the standard pay-as-you-go plan.\n\n#### Can I get custom pricing?\n\nYes. Fill out this form and our sales team will contact you to discuss this\noption.\n\n#### Do you have a waiting list for GPU instances?\n\nYes. Fill out this form and our sales team will contact you to discuss the\ndetails and add you to our waiting list.\n\n##  Contact us to get personalized offer\n\nTell us about the challenges of your business, and we\u2019ll help you grow in any\ncountry in the world.\n\nTalk to an expert\n\nWe provide powerful solutions that will help your business grow globally. Try\nour superior performance for free.\n\nConvenient cloud services with low latency around the world proven by the\nlargest online businesses.\n\n####  Products\n\nCDNDNSHostingStreaming PlatformStorageDDoS ProtectionCloudIT Infrastructure\nManagement\n\n####  Company\n\nAboutAffiliate ProgramReferral ProgramCase\nStudiesCareersBlogLearningPressLegal Information#SupportUkraine\n\n####  Resources\n\nStatus PageAPI DocumentationProduct DocumentationLooking GlassDeveloper\nToolsProducts RoadmapHelp Center\n\n#### Contact\n\nsupport@gcore.cominfo@gcore.comReport abuse\n\n####  Sales\n\n\\+ 352 208 80 507sales@gcore.com\n\n#### Follow us on social media\n\n#### Subscribe and discover the latest updates, news, and features\n\nWe value your inbox and are committed to preventing spam\n\nBy clicking the button you give us an informed, specific and unambiguous\nconsent to process your personal data in accordance with our Privacy policy\n\nThis site is protected by reCAPTCHA and the Google Privacy Policy and Terms of\nService apply.\n\nG-Core Labs S.A. \u00a9 2015\u20132023 All rights reserved. Principal place of business\nand postal address: 2-4, Rue Edmond Reuter, L-5326 Contern, Luxembourg\n\n"
}